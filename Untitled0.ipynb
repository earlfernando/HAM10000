{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earlfernando/HAM10000/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRG6kkW86oos",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "f612c150-4417-4661-99d2-818ce5860317"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52cbf75e-973c-4fe1-9360-2449bbba6fae\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-52cbf75e-973c-4fe1-9360-2449bbba6fae\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving HAM10000_metadata.csv to HAM10000_metadata.csv\n",
            "User uploaded file \"HAM10000_metadata.csv\" with length 563277 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNxBbV757Diz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XmrW7Cw1yln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdeZpYM87KtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ok2bjaaR7MbH",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYrJvJ0n1-Ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_frame= pd.read_csv(io.BytesIO(uploaded['HAM10000_metadata.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMO7Jpy_7OCn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6cf33957-3b84-4d4e-e008-75fe44c87c72"
      },
      "source": [
        "print(data_frame.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     lesion_id      image_id   dx dx_type   age   sex localization\n",
            "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
            "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
            "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
            "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
            "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzUBjE5n7R_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "66967803-e322-4ebf-c930-360c25619a19"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "new_data_frame = data_frame[['dx','dx_type','age','sex','localization']]\n",
        "new_data_frame.head()\n",
        "label_dataframe=new_data_frame.drop(['dx'],axis=1)\n",
        "label_dataframe.head()\n",
        "print(label_dataframe.columns)\n",
        "for i in label_dataframe.columns:\n",
        "    print(pd.unique(label_dataframe[[i]].values.ravel()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['dx_type', 'age', 'sex', 'localization'], dtype='object')\n",
            "['histo' 'consensus' 'confocal' 'follow_up']\n",
            "[80. 75. 60. 70. 55. 85. 65. 40. 50. 45. 35.  0. 30. nan  5. 25. 20. 10.\n",
            " 15.]\n",
            "['male' 'female' 'unknown']\n",
            "['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
            " 'unknown' 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KedC2uiB7jtU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b97f0b80-c9c5-4805-c93f-57cfd213fad0"
      },
      "source": [
        "label_dataframe.columns\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dx_type', 'age', 'sex', 'localization'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjjID5azAp0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9724a794-3c15-4c33-899d-9b76d57698b0"
      },
      "source": [
        "# turn X into dict\n",
        "X_dict = label_dataframe.to_dict(orient='records') # turn each row as key-value pairs\n",
        "# show X_dict\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "# instantiate a Dictvectorizer object for X\n",
        "dv_X = DictVectorizer(sparse=False) \n",
        "X_encoded = dv_X.fit_transform(X_dict)\n",
        "# show X_encoded\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import to_categorical\n",
        "col_mean =np.round( np.nanmean(X_encoded, axis=0))\n",
        "inds = np.where(np.isnan(X_encoded))\n",
        "X_encoded[inds] = np.take(col_mean, inds[1])\n",
        "from keras.utils import to_categorical\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(new_data_frame['dx'])\n",
        "label=le.transform(new_data_frame['dx']) \n",
        "y = to_categorical(label)\n",
        "print(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
        "X_test,X_val,y_test,y_val=train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "   \n",
        "    r = tp / (tp + fn + K.epsilon())    \n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "  \n",
        "def precision(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "   \n",
        "    return K.mean(p)\n",
        "def recall(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "   \n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    \n",
        "    return K.mean(r)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(23,)))\n",
        "model.add(Activation('relu'))                            \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(7))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=[recall, precision], optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False))\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=1000,\n",
        "          verbose=2,\n",
        "          validation_data=(X_val, y_val))\n",
        "\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]]\n",
            "Train on 7010 samples, validate on 1503 samples\n",
            "Epoch 1/1000\n",
            " - 3s - loss: 1.2570 - recall: 0.1171 - precision: 0.1237 - val_loss: 0.9334 - val_recall: 0.1375 - val_precision: 0.1056\n",
            "Epoch 2/1000\n",
            " - 2s - loss: 0.8791 - recall: 0.1234 - precision: 0.1357 - val_loss: 0.8675 - val_recall: 0.1321 - val_precision: 0.1147\n",
            "Epoch 3/1000\n",
            " - 2s - loss: 0.8433 - recall: 0.1231 - precision: 0.1337 - val_loss: 0.8146 - val_recall: 0.1352 - val_precision: 0.1412\n",
            "Epoch 4/1000\n",
            " - 2s - loss: 0.8102 - recall: 0.1314 - precision: 0.1561 - val_loss: 0.8412 - val_recall: 0.1058 - val_precision: 0.1374\n",
            "Epoch 5/1000\n",
            " - 2s - loss: 0.8040 - recall: 0.1309 - precision: 0.1532 - val_loss: 0.7955 - val_recall: 0.1426 - val_precision: 0.1668\n",
            "Epoch 6/1000\n",
            " - 2s - loss: 0.7810 - recall: 0.1404 - precision: 0.1795 - val_loss: 0.7700 - val_recall: 0.1421 - val_precision: 0.1933\n",
            "Epoch 7/1000\n",
            " - 2s - loss: 0.7696 - recall: 0.1490 - precision: 0.1889 - val_loss: 0.7654 - val_recall: 0.1440 - val_precision: 0.1879\n",
            "Epoch 8/1000\n",
            " - 2s - loss: 0.7648 - recall: 0.1455 - precision: 0.1911 - val_loss: 0.8133 - val_recall: 0.1242 - val_precision: 0.1959\n",
            "Epoch 9/1000\n",
            " - 2s - loss: 0.7637 - recall: 0.1499 - precision: 0.1958 - val_loss: 0.7561 - val_recall: 0.1465 - val_precision: 0.1866\n",
            "Epoch 10/1000\n",
            " - 2s - loss: 0.7517 - recall: 0.1496 - precision: 0.1919 - val_loss: 0.7678 - val_recall: 0.1394 - val_precision: 0.1942\n",
            "Epoch 11/1000\n",
            " - 2s - loss: 0.7507 - recall: 0.1524 - precision: 0.1985 - val_loss: 0.7493 - val_recall: 0.1482 - val_precision: 0.1901\n",
            "Epoch 12/1000\n",
            " - 2s - loss: 0.7452 - recall: 0.1513 - precision: 0.1971 - val_loss: 0.7663 - val_recall: 0.1321 - val_precision: 0.1863\n",
            "Epoch 13/1000\n",
            " - 2s - loss: 0.7441 - recall: 0.1511 - precision: 0.1971 - val_loss: 0.7885 - val_recall: 0.1472 - val_precision: 0.1698\n",
            "Epoch 14/1000\n",
            " - 2s - loss: 0.7516 - recall: 0.1527 - precision: 0.1959 - val_loss: 0.7702 - val_recall: 0.1375 - val_precision: 0.1996\n",
            "Epoch 15/1000\n",
            " - 2s - loss: 0.7382 - recall: 0.1545 - precision: 0.2048 - val_loss: 0.7652 - val_recall: 0.1533 - val_precision: 0.1895\n",
            "Epoch 16/1000\n",
            " - 2s - loss: 0.7323 - recall: 0.1569 - precision: 0.2015 - val_loss: 0.7474 - val_recall: 0.1450 - val_precision: 0.1895\n",
            "Epoch 17/1000\n",
            " - 2s - loss: 0.7341 - recall: 0.1559 - precision: 0.2022 - val_loss: 0.7735 - val_recall: 0.1380 - val_precision: 0.1974\n",
            "Epoch 18/1000\n",
            " - 2s - loss: 0.7346 - recall: 0.1577 - precision: 0.2023 - val_loss: 0.7495 - val_recall: 0.1487 - val_precision: 0.1878\n",
            "Epoch 19/1000\n",
            " - 2s - loss: 0.7331 - recall: 0.1584 - precision: 0.2013 - val_loss: 0.7532 - val_recall: 0.1474 - val_precision: 0.1892\n",
            "Epoch 20/1000\n",
            " - 2s - loss: 0.7327 - recall: 0.1581 - precision: 0.1994 - val_loss: 0.7650 - val_recall: 0.1273 - val_precision: 0.1863\n",
            "Epoch 21/1000\n",
            " - 2s - loss: 0.7263 - recall: 0.1586 - precision: 0.2075 - val_loss: 0.7477 - val_recall: 0.1484 - val_precision: 0.1915\n",
            "Epoch 22/1000\n",
            " - 2s - loss: 0.7267 - recall: 0.1611 - precision: 0.2060 - val_loss: 0.7445 - val_recall: 0.1519 - val_precision: 0.1893\n",
            "Epoch 23/1000\n",
            " - 2s - loss: 0.7297 - recall: 0.1582 - precision: 0.2015 - val_loss: 0.7545 - val_recall: 0.1397 - val_precision: 0.1839\n",
            "Epoch 24/1000\n",
            " - 2s - loss: 0.7240 - recall: 0.1603 - precision: 0.2048 - val_loss: 0.7532 - val_recall: 0.1496 - val_precision: 0.2072\n",
            "Epoch 25/1000\n",
            " - 2s - loss: 0.7211 - recall: 0.1569 - precision: 0.2008 - val_loss: 0.7686 - val_recall: 0.1465 - val_precision: 0.1977\n",
            "Epoch 26/1000\n",
            " - 2s - loss: 0.7244 - recall: 0.1599 - precision: 0.2046 - val_loss: 0.7515 - val_recall: 0.1592 - val_precision: 0.2153\n",
            "Epoch 27/1000\n",
            " - 2s - loss: 0.7201 - recall: 0.1606 - precision: 0.2094 - val_loss: 0.7520 - val_recall: 0.1644 - val_precision: 0.1991\n",
            "Epoch 28/1000\n",
            " - 2s - loss: 0.7194 - recall: 0.1616 - precision: 0.2049 - val_loss: 0.7570 - val_recall: 0.1664 - val_precision: 0.1991\n",
            "Epoch 29/1000\n",
            " - 2s - loss: 0.7258 - recall: 0.1622 - precision: 0.2073 - val_loss: 0.7528 - val_recall: 0.1568 - val_precision: 0.2019\n",
            "Epoch 30/1000\n",
            " - 2s - loss: 0.7220 - recall: 0.1588 - precision: 0.2027 - val_loss: 0.7766 - val_recall: 0.1662 - val_precision: 0.1932\n",
            "Epoch 31/1000\n",
            " - 2s - loss: 0.7232 - recall: 0.1578 - precision: 0.2023 - val_loss: 0.7511 - val_recall: 0.1533 - val_precision: 0.1993\n",
            "Epoch 32/1000\n",
            " - 2s - loss: 0.7173 - recall: 0.1610 - precision: 0.2066 - val_loss: 0.7905 - val_recall: 0.1361 - val_precision: 0.1625\n",
            "Epoch 33/1000\n",
            " - 2s - loss: 0.7146 - recall: 0.1583 - precision: 0.2086 - val_loss: 0.7467 - val_recall: 0.1593 - val_precision: 0.2056\n",
            "Epoch 34/1000\n",
            " - 2s - loss: 0.7143 - recall: 0.1602 - precision: 0.2084 - val_loss: 0.7513 - val_recall: 0.1427 - val_precision: 0.1925\n",
            "Epoch 35/1000\n",
            " - 2s - loss: 0.7234 - recall: 0.1608 - precision: 0.2039 - val_loss: 0.7591 - val_recall: 0.1374 - val_precision: 0.1782\n",
            "Epoch 36/1000\n",
            " - 2s - loss: 0.7163 - recall: 0.1622 - precision: 0.2085 - val_loss: 0.7878 - val_recall: 0.1387 - val_precision: 0.2030\n",
            "Epoch 37/1000\n",
            " - 2s - loss: 0.7184 - recall: 0.1647 - precision: 0.2096 - val_loss: 0.7562 - val_recall: 0.1580 - val_precision: 0.2101\n",
            "Epoch 38/1000\n",
            " - 2s - loss: 0.7169 - recall: 0.1605 - precision: 0.2056 - val_loss: 0.7498 - val_recall: 0.1632 - val_precision: 0.2151\n",
            "Epoch 39/1000\n",
            " - 2s - loss: 0.7121 - recall: 0.1618 - precision: 0.2068 - val_loss: 0.7680 - val_recall: 0.1456 - val_precision: 0.2016\n",
            "Epoch 40/1000\n",
            " - 2s - loss: 0.7164 - recall: 0.1583 - precision: 0.2007 - val_loss: 0.7651 - val_recall: 0.1593 - val_precision: 0.1939\n",
            "Epoch 41/1000\n",
            " - 2s - loss: 0.7116 - recall: 0.1628 - precision: 0.2050 - val_loss: 0.7505 - val_recall: 0.1617 - val_precision: 0.2060\n",
            "Epoch 42/1000\n",
            " - 2s - loss: 0.7122 - recall: 0.1634 - precision: 0.2113 - val_loss: 0.7612 - val_recall: 0.1489 - val_precision: 0.2035\n",
            "Epoch 43/1000\n",
            " - 2s - loss: 0.7064 - recall: 0.1654 - precision: 0.2172 - val_loss: 0.7583 - val_recall: 0.1605 - val_precision: 0.2070\n",
            "Epoch 44/1000\n",
            " - 2s - loss: 0.7063 - recall: 0.1650 - precision: 0.2140 - val_loss: 0.7498 - val_recall: 0.1412 - val_precision: 0.1862\n",
            "Epoch 45/1000\n",
            " - 2s - loss: 0.7129 - recall: 0.1622 - precision: 0.2058 - val_loss: 0.7574 - val_recall: 0.1562 - val_precision: 0.2063\n",
            "Epoch 46/1000\n",
            " - 2s - loss: 0.7108 - recall: 0.1648 - precision: 0.2072 - val_loss: 0.7579 - val_recall: 0.1427 - val_precision: 0.1915\n",
            "Epoch 47/1000\n",
            " - 2s - loss: 0.7202 - recall: 0.1543 - precision: 0.2019 - val_loss: 0.7552 - val_recall: 0.1553 - val_precision: 0.2054\n",
            "Epoch 48/1000\n",
            " - 2s - loss: 0.7121 - recall: 0.1634 - precision: 0.2100 - val_loss: 0.7576 - val_recall: 0.1532 - val_precision: 0.2080\n",
            "Epoch 49/1000\n",
            " - 2s - loss: 0.7096 - recall: 0.1693 - precision: 0.2176 - val_loss: 0.7656 - val_recall: 0.1529 - val_precision: 0.1976\n",
            "Epoch 50/1000\n",
            " - 2s - loss: 0.7042 - recall: 0.1641 - precision: 0.2113 - val_loss: 0.7546 - val_recall: 0.1459 - val_precision: 0.1911\n",
            "Epoch 51/1000\n",
            " - 2s - loss: 0.7103 - recall: 0.1656 - precision: 0.2086 - val_loss: 0.7476 - val_recall: 0.1594 - val_precision: 0.2100\n",
            "Epoch 52/1000\n",
            " - 2s - loss: 0.7071 - recall: 0.1667 - precision: 0.2137 - val_loss: 0.7448 - val_recall: 0.1602 - val_precision: 0.2153\n",
            "Epoch 53/1000\n",
            " - 2s - loss: 0.7020 - recall: 0.1633 - precision: 0.2075 - val_loss: 0.7534 - val_recall: 0.1652 - val_precision: 0.2158\n",
            "Epoch 54/1000\n",
            " - 2s - loss: 0.7070 - recall: 0.1645 - precision: 0.2143 - val_loss: 0.7553 - val_recall: 0.1541 - val_precision: 0.2036\n",
            "Epoch 55/1000\n",
            " - 2s - loss: 0.7068 - recall: 0.1676 - precision: 0.2171 - val_loss: 0.7492 - val_recall: 0.1616 - val_precision: 0.2127\n",
            "Epoch 56/1000\n",
            " - 2s - loss: 0.7034 - recall: 0.1652 - precision: 0.2113 - val_loss: 0.7469 - val_recall: 0.1553 - val_precision: 0.1973\n",
            "Epoch 57/1000\n",
            " - 2s - loss: 0.7046 - recall: 0.1624 - precision: 0.2072 - val_loss: 0.7606 - val_recall: 0.1515 - val_precision: 0.1948\n",
            "Epoch 58/1000\n",
            " - 2s - loss: 0.7019 - recall: 0.1653 - precision: 0.2117 - val_loss: 0.7436 - val_recall: 0.1625 - val_precision: 0.2028\n",
            "Epoch 59/1000\n",
            " - 2s - loss: 0.6999 - recall: 0.1636 - precision: 0.2102 - val_loss: 0.7522 - val_recall: 0.1585 - val_precision: 0.2107\n",
            "Epoch 60/1000\n",
            " - 2s - loss: 0.7016 - recall: 0.1663 - precision: 0.2155 - val_loss: 0.7449 - val_recall: 0.1713 - val_precision: 0.2167\n",
            "Epoch 61/1000\n",
            " - 2s - loss: 0.6981 - recall: 0.1673 - precision: 0.2137 - val_loss: 0.7487 - val_recall: 0.1642 - val_precision: 0.2080\n",
            "Epoch 62/1000\n",
            " - 2s - loss: 0.6984 - recall: 0.1680 - precision: 0.2183 - val_loss: 0.7432 - val_recall: 0.1672 - val_precision: 0.2194\n",
            "Epoch 63/1000\n",
            " - 2s - loss: 0.6970 - recall: 0.1711 - precision: 0.2209 - val_loss: 0.7581 - val_recall: 0.1491 - val_precision: 0.1957\n",
            "Epoch 64/1000\n",
            " - 2s - loss: 0.7029 - recall: 0.1648 - precision: 0.2085 - val_loss: 0.7438 - val_recall: 0.1594 - val_precision: 0.2036\n",
            "Epoch 65/1000\n",
            " - 2s - loss: 0.7027 - recall: 0.1713 - precision: 0.2287 - val_loss: 0.7538 - val_recall: 0.1511 - val_precision: 0.1888\n",
            "Epoch 66/1000\n",
            " - 2s - loss: 0.7012 - recall: 0.1670 - precision: 0.2171 - val_loss: 0.7492 - val_recall: 0.1469 - val_precision: 0.1942\n",
            "Epoch 67/1000\n",
            " - 2s - loss: 0.6993 - recall: 0.1658 - precision: 0.2161 - val_loss: 0.7495 - val_recall: 0.1628 - val_precision: 0.2077\n",
            "Epoch 68/1000\n",
            " - 2s - loss: 0.6987 - recall: 0.1638 - precision: 0.2085 - val_loss: 0.7532 - val_recall: 0.1459 - val_precision: 0.1987\n",
            "Epoch 69/1000\n",
            " - 2s - loss: 0.6981 - recall: 0.1647 - precision: 0.2085 - val_loss: 0.7527 - val_recall: 0.1593 - val_precision: 0.2041\n",
            "Epoch 70/1000\n",
            " - 2s - loss: 0.7004 - recall: 0.1665 - precision: 0.2089 - val_loss: 0.7550 - val_recall: 0.1653 - val_precision: 0.2036\n",
            "Epoch 71/1000\n",
            " - 2s - loss: 0.6938 - recall: 0.1720 - precision: 0.2189 - val_loss: 0.7482 - val_recall: 0.1583 - val_precision: 0.2053\n",
            "Epoch 72/1000\n",
            " - 2s - loss: 0.6947 - recall: 0.1658 - precision: 0.2113 - val_loss: 0.7694 - val_recall: 0.1427 - val_precision: 0.1947\n",
            "Epoch 73/1000\n",
            " - 2s - loss: 0.6991 - recall: 0.1645 - precision: 0.2131 - val_loss: 0.7493 - val_recall: 0.1589 - val_precision: 0.2131\n",
            "Epoch 74/1000\n",
            " - 2s - loss: 0.6925 - recall: 0.1720 - precision: 0.2206 - val_loss: 0.7424 - val_recall: 0.1665 - val_precision: 0.2172\n",
            "Epoch 75/1000\n",
            " - 2s - loss: 0.6991 - recall: 0.1719 - precision: 0.2171 - val_loss: 0.7548 - val_recall: 0.1395 - val_precision: 0.1851\n",
            "Epoch 76/1000\n",
            " - 2s - loss: 0.6942 - recall: 0.1678 - precision: 0.2140 - val_loss: 0.7660 - val_recall: 0.1584 - val_precision: 0.1985\n",
            "Epoch 77/1000\n",
            " - 2s - loss: 0.6998 - recall: 0.1694 - precision: 0.2161 - val_loss: 0.7534 - val_recall: 0.1523 - val_precision: 0.2041\n",
            "Epoch 78/1000\n",
            " - 2s - loss: 0.7028 - recall: 0.1653 - precision: 0.2119 - val_loss: 0.7544 - val_recall: 0.1642 - val_precision: 0.2134\n",
            "Epoch 79/1000\n",
            " - 2s - loss: 0.6953 - recall: 0.1726 - precision: 0.2209 - val_loss: 0.7416 - val_recall: 0.1550 - val_precision: 0.2015\n",
            "Epoch 80/1000\n",
            " - 2s - loss: 0.6921 - recall: 0.1696 - precision: 0.2134 - val_loss: 0.7552 - val_recall: 0.1515 - val_precision: 0.1899\n",
            "Epoch 81/1000\n",
            " - 2s - loss: 0.6957 - recall: 0.1717 - precision: 0.2160 - val_loss: 0.7578 - val_recall: 0.1478 - val_precision: 0.2025\n",
            "Epoch 82/1000\n",
            " - 2s - loss: 0.6944 - recall: 0.1684 - precision: 0.2198 - val_loss: 0.7623 - val_recall: 0.1483 - val_precision: 0.1917\n",
            "Epoch 83/1000\n",
            " - 2s - loss: 0.6945 - recall: 0.1617 - precision: 0.2111 - val_loss: 0.7486 - val_recall: 0.1545 - val_precision: 0.2032\n",
            "Epoch 84/1000\n",
            " - 2s - loss: 0.6928 - recall: 0.1668 - precision: 0.2147 - val_loss: 0.7499 - val_recall: 0.1467 - val_precision: 0.2034\n",
            "Epoch 85/1000\n",
            " - 2s - loss: 0.6919 - recall: 0.1756 - precision: 0.2244 - val_loss: 0.7516 - val_recall: 0.1490 - val_precision: 0.1983\n",
            "Epoch 86/1000\n",
            " - 2s - loss: 0.6923 - recall: 0.1710 - precision: 0.2229 - val_loss: 0.7516 - val_recall: 0.1400 - val_precision: 0.1906\n",
            "Epoch 87/1000\n",
            " - 2s - loss: 0.6942 - recall: 0.1676 - precision: 0.2174 - val_loss: 0.7437 - val_recall: 0.1553 - val_precision: 0.2008\n",
            "Epoch 88/1000\n",
            " - 2s - loss: 0.6897 - recall: 0.1698 - precision: 0.2187 - val_loss: 0.7453 - val_recall: 0.1587 - val_precision: 0.2067\n",
            "Epoch 89/1000\n",
            " - 2s - loss: 0.6879 - recall: 0.1739 - precision: 0.2202 - val_loss: 0.7519 - val_recall: 0.1454 - val_precision: 0.1983\n",
            "Epoch 90/1000\n",
            " - 2s - loss: 0.6860 - recall: 0.1742 - precision: 0.2264 - val_loss: 0.7454 - val_recall: 0.1562 - val_precision: 0.2060\n",
            "Epoch 91/1000\n",
            " - 2s - loss: 0.6889 - recall: 0.1754 - precision: 0.2290 - val_loss: 0.7566 - val_recall: 0.1420 - val_precision: 0.1973\n",
            "Epoch 92/1000\n",
            " - 2s - loss: 0.6908 - recall: 0.1722 - precision: 0.2233 - val_loss: 0.7610 - val_recall: 0.1523 - val_precision: 0.1918\n",
            "Epoch 93/1000\n",
            " - 2s - loss: 0.6878 - recall: 0.1748 - precision: 0.2247 - val_loss: 0.7546 - val_recall: 0.1533 - val_precision: 0.2054\n",
            "Epoch 94/1000\n",
            " - 2s - loss: 0.6878 - recall: 0.1711 - precision: 0.2211 - val_loss: 0.7582 - val_recall: 0.1691 - val_precision: 0.2066\n",
            "Epoch 95/1000\n",
            " - 2s - loss: 0.6902 - recall: 0.1703 - precision: 0.2157 - val_loss: 0.7453 - val_recall: 0.1656 - val_precision: 0.2198\n",
            "Epoch 96/1000\n",
            " - 2s - loss: 0.6903 - recall: 0.1726 - precision: 0.2238 - val_loss: 0.7525 - val_recall: 0.1683 - val_precision: 0.2107\n",
            "Epoch 97/1000\n",
            " - 2s - loss: 0.6895 - recall: 0.1709 - precision: 0.2194 - val_loss: 0.7445 - val_recall: 0.1590 - val_precision: 0.2089\n",
            "Epoch 98/1000\n",
            " - 2s - loss: 0.6863 - recall: 0.1690 - precision: 0.2161 - val_loss: 0.7457 - val_recall: 0.1603 - val_precision: 0.2030\n",
            "Epoch 99/1000\n",
            " - 2s - loss: 0.6892 - recall: 0.1728 - precision: 0.2253 - val_loss: 0.7486 - val_recall: 0.1647 - val_precision: 0.2111\n",
            "Epoch 100/1000\n",
            " - 2s - loss: 0.6867 - recall: 0.1773 - precision: 0.2247 - val_loss: 0.7516 - val_recall: 0.1499 - val_precision: 0.1969\n",
            "Epoch 101/1000\n",
            " - 2s - loss: 0.6897 - recall: 0.1736 - precision: 0.2210 - val_loss: 0.7516 - val_recall: 0.1491 - val_precision: 0.1958\n",
            "Epoch 102/1000\n",
            " - 2s - loss: 0.6905 - recall: 0.1730 - precision: 0.2210 - val_loss: 0.7491 - val_recall: 0.1570 - val_precision: 0.2026\n",
            "Epoch 103/1000\n",
            " - 2s - loss: 0.6890 - recall: 0.1757 - precision: 0.2306 - val_loss: 0.7470 - val_recall: 0.1520 - val_precision: 0.1973\n",
            "Epoch 104/1000\n",
            " - 2s - loss: 0.6861 - recall: 0.1738 - precision: 0.2285 - val_loss: 0.7515 - val_recall: 0.1511 - val_precision: 0.2038\n",
            "Epoch 105/1000\n",
            " - 2s - loss: 0.6860 - recall: 0.1705 - precision: 0.2220 - val_loss: 0.7532 - val_recall: 0.1682 - val_precision: 0.2084\n",
            "Epoch 106/1000\n",
            " - 2s - loss: 0.6897 - recall: 0.1737 - precision: 0.2254 - val_loss: 0.7509 - val_recall: 0.1655 - val_precision: 0.2164\n",
            "Epoch 107/1000\n",
            " - 2s - loss: 0.6847 - recall: 0.1707 - precision: 0.2157 - val_loss: 0.7481 - val_recall: 0.1705 - val_precision: 0.2154\n",
            "Epoch 108/1000\n",
            " - 2s - loss: 0.6850 - recall: 0.1689 - precision: 0.2202 - val_loss: 0.7449 - val_recall: 0.1573 - val_precision: 0.2057\n",
            "Epoch 109/1000\n",
            " - 2s - loss: 0.6867 - recall: 0.1740 - precision: 0.2265 - val_loss: 0.7505 - val_recall: 0.1576 - val_precision: 0.2132\n",
            "Epoch 110/1000\n",
            " - 2s - loss: 0.6838 - recall: 0.1711 - precision: 0.2213 - val_loss: 0.7586 - val_recall: 0.1475 - val_precision: 0.1959\n",
            "Epoch 111/1000\n",
            " - 2s - loss: 0.6845 - recall: 0.1761 - precision: 0.2345 - val_loss: 0.7533 - val_recall: 0.1648 - val_precision: 0.2087\n",
            "Epoch 112/1000\n",
            " - 2s - loss: 0.6808 - recall: 0.1745 - precision: 0.2273 - val_loss: 0.7506 - val_recall: 0.1475 - val_precision: 0.1966\n",
            "Epoch 113/1000\n",
            " - 2s - loss: 0.6843 - recall: 0.1716 - precision: 0.2188 - val_loss: 0.7559 - val_recall: 0.1562 - val_precision: 0.1980\n",
            "Epoch 114/1000\n",
            " - 2s - loss: 0.6850 - recall: 0.1787 - precision: 0.2289 - val_loss: 0.7555 - val_recall: 0.1641 - val_precision: 0.2185\n",
            "Epoch 115/1000\n",
            " - 2s - loss: 0.6839 - recall: 0.1697 - precision: 0.2175 - val_loss: 0.7499 - val_recall: 0.1558 - val_precision: 0.2036\n",
            "Epoch 116/1000\n",
            " - 2s - loss: 0.6778 - recall: 0.1712 - precision: 0.2266 - val_loss: 0.7698 - val_recall: 0.1642 - val_precision: 0.1991\n",
            "Epoch 117/1000\n",
            " - 2s - loss: 0.6808 - recall: 0.1735 - precision: 0.2305 - val_loss: 0.7593 - val_recall: 0.1561 - val_precision: 0.2071\n",
            "Epoch 118/1000\n",
            " - 2s - loss: 0.6884 - recall: 0.1730 - precision: 0.2260 - val_loss: 0.7529 - val_recall: 0.1521 - val_precision: 0.2061\n",
            "Epoch 119/1000\n",
            " - 2s - loss: 0.6819 - recall: 0.1768 - precision: 0.2318 - val_loss: 0.7522 - val_recall: 0.1679 - val_precision: 0.2111\n",
            "Epoch 120/1000\n",
            " - 2s - loss: 0.6860 - recall: 0.1761 - precision: 0.2315 - val_loss: 0.7535 - val_recall: 0.1681 - val_precision: 0.2140\n",
            "Epoch 121/1000\n",
            " - 2s - loss: 0.6863 - recall: 0.1770 - precision: 0.2331 - val_loss: 0.7643 - val_recall: 0.1530 - val_precision: 0.1978\n",
            "Epoch 122/1000\n",
            " - 2s - loss: 0.6805 - recall: 0.1793 - precision: 0.2276 - val_loss: 0.7538 - val_recall: 0.1640 - val_precision: 0.2091\n",
            "Epoch 123/1000\n",
            " - 2s - loss: 0.6814 - recall: 0.1760 - precision: 0.2271 - val_loss: 0.7504 - val_recall: 0.1705 - val_precision: 0.2259\n",
            "Epoch 124/1000\n",
            " - 2s - loss: 0.6865 - recall: 0.1797 - precision: 0.2288 - val_loss: 0.7473 - val_recall: 0.1564 - val_precision: 0.2072\n",
            "Epoch 125/1000\n",
            " - 2s - loss: 0.6846 - recall: 0.1802 - precision: 0.2385 - val_loss: 0.7590 - val_recall: 0.1535 - val_precision: 0.1945\n",
            "Epoch 126/1000\n",
            " - 2s - loss: 0.6830 - recall: 0.1742 - precision: 0.2298 - val_loss: 0.7549 - val_recall: 0.1571 - val_precision: 0.2022\n",
            "Epoch 127/1000\n",
            " - 2s - loss: 0.6855 - recall: 0.1686 - precision: 0.2193 - val_loss: 0.7461 - val_recall: 0.1437 - val_precision: 0.1907\n",
            "Epoch 128/1000\n",
            " - 2s - loss: 0.6785 - recall: 0.1776 - precision: 0.2220 - val_loss: 0.7521 - val_recall: 0.1628 - val_precision: 0.2122\n",
            "Epoch 129/1000\n",
            " - 2s - loss: 0.6837 - recall: 0.1785 - precision: 0.2325 - val_loss: 0.7475 - val_recall: 0.1611 - val_precision: 0.2080\n",
            "Epoch 130/1000\n",
            " - 2s - loss: 0.6847 - recall: 0.1716 - precision: 0.2268 - val_loss: 0.7582 - val_recall: 0.1607 - val_precision: 0.2115\n",
            "Epoch 131/1000\n",
            " - 2s - loss: 0.6771 - recall: 0.1796 - precision: 0.2334 - val_loss: 0.7502 - val_recall: 0.1720 - val_precision: 0.2147\n",
            "Epoch 132/1000\n",
            " - 2s - loss: 0.6789 - recall: 0.1823 - precision: 0.2323 - val_loss: 0.7440 - val_recall: 0.1589 - val_precision: 0.2093\n",
            "Epoch 133/1000\n",
            " - 2s - loss: 0.6847 - recall: 0.1795 - precision: 0.2333 - val_loss: 0.7497 - val_recall: 0.1517 - val_precision: 0.2005\n",
            "Epoch 134/1000\n",
            " - 2s - loss: 0.6797 - recall: 0.1745 - precision: 0.2312 - val_loss: 0.7523 - val_recall: 0.1580 - val_precision: 0.2070\n",
            "Epoch 135/1000\n",
            " - 2s - loss: 0.6805 - recall: 0.1722 - precision: 0.2307 - val_loss: 0.7482 - val_recall: 0.1587 - val_precision: 0.2098\n",
            "Epoch 136/1000\n",
            " - 2s - loss: 0.6849 - recall: 0.1702 - precision: 0.2260 - val_loss: 0.7534 - val_recall: 0.1530 - val_precision: 0.2056\n",
            "Epoch 137/1000\n",
            " - 2s - loss: 0.6801 - recall: 0.1752 - precision: 0.2312 - val_loss: 0.7570 - val_recall: 0.1484 - val_precision: 0.1929\n",
            "Epoch 138/1000\n",
            " - 2s - loss: 0.6786 - recall: 0.1794 - precision: 0.2315 - val_loss: 0.7447 - val_recall: 0.1591 - val_precision: 0.2046\n",
            "Epoch 139/1000\n",
            " - 2s - loss: 0.6768 - recall: 0.1777 - precision: 0.2338 - val_loss: 0.7597 - val_recall: 0.1499 - val_precision: 0.2005\n",
            "Epoch 140/1000\n",
            " - 2s - loss: 0.6835 - recall: 0.1769 - precision: 0.2349 - val_loss: 0.7507 - val_recall: 0.1460 - val_precision: 0.1996\n",
            "Epoch 141/1000\n",
            " - 2s - loss: 0.6806 - recall: 0.1724 - precision: 0.2321 - val_loss: 0.7540 - val_recall: 0.1587 - val_precision: 0.2127\n",
            "Epoch 142/1000\n",
            " - 2s - loss: 0.6762 - recall: 0.1764 - precision: 0.2247 - val_loss: 0.7471 - val_recall: 0.1667 - val_precision: 0.2186\n",
            "Epoch 143/1000\n",
            " - 2s - loss: 0.6758 - recall: 0.1796 - precision: 0.2330 - val_loss: 0.7543 - val_recall: 0.1613 - val_precision: 0.2113\n",
            "Epoch 144/1000\n",
            " - 2s - loss: 0.6753 - recall: 0.1818 - precision: 0.2347 - val_loss: 0.7567 - val_recall: 0.1539 - val_precision: 0.2028\n",
            "Epoch 145/1000\n",
            " - 2s - loss: 0.6817 - recall: 0.1703 - precision: 0.2234 - val_loss: 0.7518 - val_recall: 0.1599 - val_precision: 0.2137\n",
            "Epoch 146/1000\n",
            " - 2s - loss: 0.6813 - recall: 0.1729 - precision: 0.2275 - val_loss: 0.7632 - val_recall: 0.1495 - val_precision: 0.1960\n",
            "Epoch 147/1000\n",
            " - 2s - loss: 0.6832 - recall: 0.1792 - precision: 0.2302 - val_loss: 0.7448 - val_recall: 0.1556 - val_precision: 0.2020\n",
            "Epoch 148/1000\n",
            " - 2s - loss: 0.6829 - recall: 0.1734 - precision: 0.2313 - val_loss: 0.7475 - val_recall: 0.1545 - val_precision: 0.2070\n",
            "Epoch 149/1000\n",
            " - 2s - loss: 0.6761 - recall: 0.1763 - precision: 0.2319 - val_loss: 0.7615 - val_recall: 0.1659 - val_precision: 0.2151\n",
            "Epoch 150/1000\n",
            " - 2s - loss: 0.6795 - recall: 0.1766 - precision: 0.2289 - val_loss: 0.7532 - val_recall: 0.1586 - val_precision: 0.2038\n",
            "Epoch 151/1000\n",
            " - 2s - loss: 0.6791 - recall: 0.1792 - precision: 0.2363 - val_loss: 0.7553 - val_recall: 0.1471 - val_precision: 0.1918\n",
            "Epoch 152/1000\n",
            " - 2s - loss: 0.6771 - recall: 0.1737 - precision: 0.2285 - val_loss: 0.7530 - val_recall: 0.1541 - val_precision: 0.2056\n",
            "Epoch 153/1000\n",
            " - 2s - loss: 0.6876 - recall: 0.1737 - precision: 0.2270 - val_loss: 0.7524 - val_recall: 0.1621 - val_precision: 0.2158\n",
            "Epoch 154/1000\n",
            " - 2s - loss: 0.6800 - recall: 0.1752 - precision: 0.2365 - val_loss: 0.7498 - val_recall: 0.1575 - val_precision: 0.2081\n",
            "Epoch 155/1000\n",
            " - 2s - loss: 0.6794 - recall: 0.1798 - precision: 0.2325 - val_loss: 0.7517 - val_recall: 0.1558 - val_precision: 0.2059\n",
            "Epoch 156/1000\n",
            " - 2s - loss: 0.6752 - recall: 0.1755 - precision: 0.2280 - val_loss: 0.7536 - val_recall: 0.1511 - val_precision: 0.2016\n",
            "Epoch 157/1000\n",
            " - 2s - loss: 0.6841 - recall: 0.1739 - precision: 0.2291 - val_loss: 0.7506 - val_recall: 0.1563 - val_precision: 0.2091\n",
            "Epoch 158/1000\n",
            " - 2s - loss: 0.6773 - recall: 0.1794 - precision: 0.2376 - val_loss: 0.7477 - val_recall: 0.1603 - val_precision: 0.2003\n",
            "Epoch 159/1000\n",
            " - 2s - loss: 0.6727 - recall: 0.1768 - precision: 0.2343 - val_loss: 0.7534 - val_recall: 0.1572 - val_precision: 0.2026\n",
            "Epoch 160/1000\n",
            " - 2s - loss: 0.6777 - recall: 0.1763 - precision: 0.2345 - val_loss: 0.7546 - val_recall: 0.1425 - val_precision: 0.1968\n",
            "Epoch 161/1000\n",
            " - 2s - loss: 0.6767 - recall: 0.1784 - precision: 0.2304 - val_loss: 0.7677 - val_recall: 0.1579 - val_precision: 0.2010\n",
            "Epoch 162/1000\n",
            " - 2s - loss: 0.6779 - recall: 0.1745 - precision: 0.2264 - val_loss: 0.7555 - val_recall: 0.1442 - val_precision: 0.1926\n",
            "Epoch 163/1000\n",
            " - 2s - loss: 0.6755 - recall: 0.1726 - precision: 0.2261 - val_loss: 0.7476 - val_recall: 0.1502 - val_precision: 0.2013\n",
            "Epoch 164/1000\n",
            " - 2s - loss: 0.6781 - recall: 0.1754 - precision: 0.2317 - val_loss: 0.7670 - val_recall: 0.1479 - val_precision: 0.1921\n",
            "Epoch 165/1000\n",
            " - 2s - loss: 0.6753 - recall: 0.1775 - precision: 0.2315 - val_loss: 0.7613 - val_recall: 0.1456 - val_precision: 0.1899\n",
            "Epoch 166/1000\n",
            " - 2s - loss: 0.6717 - recall: 0.1765 - precision: 0.2327 - val_loss: 0.7590 - val_recall: 0.1492 - val_precision: 0.2067\n",
            "Epoch 167/1000\n",
            " - 2s - loss: 0.6758 - recall: 0.1740 - precision: 0.2322 - val_loss: 0.7568 - val_recall: 0.1610 - val_precision: 0.2178\n",
            "Epoch 168/1000\n",
            " - 2s - loss: 0.6808 - recall: 0.1770 - precision: 0.2324 - val_loss: 0.7563 - val_recall: 0.1523 - val_precision: 0.1992\n",
            "Epoch 169/1000\n",
            " - 2s - loss: 0.6731 - recall: 0.1800 - precision: 0.2326 - val_loss: 0.7513 - val_recall: 0.1482 - val_precision: 0.2009\n",
            "Epoch 170/1000\n",
            " - 2s - loss: 0.6744 - recall: 0.1802 - precision: 0.2342 - val_loss: 0.7573 - val_recall: 0.1566 - val_precision: 0.2171\n",
            "Epoch 171/1000\n",
            " - 2s - loss: 0.6758 - recall: 0.1776 - precision: 0.2317 - val_loss: 0.7581 - val_recall: 0.1609 - val_precision: 0.2126\n",
            "Epoch 172/1000\n",
            " - 2s - loss: 0.6814 - recall: 0.1810 - precision: 0.2384 - val_loss: 0.7643 - val_recall: 0.1535 - val_precision: 0.2034\n",
            "Epoch 173/1000\n",
            " - 2s - loss: 0.6753 - recall: 0.1821 - precision: 0.2360 - val_loss: 0.7607 - val_recall: 0.1658 - val_precision: 0.2140\n",
            "Epoch 174/1000\n",
            " - 2s - loss: 0.6822 - recall: 0.1763 - precision: 0.2251 - val_loss: 0.7690 - val_recall: 0.1685 - val_precision: 0.2180\n",
            "Epoch 175/1000\n",
            " - 2s - loss: 0.6750 - recall: 0.1781 - precision: 0.2335 - val_loss: 0.7547 - val_recall: 0.1688 - val_precision: 0.2214\n",
            "Epoch 176/1000\n",
            " - 2s - loss: 0.6751 - recall: 0.1810 - precision: 0.2340 - val_loss: 0.7504 - val_recall: 0.1534 - val_precision: 0.2002\n",
            "Epoch 177/1000\n",
            " - 2s - loss: 0.6786 - recall: 0.1817 - precision: 0.2379 - val_loss: 0.7616 - val_recall: 0.1571 - val_precision: 0.1923\n",
            "Epoch 178/1000\n",
            " - 2s - loss: 0.6757 - recall: 0.1815 - precision: 0.2333 - val_loss: 0.7725 - val_recall: 0.1584 - val_precision: 0.2029\n",
            "Epoch 179/1000\n",
            " - 2s - loss: 0.6758 - recall: 0.1801 - precision: 0.2282 - val_loss: 0.7561 - val_recall: 0.1546 - val_precision: 0.1958\n",
            "Epoch 180/1000\n",
            " - 2s - loss: 0.6725 - recall: 0.1804 - precision: 0.2358 - val_loss: 0.7600 - val_recall: 0.1567 - val_precision: 0.2097\n",
            "Epoch 181/1000\n",
            " - 2s - loss: 0.6771 - recall: 0.1797 - precision: 0.2318 - val_loss: 0.7626 - val_recall: 0.1650 - val_precision: 0.2099\n",
            "Epoch 182/1000\n",
            " - 2s - loss: 0.6756 - recall: 0.1774 - precision: 0.2355 - val_loss: 0.7553 - val_recall: 0.1627 - val_precision: 0.2118\n",
            "Epoch 183/1000\n",
            " - 2s - loss: 0.6755 - recall: 0.1760 - precision: 0.2287 - val_loss: 0.7541 - val_recall: 0.1560 - val_precision: 0.2008\n",
            "Epoch 184/1000\n",
            " - 2s - loss: 0.6757 - recall: 0.1781 - precision: 0.2314 - val_loss: 0.7590 - val_recall: 0.1611 - val_precision: 0.2044\n",
            "Epoch 185/1000\n",
            " - 2s - loss: 0.6728 - recall: 0.1821 - precision: 0.2350 - val_loss: 0.7567 - val_recall: 0.1622 - val_precision: 0.2089\n",
            "Epoch 186/1000\n",
            " - 2s - loss: 0.6723 - recall: 0.1822 - precision: 0.2431 - val_loss: 0.7606 - val_recall: 0.1589 - val_precision: 0.2095\n",
            "Epoch 187/1000\n",
            " - 2s - loss: 0.6716 - recall: 0.1828 - precision: 0.2383 - val_loss: 0.7689 - val_recall: 0.1598 - val_precision: 0.2072\n",
            "Epoch 188/1000\n",
            " - 2s - loss: 0.6747 - recall: 0.1822 - precision: 0.2326 - val_loss: 0.7575 - val_recall: 0.1578 - val_precision: 0.2059\n",
            "Epoch 189/1000\n",
            " - 2s - loss: 0.6731 - recall: 0.1839 - precision: 0.2393 - val_loss: 0.7678 - val_recall: 0.1706 - val_precision: 0.2133\n",
            "Epoch 190/1000\n",
            " - 2s - loss: 0.6720 - recall: 0.1857 - precision: 0.2445 - val_loss: 0.7635 - val_recall: 0.1447 - val_precision: 0.1941\n",
            "Epoch 191/1000\n",
            " - 2s - loss: 0.6746 - recall: 0.1821 - precision: 0.2438 - val_loss: 0.7546 - val_recall: 0.1537 - val_precision: 0.2053\n",
            "Epoch 192/1000\n",
            " - 2s - loss: 0.6721 - recall: 0.1796 - precision: 0.2321 - val_loss: 0.7565 - val_recall: 0.1658 - val_precision: 0.2140\n",
            "Epoch 193/1000\n",
            " - 2s - loss: 0.6772 - recall: 0.1764 - precision: 0.2394 - val_loss: 0.7579 - val_recall: 0.1659 - val_precision: 0.2145\n",
            "Epoch 194/1000\n",
            " - 2s - loss: 0.6733 - recall: 0.1757 - precision: 0.2338 - val_loss: 0.7506 - val_recall: 0.1575 - val_precision: 0.2089\n",
            "Epoch 195/1000\n",
            " - 2s - loss: 0.6733 - recall: 0.1771 - precision: 0.2345 - val_loss: 0.7504 - val_recall: 0.1617 - val_precision: 0.2067\n",
            "Epoch 196/1000\n",
            " - 2s - loss: 0.6709 - recall: 0.1771 - precision: 0.2348 - val_loss: 0.7655 - val_recall: 0.1656 - val_precision: 0.2105\n",
            "Epoch 197/1000\n",
            " - 2s - loss: 0.6739 - recall: 0.1807 - precision: 0.2402 - val_loss: 0.7553 - val_recall: 0.1496 - val_precision: 0.2065\n",
            "Epoch 198/1000\n",
            " - 2s - loss: 0.6740 - recall: 0.1800 - precision: 0.2337 - val_loss: 0.7579 - val_recall: 0.1535 - val_precision: 0.1966\n",
            "Epoch 199/1000\n",
            " - 2s - loss: 0.6734 - recall: 0.1758 - precision: 0.2321 - val_loss: 0.7514 - val_recall: 0.1481 - val_precision: 0.1939\n",
            "Epoch 200/1000\n",
            " - 2s - loss: 0.6725 - recall: 0.1812 - precision: 0.2373 - val_loss: 0.7736 - val_recall: 0.1510 - val_precision: 0.1907\n",
            "Epoch 201/1000\n",
            " - 2s - loss: 0.6710 - recall: 0.1840 - precision: 0.2424 - val_loss: 0.7576 - val_recall: 0.1538 - val_precision: 0.2025\n",
            "Epoch 202/1000\n",
            " - 2s - loss: 0.6670 - recall: 0.1801 - precision: 0.2346 - val_loss: 0.7619 - val_recall: 0.1516 - val_precision: 0.2018\n",
            "Epoch 203/1000\n",
            " - 2s - loss: 0.6687 - recall: 0.1812 - precision: 0.2394 - val_loss: 0.7599 - val_recall: 0.1634 - val_precision: 0.2131\n",
            "Epoch 204/1000\n",
            " - 2s - loss: 0.6773 - recall: 0.1812 - precision: 0.2426 - val_loss: 0.7600 - val_recall: 0.1551 - val_precision: 0.2079\n",
            "Epoch 205/1000\n",
            " - 2s - loss: 0.6709 - recall: 0.1834 - precision: 0.2372 - val_loss: 0.7605 - val_recall: 0.1497 - val_precision: 0.2004\n",
            "Epoch 206/1000\n",
            " - 2s - loss: 0.6706 - recall: 0.1838 - precision: 0.2373 - val_loss: 0.7623 - val_recall: 0.1623 - val_precision: 0.2137\n",
            "Epoch 207/1000\n",
            " - 2s - loss: 0.6767 - recall: 0.1762 - precision: 0.2368 - val_loss: 0.7603 - val_recall: 0.1479 - val_precision: 0.1993\n",
            "Epoch 208/1000\n",
            " - 2s - loss: 0.6730 - recall: 0.1802 - precision: 0.2375 - val_loss: 0.7652 - val_recall: 0.1440 - val_precision: 0.1948\n",
            "Epoch 209/1000\n",
            " - 2s - loss: 0.6691 - recall: 0.1820 - precision: 0.2438 - val_loss: 0.7606 - val_recall: 0.1649 - val_precision: 0.2088\n",
            "Epoch 210/1000\n",
            " - 2s - loss: 0.6687 - recall: 0.1827 - precision: 0.2380 - val_loss: 0.7680 - val_recall: 0.1565 - val_precision: 0.2122\n",
            "Epoch 211/1000\n",
            " - 2s - loss: 0.6753 - recall: 0.1822 - precision: 0.2347 - val_loss: 0.7591 - val_recall: 0.1448 - val_precision: 0.1970\n",
            "Epoch 212/1000\n",
            " - 2s - loss: 0.6750 - recall: 0.1751 - precision: 0.2352 - val_loss: 0.7573 - val_recall: 0.1693 - val_precision: 0.2156\n",
            "Epoch 213/1000\n",
            " - 2s - loss: 0.6754 - recall: 0.1790 - precision: 0.2304 - val_loss: 0.7643 - val_recall: 0.1509 - val_precision: 0.2090\n",
            "Epoch 214/1000\n",
            " - 2s - loss: 0.6728 - recall: 0.1798 - precision: 0.2378 - val_loss: 0.7543 - val_recall: 0.1679 - val_precision: 0.2164\n",
            "Epoch 215/1000\n",
            " - 2s - loss: 0.6685 - recall: 0.1830 - precision: 0.2381 - val_loss: 0.7633 - val_recall: 0.1555 - val_precision: 0.2102\n",
            "Epoch 216/1000\n",
            " - 2s - loss: 0.6688 - recall: 0.1819 - precision: 0.2358 - val_loss: 0.7589 - val_recall: 0.1637 - val_precision: 0.2081\n",
            "Epoch 217/1000\n",
            " - 2s - loss: 0.6659 - recall: 0.1734 - precision: 0.2295 - val_loss: 0.7544 - val_recall: 0.1535 - val_precision: 0.2056\n",
            "Epoch 218/1000\n",
            " - 2s - loss: 0.6694 - recall: 0.1836 - precision: 0.2482 - val_loss: 0.7535 - val_recall: 0.1497 - val_precision: 0.1996\n",
            "Epoch 219/1000\n",
            " - 2s - loss: 0.6705 - recall: 0.1898 - precision: 0.2466 - val_loss: 0.7606 - val_recall: 0.1487 - val_precision: 0.1971\n",
            "Epoch 220/1000\n",
            " - 2s - loss: 0.6701 - recall: 0.1766 - precision: 0.2342 - val_loss: 0.7578 - val_recall: 0.1559 - val_precision: 0.2058\n",
            "Epoch 221/1000\n",
            " - 2s - loss: 0.6710 - recall: 0.1775 - precision: 0.2308 - val_loss: 0.7654 - val_recall: 0.1498 - val_precision: 0.1978\n",
            "Epoch 222/1000\n",
            " - 2s - loss: 0.6725 - recall: 0.1752 - precision: 0.2302 - val_loss: 0.7541 - val_recall: 0.1590 - val_precision: 0.2036\n",
            "Epoch 223/1000\n",
            " - 2s - loss: 0.6712 - recall: 0.1836 - precision: 0.2348 - val_loss: 0.7656 - val_recall: 0.1561 - val_precision: 0.2040\n",
            "Epoch 224/1000\n",
            " - 2s - loss: 0.6739 - recall: 0.1852 - precision: 0.2404 - val_loss: 0.7532 - val_recall: 0.1574 - val_precision: 0.2062\n",
            "Epoch 225/1000\n",
            " - 2s - loss: 0.6675 - recall: 0.1781 - precision: 0.2402 - val_loss: 0.7594 - val_recall: 0.1731 - val_precision: 0.2195\n",
            "Epoch 226/1000\n",
            " - 2s - loss: 0.6679 - recall: 0.1827 - precision: 0.2465 - val_loss: 0.7704 - val_recall: 0.1556 - val_precision: 0.2022\n",
            "Epoch 227/1000\n",
            " - 2s - loss: 0.6713 - recall: 0.1817 - precision: 0.2352 - val_loss: 0.7627 - val_recall: 0.1505 - val_precision: 0.1995\n",
            "Epoch 228/1000\n",
            " - 2s - loss: 0.6655 - recall: 0.1765 - precision: 0.2340 - val_loss: 0.7549 - val_recall: 0.1686 - val_precision: 0.2187\n",
            "Epoch 229/1000\n",
            " - 2s - loss: 0.6694 - recall: 0.1774 - precision: 0.2326 - val_loss: 0.7653 - val_recall: 0.1550 - val_precision: 0.2054\n",
            "Epoch 230/1000\n",
            " - 2s - loss: 0.6662 - recall: 0.1776 - precision: 0.2337 - val_loss: 0.7565 - val_recall: 0.1564 - val_precision: 0.2037\n",
            "Epoch 231/1000\n",
            " - 2s - loss: 0.6693 - recall: 0.1843 - precision: 0.2426 - val_loss: 0.7656 - val_recall: 0.1505 - val_precision: 0.1966\n",
            "Epoch 232/1000\n",
            " - 2s - loss: 0.6686 - recall: 0.1803 - precision: 0.2372 - val_loss: 0.7704 - val_recall: 0.1559 - val_precision: 0.2110\n",
            "Epoch 233/1000\n",
            " - 2s - loss: 0.6655 - recall: 0.1845 - precision: 0.2439 - val_loss: 0.7531 - val_recall: 0.1597 - val_precision: 0.2158\n",
            "Epoch 234/1000\n",
            " - 2s - loss: 0.6685 - recall: 0.1819 - precision: 0.2424 - val_loss: 0.7512 - val_recall: 0.1522 - val_precision: 0.2039\n",
            "Epoch 235/1000\n",
            " - 2s - loss: 0.6672 - recall: 0.1815 - precision: 0.2433 - val_loss: 0.7557 - val_recall: 0.1610 - val_precision: 0.2152\n",
            "Epoch 236/1000\n",
            " - 2s - loss: 0.6750 - recall: 0.1770 - precision: 0.2374 - val_loss: 0.7603 - val_recall: 0.1535 - val_precision: 0.2027\n",
            "Epoch 237/1000\n",
            " - 2s - loss: 0.6718 - recall: 0.1802 - precision: 0.2378 - val_loss: 0.7688 - val_recall: 0.1537 - val_precision: 0.2043\n",
            "Epoch 238/1000\n",
            " - 2s - loss: 0.6722 - recall: 0.1796 - precision: 0.2333 - val_loss: 0.7521 - val_recall: 0.1470 - val_precision: 0.1969\n",
            "Epoch 239/1000\n",
            " - 2s - loss: 0.6701 - recall: 0.1830 - precision: 0.2494 - val_loss: 0.7559 - val_recall: 0.1477 - val_precision: 0.2026\n",
            "Epoch 240/1000\n",
            " - 2s - loss: 0.6624 - recall: 0.1819 - precision: 0.2478 - val_loss: 0.7575 - val_recall: 0.1523 - val_precision: 0.1978\n",
            "Epoch 241/1000\n",
            " - 2s - loss: 0.6692 - recall: 0.1774 - precision: 0.2331 - val_loss: 0.7709 - val_recall: 0.1546 - val_precision: 0.2075\n",
            "Epoch 242/1000\n",
            " - 2s - loss: 0.6654 - recall: 0.1822 - precision: 0.2366 - val_loss: 0.7701 - val_recall: 0.1502 - val_precision: 0.1938\n",
            "Epoch 243/1000\n",
            " - 2s - loss: 0.6699 - recall: 0.1862 - precision: 0.2413 - val_loss: 0.7689 - val_recall: 0.1518 - val_precision: 0.1959\n",
            "Epoch 244/1000\n",
            " - 2s - loss: 0.6686 - recall: 0.1849 - precision: 0.2441 - val_loss: 0.7599 - val_recall: 0.1593 - val_precision: 0.2054\n",
            "Epoch 245/1000\n",
            " - 2s - loss: 0.6649 - recall: 0.1810 - precision: 0.2376 - val_loss: 0.7642 - val_recall: 0.1541 - val_precision: 0.2038\n",
            "Epoch 246/1000\n",
            " - 2s - loss: 0.6697 - recall: 0.1809 - precision: 0.2349 - val_loss: 0.7588 - val_recall: 0.1576 - val_precision: 0.1993\n",
            "Epoch 247/1000\n",
            " - 2s - loss: 0.6692 - recall: 0.1818 - precision: 0.2389 - val_loss: 0.7616 - val_recall: 0.1610 - val_precision: 0.2078\n",
            "Epoch 248/1000\n",
            " - 2s - loss: 0.6682 - recall: 0.1813 - precision: 0.2407 - val_loss: 0.7560 - val_recall: 0.1538 - val_precision: 0.2075\n",
            "Epoch 249/1000\n",
            " - 2s - loss: 0.6727 - recall: 0.1816 - precision: 0.2301 - val_loss: 0.7584 - val_recall: 0.1511 - val_precision: 0.1986\n",
            "Epoch 250/1000\n",
            " - 2s - loss: 0.6680 - recall: 0.1809 - precision: 0.2386 - val_loss: 0.7556 - val_recall: 0.1520 - val_precision: 0.2055\n",
            "Epoch 251/1000\n",
            " - 2s - loss: 0.6680 - recall: 0.1775 - precision: 0.2398 - val_loss: 0.7594 - val_recall: 0.1553 - val_precision: 0.2099\n",
            "Epoch 252/1000\n",
            " - 2s - loss: 0.6710 - recall: 0.1790 - precision: 0.2350 - val_loss: 0.7575 - val_recall: 0.1561 - val_precision: 0.2068\n",
            "Epoch 253/1000\n",
            " - 2s - loss: 0.6704 - recall: 0.1827 - precision: 0.2425 - val_loss: 0.7568 - val_recall: 0.1534 - val_precision: 0.2050\n",
            "Epoch 254/1000\n",
            " - 2s - loss: 0.6704 - recall: 0.1814 - precision: 0.2371 - val_loss: 0.7590 - val_recall: 0.1552 - val_precision: 0.2036\n",
            "Epoch 255/1000\n",
            " - 2s - loss: 0.6675 - recall: 0.1828 - precision: 0.2485 - val_loss: 0.7665 - val_recall: 0.1505 - val_precision: 0.2024\n",
            "Epoch 256/1000\n",
            " - 2s - loss: 0.6690 - recall: 0.1821 - precision: 0.2391 - val_loss: 0.7680 - val_recall: 0.1587 - val_precision: 0.2227\n",
            "Epoch 257/1000\n",
            " - 2s - loss: 0.6638 - recall: 0.1838 - precision: 0.2405 - val_loss: 0.7550 - val_recall: 0.1562 - val_precision: 0.2065\n",
            "Epoch 258/1000\n",
            " - 2s - loss: 0.6638 - recall: 0.1823 - precision: 0.2356 - val_loss: 0.7541 - val_recall: 0.1718 - val_precision: 0.2212\n",
            "Epoch 259/1000\n",
            " - 2s - loss: 0.6670 - recall: 0.1836 - precision: 0.2413 - val_loss: 0.7670 - val_recall: 0.1599 - val_precision: 0.2074\n",
            "Epoch 260/1000\n",
            " - 2s - loss: 0.6695 - recall: 0.1828 - precision: 0.2435 - val_loss: 0.7597 - val_recall: 0.1578 - val_precision: 0.2059\n",
            "Epoch 261/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1863 - precision: 0.2445 - val_loss: 0.7615 - val_recall: 0.1566 - val_precision: 0.2048\n",
            "Epoch 262/1000\n",
            " - 2s - loss: 0.6653 - recall: 0.1812 - precision: 0.2412 - val_loss: 0.7662 - val_recall: 0.1541 - val_precision: 0.1970\n",
            "Epoch 263/1000\n",
            " - 2s - loss: 0.6656 - recall: 0.1778 - precision: 0.2391 - val_loss: 0.7663 - val_recall: 0.1568 - val_precision: 0.1986\n",
            "Epoch 264/1000\n",
            " - 2s - loss: 0.6698 - recall: 0.1832 - precision: 0.2400 - val_loss: 0.7626 - val_recall: 0.1565 - val_precision: 0.2070\n",
            "Epoch 265/1000\n",
            " - 2s - loss: 0.6646 - recall: 0.1874 - precision: 0.2457 - val_loss: 0.7591 - val_recall: 0.1516 - val_precision: 0.2083\n",
            "Epoch 266/1000\n",
            " - 2s - loss: 0.6636 - recall: 0.1846 - precision: 0.2406 - val_loss: 0.7671 - val_recall: 0.1528 - val_precision: 0.1990\n",
            "Epoch 267/1000\n",
            " - 2s - loss: 0.6681 - recall: 0.1818 - precision: 0.2404 - val_loss: 0.7545 - val_recall: 0.1529 - val_precision: 0.1986\n",
            "Epoch 268/1000\n",
            " - 2s - loss: 0.6682 - recall: 0.1843 - precision: 0.2393 - val_loss: 0.7647 - val_recall: 0.1515 - val_precision: 0.1968\n",
            "Epoch 269/1000\n",
            " - 2s - loss: 0.6657 - recall: 0.1854 - precision: 0.2450 - val_loss: 0.7623 - val_recall: 0.1589 - val_precision: 0.2069\n",
            "Epoch 270/1000\n",
            " - 2s - loss: 0.6620 - recall: 0.1831 - precision: 0.2455 - val_loss: 0.7660 - val_recall: 0.1544 - val_precision: 0.1992\n",
            "Epoch 271/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1840 - precision: 0.2406 - val_loss: 0.7609 - val_recall: 0.1674 - val_precision: 0.2239\n",
            "Epoch 272/1000\n",
            " - 2s - loss: 0.6656 - recall: 0.1884 - precision: 0.2473 - val_loss: 0.7640 - val_recall: 0.1601 - val_precision: 0.2106\n",
            "Epoch 273/1000\n",
            " - 2s - loss: 0.6660 - recall: 0.1841 - precision: 0.2406 - val_loss: 0.7609 - val_recall: 0.1579 - val_precision: 0.2075\n",
            "Epoch 274/1000\n",
            " - 2s - loss: 0.6645 - recall: 0.1838 - precision: 0.2436 - val_loss: 0.7694 - val_recall: 0.1699 - val_precision: 0.2153\n",
            "Epoch 275/1000\n",
            " - 2s - loss: 0.6664 - recall: 0.1837 - precision: 0.2418 - val_loss: 0.7567 - val_recall: 0.1596 - val_precision: 0.2096\n",
            "Epoch 276/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1859 - precision: 0.2436 - val_loss: 0.7620 - val_recall: 0.1521 - val_precision: 0.2063\n",
            "Epoch 277/1000\n",
            " - 2s - loss: 0.6663 - recall: 0.1810 - precision: 0.2451 - val_loss: 0.7651 - val_recall: 0.1527 - val_precision: 0.1979\n",
            "Epoch 278/1000\n",
            " - 2s - loss: 0.6636 - recall: 0.1829 - precision: 0.2453 - val_loss: 0.7698 - val_recall: 0.1591 - val_precision: 0.2128\n",
            "Epoch 279/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1860 - precision: 0.2477 - val_loss: 0.7614 - val_recall: 0.1576 - val_precision: 0.2053\n",
            "Epoch 280/1000\n",
            " - 2s - loss: 0.6684 - recall: 0.1841 - precision: 0.2500 - val_loss: 0.7592 - val_recall: 0.1512 - val_precision: 0.2077\n",
            "Epoch 281/1000\n",
            " - 2s - loss: 0.6646 - recall: 0.1854 - precision: 0.2470 - val_loss: 0.7562 - val_recall: 0.1568 - val_precision: 0.2103\n",
            "Epoch 282/1000\n",
            " - 2s - loss: 0.6670 - recall: 0.1829 - precision: 0.2427 - val_loss: 0.7661 - val_recall: 0.1624 - val_precision: 0.2124\n",
            "Epoch 283/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1840 - precision: 0.2430 - val_loss: 0.7623 - val_recall: 0.1571 - val_precision: 0.2074\n",
            "Epoch 284/1000\n",
            " - 2s - loss: 0.6655 - recall: 0.1769 - precision: 0.2328 - val_loss: 0.7643 - val_recall: 0.1531 - val_precision: 0.1974\n",
            "Epoch 285/1000\n",
            " - 2s - loss: 0.6667 - recall: 0.1816 - precision: 0.2393 - val_loss: 0.7571 - val_recall: 0.1496 - val_precision: 0.2023\n",
            "Epoch 286/1000\n",
            " - 2s - loss: 0.6676 - recall: 0.1839 - precision: 0.2414 - val_loss: 0.7622 - val_recall: 0.1584 - val_precision: 0.2073\n",
            "Epoch 287/1000\n",
            " - 2s - loss: 0.6648 - recall: 0.1868 - precision: 0.2405 - val_loss: 0.7712 - val_recall: 0.1610 - val_precision: 0.2137\n",
            "Epoch 288/1000\n",
            " - 2s - loss: 0.6685 - recall: 0.1838 - precision: 0.2436 - val_loss: 0.7596 - val_recall: 0.1598 - val_precision: 0.2101\n",
            "Epoch 289/1000\n",
            " - 2s - loss: 0.6631 - recall: 0.1828 - precision: 0.2524 - val_loss: 0.7753 - val_recall: 0.1563 - val_precision: 0.1967\n",
            "Epoch 290/1000\n",
            " - 2s - loss: 0.6674 - recall: 0.1827 - precision: 0.2347 - val_loss: 0.7611 - val_recall: 0.1552 - val_precision: 0.2065\n",
            "Epoch 291/1000\n",
            " - 2s - loss: 0.6590 - recall: 0.1906 - precision: 0.2566 - val_loss: 0.7824 - val_recall: 0.1531 - val_precision: 0.1942\n",
            "Epoch 292/1000\n",
            " - 2s - loss: 0.6666 - recall: 0.1845 - precision: 0.2421 - val_loss: 0.7685 - val_recall: 0.1506 - val_precision: 0.2059\n",
            "Epoch 293/1000\n",
            " - 2s - loss: 0.6639 - recall: 0.1765 - precision: 0.2366 - val_loss: 0.7649 - val_recall: 0.1579 - val_precision: 0.1991\n",
            "Epoch 294/1000\n",
            " - 2s - loss: 0.6724 - recall: 0.1754 - precision: 0.2295 - val_loss: 0.7751 - val_recall: 0.1521 - val_precision: 0.2051\n",
            "Epoch 295/1000\n",
            " - 2s - loss: 0.6693 - recall: 0.1831 - precision: 0.2407 - val_loss: 0.7573 - val_recall: 0.1505 - val_precision: 0.1982\n",
            "Epoch 296/1000\n",
            " - 2s - loss: 0.6670 - recall: 0.1793 - precision: 0.2394 - val_loss: 0.7628 - val_recall: 0.1556 - val_precision: 0.2016\n",
            "Epoch 297/1000\n",
            " - 2s - loss: 0.6707 - recall: 0.1866 - precision: 0.2452 - val_loss: 0.7676 - val_recall: 0.1619 - val_precision: 0.2137\n",
            "Epoch 298/1000\n",
            " - 2s - loss: 0.6645 - recall: 0.1858 - precision: 0.2450 - val_loss: 0.7831 - val_recall: 0.1513 - val_precision: 0.1982\n",
            "Epoch 299/1000\n",
            " - 2s - loss: 0.6636 - recall: 0.1848 - precision: 0.2427 - val_loss: 0.7779 - val_recall: 0.1521 - val_precision: 0.2038\n",
            "Epoch 300/1000\n",
            " - 2s - loss: 0.6675 - recall: 0.1785 - precision: 0.2376 - val_loss: 0.7786 - val_recall: 0.1602 - val_precision: 0.2160\n",
            "Epoch 301/1000\n",
            " - 2s - loss: 0.6668 - recall: 0.1873 - precision: 0.2404 - val_loss: 0.7602 - val_recall: 0.1593 - val_precision: 0.2127\n",
            "Epoch 302/1000\n",
            " - 2s - loss: 0.6597 - recall: 0.1887 - precision: 0.2565 - val_loss: 0.7732 - val_recall: 0.1544 - val_precision: 0.2151\n",
            "Epoch 303/1000\n",
            " - 2s - loss: 0.6679 - recall: 0.1839 - precision: 0.2403 - val_loss: 0.7656 - val_recall: 0.1546 - val_precision: 0.2035\n",
            "Epoch 304/1000\n",
            " - 2s - loss: 0.6664 - recall: 0.1864 - precision: 0.2538 - val_loss: 0.7694 - val_recall: 0.1540 - val_precision: 0.1954\n",
            "Epoch 305/1000\n",
            " - 2s - loss: 0.6661 - recall: 0.1816 - precision: 0.2395 - val_loss: 0.7723 - val_recall: 0.1550 - val_precision: 0.2066\n",
            "Epoch 306/1000\n",
            " - 2s - loss: 0.6674 - recall: 0.1863 - precision: 0.2470 - val_loss: 0.7643 - val_recall: 0.1527 - val_precision: 0.1999\n",
            "Epoch 307/1000\n",
            " - 2s - loss: 0.6652 - recall: 0.1865 - precision: 0.2485 - val_loss: 0.7622 - val_recall: 0.1504 - val_precision: 0.2022\n",
            "Epoch 308/1000\n",
            " - 2s - loss: 0.6624 - recall: 0.1860 - precision: 0.2527 - val_loss: 0.7815 - val_recall: 0.1664 - val_precision: 0.2159\n",
            "Epoch 309/1000\n",
            " - 2s - loss: 0.6646 - recall: 0.1891 - precision: 0.2525 - val_loss: 0.7719 - val_recall: 0.1554 - val_precision: 0.2022\n",
            "Epoch 310/1000\n",
            " - 2s - loss: 0.6652 - recall: 0.1818 - precision: 0.2405 - val_loss: 0.7695 - val_recall: 0.1552 - val_precision: 0.2047\n",
            "Epoch 311/1000\n",
            " - 2s - loss: 0.6587 - recall: 0.1857 - precision: 0.2442 - val_loss: 0.7616 - val_recall: 0.1469 - val_precision: 0.1997\n",
            "Epoch 312/1000\n",
            " - 2s - loss: 0.6651 - recall: 0.1878 - precision: 0.2484 - val_loss: 0.7689 - val_recall: 0.1566 - val_precision: 0.2162\n",
            "Epoch 313/1000\n",
            " - 2s - loss: 0.6652 - recall: 0.1806 - precision: 0.2419 - val_loss: 0.7613 - val_recall: 0.1602 - val_precision: 0.2059\n",
            "Epoch 314/1000\n",
            " - 2s - loss: 0.6614 - recall: 0.1838 - precision: 0.2386 - val_loss: 0.7690 - val_recall: 0.1559 - val_precision: 0.2062\n",
            "Epoch 315/1000\n",
            " - 2s - loss: 0.6633 - recall: 0.1746 - precision: 0.2374 - val_loss: 0.7593 - val_recall: 0.1546 - val_precision: 0.2034\n",
            "Epoch 316/1000\n",
            " - 2s - loss: 0.6613 - recall: 0.1891 - precision: 0.2441 - val_loss: 0.7656 - val_recall: 0.1581 - val_precision: 0.2078\n",
            "Epoch 317/1000\n",
            " - 2s - loss: 0.6654 - recall: 0.1849 - precision: 0.2455 - val_loss: 0.7672 - val_recall: 0.1506 - val_precision: 0.1955\n",
            "Epoch 318/1000\n",
            " - 2s - loss: 0.6602 - recall: 0.1852 - precision: 0.2416 - val_loss: 0.7661 - val_recall: 0.1727 - val_precision: 0.2231\n",
            "Epoch 319/1000\n",
            " - 2s - loss: 0.6645 - recall: 0.1867 - precision: 0.2489 - val_loss: 0.7640 - val_recall: 0.1578 - val_precision: 0.2050\n",
            "Epoch 320/1000\n",
            " - 2s - loss: 0.6675 - recall: 0.1893 - precision: 0.2519 - val_loss: 0.7675 - val_recall: 0.1566 - val_precision: 0.2040\n",
            "Epoch 321/1000\n",
            " - 2s - loss: 0.6650 - recall: 0.1743 - precision: 0.2313 - val_loss: 0.7715 - val_recall: 0.1570 - val_precision: 0.2057\n",
            "Epoch 322/1000\n",
            " - 2s - loss: 0.6605 - recall: 0.1813 - precision: 0.2398 - val_loss: 0.7803 - val_recall: 0.1568 - val_precision: 0.2035\n",
            "Epoch 323/1000\n",
            " - 2s - loss: 0.6647 - recall: 0.1781 - precision: 0.2388 - val_loss: 0.7762 - val_recall: 0.1569 - val_precision: 0.2000\n",
            "Epoch 324/1000\n",
            " - 2s - loss: 0.6619 - recall: 0.1868 - precision: 0.2477 - val_loss: 0.7702 - val_recall: 0.1545 - val_precision: 0.2043\n",
            "Epoch 325/1000\n",
            " - 2s - loss: 0.6651 - recall: 0.1834 - precision: 0.2494 - val_loss: 0.7724 - val_recall: 0.1506 - val_precision: 0.2034\n",
            "Epoch 326/1000\n",
            " - 2s - loss: 0.6628 - recall: 0.1816 - precision: 0.2379 - val_loss: 0.7729 - val_recall: 0.1652 - val_precision: 0.2110\n",
            "Epoch 327/1000\n",
            " - 2s - loss: 0.6624 - recall: 0.1866 - precision: 0.2461 - val_loss: 0.7798 - val_recall: 0.1495 - val_precision: 0.2090\n",
            "Epoch 328/1000\n",
            " - 2s - loss: 0.6638 - recall: 0.1813 - precision: 0.2415 - val_loss: 0.7658 - val_recall: 0.1590 - val_precision: 0.2075\n",
            "Epoch 329/1000\n",
            " - 2s - loss: 0.6610 - recall: 0.1895 - precision: 0.2523 - val_loss: 0.7729 - val_recall: 0.1521 - val_precision: 0.2151\n",
            "Epoch 330/1000\n",
            " - 2s - loss: 0.6615 - recall: 0.1852 - precision: 0.2457 - val_loss: 0.7682 - val_recall: 0.1543 - val_precision: 0.1996\n",
            "Epoch 331/1000\n",
            " - 2s - loss: 0.6657 - recall: 0.1826 - precision: 0.2442 - val_loss: 0.7684 - val_recall: 0.1594 - val_precision: 0.2058\n",
            "Epoch 332/1000\n",
            " - 2s - loss: 0.6612 - recall: 0.1886 - precision: 0.2490 - val_loss: 0.7662 - val_recall: 0.1551 - val_precision: 0.2060\n",
            "Epoch 333/1000\n",
            " - 2s - loss: 0.6696 - recall: 0.1831 - precision: 0.2450 - val_loss: 0.7790 - val_recall: 0.1608 - val_precision: 0.2143\n",
            "Epoch 334/1000\n",
            " - 2s - loss: 0.6645 - recall: 0.1865 - precision: 0.2457 - val_loss: 0.7703 - val_recall: 0.1618 - val_precision: 0.2109\n",
            "Epoch 335/1000\n",
            " - 2s - loss: 0.6653 - recall: 0.1793 - precision: 0.2373 - val_loss: 0.7842 - val_recall: 0.1621 - val_precision: 0.2143\n",
            "Epoch 336/1000\n",
            " - 2s - loss: 0.6672 - recall: 0.1832 - precision: 0.2469 - val_loss: 0.7739 - val_recall: 0.1513 - val_precision: 0.2032\n",
            "Epoch 337/1000\n",
            " - 2s - loss: 0.6654 - recall: 0.1804 - precision: 0.2387 - val_loss: 0.7751 - val_recall: 0.1534 - val_precision: 0.2049\n",
            "Epoch 338/1000\n",
            " - 2s - loss: 0.6643 - recall: 0.1869 - precision: 0.2519 - val_loss: 0.7716 - val_recall: 0.1545 - val_precision: 0.2109\n",
            "Epoch 339/1000\n",
            " - 2s - loss: 0.6654 - recall: 0.1905 - precision: 0.2530 - val_loss: 0.7747 - val_recall: 0.1537 - val_precision: 0.2023\n",
            "Epoch 340/1000\n",
            " - 2s - loss: 0.6640 - recall: 0.1870 - precision: 0.2487 - val_loss: 0.7741 - val_recall: 0.1597 - val_precision: 0.2108\n",
            "Epoch 341/1000\n",
            " - 2s - loss: 0.6601 - recall: 0.1869 - precision: 0.2494 - val_loss: 0.7745 - val_recall: 0.1711 - val_precision: 0.2201\n",
            "Epoch 342/1000\n",
            " - 2s - loss: 0.6592 - recall: 0.1827 - precision: 0.2467 - val_loss: 0.7671 - val_recall: 0.1624 - val_precision: 0.2128\n",
            "Epoch 343/1000\n",
            " - 2s - loss: 0.6590 - recall: 0.1852 - precision: 0.2486 - val_loss: 0.7692 - val_recall: 0.1456 - val_precision: 0.1957\n",
            "Epoch 344/1000\n",
            " - 2s - loss: 0.6591 - recall: 0.1835 - precision: 0.2534 - val_loss: 0.7700 - val_recall: 0.1502 - val_precision: 0.2047\n",
            "Epoch 345/1000\n",
            " - 2s - loss: 0.6597 - recall: 0.1842 - precision: 0.2449 - val_loss: 0.7756 - val_recall: 0.1657 - val_precision: 0.2089\n",
            "Epoch 346/1000\n",
            " - 2s - loss: 0.6593 - recall: 0.1900 - precision: 0.2525 - val_loss: 0.7752 - val_recall: 0.1610 - val_precision: 0.2110\n",
            "Epoch 347/1000\n",
            " - 2s - loss: 0.6588 - recall: 0.1849 - precision: 0.2421 - val_loss: 0.7770 - val_recall: 0.1585 - val_precision: 0.2097\n",
            "Epoch 348/1000\n",
            " - 2s - loss: 0.6651 - recall: 0.1830 - precision: 0.2430 - val_loss: 0.7625 - val_recall: 0.1617 - val_precision: 0.2114\n",
            "Epoch 349/1000\n",
            " - 2s - loss: 0.6646 - recall: 0.1786 - precision: 0.2390 - val_loss: 0.7730 - val_recall: 0.1659 - val_precision: 0.2194\n",
            "Epoch 350/1000\n",
            " - 2s - loss: 0.6615 - recall: 0.1866 - precision: 0.2507 - val_loss: 0.7762 - val_recall: 0.1631 - val_precision: 0.2082\n",
            "Epoch 351/1000\n",
            " - 2s - loss: 0.6595 - recall: 0.1916 - precision: 0.2556 - val_loss: 0.7855 - val_recall: 0.1573 - val_precision: 0.2052\n",
            "Epoch 352/1000\n",
            " - 2s - loss: 0.6596 - recall: 0.1859 - precision: 0.2492 - val_loss: 0.7717 - val_recall: 0.1646 - val_precision: 0.2149\n",
            "Epoch 353/1000\n",
            " - 2s - loss: 0.6639 - recall: 0.1826 - precision: 0.2402 - val_loss: 0.7711 - val_recall: 0.1515 - val_precision: 0.1989\n",
            "Epoch 354/1000\n",
            " - 2s - loss: 0.6594 - recall: 0.1766 - precision: 0.2333 - val_loss: 0.7714 - val_recall: 0.1562 - val_precision: 0.2147\n",
            "Epoch 355/1000\n",
            " - 2s - loss: 0.6640 - recall: 0.1842 - precision: 0.2433 - val_loss: 0.7697 - val_recall: 0.1539 - val_precision: 0.2077\n",
            "Epoch 356/1000\n",
            " - 2s - loss: 0.6593 - recall: 0.1886 - precision: 0.2538 - val_loss: 0.7755 - val_recall: 0.1603 - val_precision: 0.2090\n",
            "Epoch 357/1000\n",
            " - 2s - loss: 0.6584 - recall: 0.1869 - precision: 0.2425 - val_loss: 0.7688 - val_recall: 0.1573 - val_precision: 0.2119\n",
            "Epoch 358/1000\n",
            " - 2s - loss: 0.6607 - recall: 0.1891 - precision: 0.2508 - val_loss: 0.7735 - val_recall: 0.1515 - val_precision: 0.2041\n",
            "Epoch 359/1000\n",
            " - 2s - loss: 0.6693 - recall: 0.1828 - precision: 0.2438 - val_loss: 0.7729 - val_recall: 0.1459 - val_precision: 0.1958\n",
            "Epoch 360/1000\n",
            " - 2s - loss: 0.6637 - recall: 0.1806 - precision: 0.2420 - val_loss: 0.7753 - val_recall: 0.1615 - val_precision: 0.2107\n",
            "Epoch 361/1000\n",
            " - 2s - loss: 0.6696 - recall: 0.1816 - precision: 0.2384 - val_loss: 0.7740 - val_recall: 0.1571 - val_precision: 0.2051\n",
            "Epoch 362/1000\n",
            " - 2s - loss: 0.6584 - recall: 0.1785 - precision: 0.2414 - val_loss: 0.7826 - val_recall: 0.1603 - val_precision: 0.2128\n",
            "Epoch 363/1000\n",
            " - 2s - loss: 0.6598 - recall: 0.1872 - precision: 0.2511 - val_loss: 0.7689 - val_recall: 0.1581 - val_precision: 0.2086\n",
            "Epoch 364/1000\n",
            " - 2s - loss: 0.6667 - recall: 0.1845 - precision: 0.2434 - val_loss: 0.7715 - val_recall: 0.1697 - val_precision: 0.2251\n",
            "Epoch 365/1000\n",
            " - 2s - loss: 0.6623 - recall: 0.1849 - precision: 0.2451 - val_loss: 0.7634 - val_recall: 0.1576 - val_precision: 0.2051\n",
            "Epoch 366/1000\n",
            " - 2s - loss: 0.6672 - recall: 0.1834 - precision: 0.2409 - val_loss: 0.7721 - val_recall: 0.1701 - val_precision: 0.2196\n",
            "Epoch 367/1000\n",
            " - 2s - loss: 0.6663 - recall: 0.1888 - precision: 0.2456 - val_loss: 0.7728 - val_recall: 0.1568 - val_precision: 0.2037\n",
            "Epoch 368/1000\n",
            " - 2s - loss: 0.6577 - recall: 0.1824 - precision: 0.2399 - val_loss: 0.7736 - val_recall: 0.1563 - val_precision: 0.1995\n",
            "Epoch 369/1000\n",
            " - 2s - loss: 0.6585 - recall: 0.1827 - precision: 0.2451 - val_loss: 0.7769 - val_recall: 0.1652 - val_precision: 0.2168\n",
            "Epoch 370/1000\n",
            " - 2s - loss: 0.6600 - recall: 0.1857 - precision: 0.2457 - val_loss: 0.7750 - val_recall: 0.1635 - val_precision: 0.2148\n",
            "Epoch 371/1000\n",
            " - 2s - loss: 0.6613 - recall: 0.1882 - precision: 0.2472 - val_loss: 0.7752 - val_recall: 0.1603 - val_precision: 0.2045\n",
            "Epoch 372/1000\n",
            " - 2s - loss: 0.6591 - recall: 0.1887 - precision: 0.2482 - val_loss: 0.7704 - val_recall: 0.1501 - val_precision: 0.2023\n",
            "Epoch 373/1000\n",
            " - 2s - loss: 0.6584 - recall: 0.1862 - precision: 0.2437 - val_loss: 0.7868 - val_recall: 0.1620 - val_precision: 0.2079\n",
            "Epoch 374/1000\n",
            " - 2s - loss: 0.6642 - recall: 0.1869 - precision: 0.2524 - val_loss: 0.7726 - val_recall: 0.1509 - val_precision: 0.1978\n",
            "Epoch 375/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1837 - precision: 0.2481 - val_loss: 0.7748 - val_recall: 0.1537 - val_precision: 0.2069\n",
            "Epoch 376/1000\n",
            " - 2s - loss: 0.6635 - recall: 0.1831 - precision: 0.2460 - val_loss: 0.7656 - val_recall: 0.1566 - val_precision: 0.2105\n",
            "Epoch 377/1000\n",
            " - 2s - loss: 0.6557 - recall: 0.1909 - precision: 0.2558 - val_loss: 0.7681 - val_recall: 0.1514 - val_precision: 0.1984\n",
            "Epoch 378/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1845 - precision: 0.2452 - val_loss: 0.7671 - val_recall: 0.1463 - val_precision: 0.1897\n",
            "Epoch 379/1000\n",
            " - 2s - loss: 0.6639 - recall: 0.1900 - precision: 0.2552 - val_loss: 0.7722 - val_recall: 0.1701 - val_precision: 0.2249\n",
            "Epoch 380/1000\n",
            " - 2s - loss: 0.6613 - recall: 0.1873 - precision: 0.2468 - val_loss: 0.7736 - val_recall: 0.1478 - val_precision: 0.1972\n",
            "Epoch 381/1000\n",
            " - 2s - loss: 0.6640 - recall: 0.1837 - precision: 0.2458 - val_loss: 0.7813 - val_recall: 0.1637 - val_precision: 0.2158\n",
            "Epoch 382/1000\n",
            " - 2s - loss: 0.6552 - recall: 0.1915 - precision: 0.2506 - val_loss: 0.7793 - val_recall: 0.1552 - val_precision: 0.2119\n",
            "Epoch 383/1000\n",
            " - 2s - loss: 0.6652 - recall: 0.1806 - precision: 0.2372 - val_loss: 0.7632 - val_recall: 0.1523 - val_precision: 0.1974\n",
            "Epoch 384/1000\n",
            " - 2s - loss: 0.6618 - recall: 0.1907 - precision: 0.2528 - val_loss: 0.7616 - val_recall: 0.1537 - val_precision: 0.2052\n",
            "Epoch 385/1000\n",
            " - 2s - loss: 0.6580 - recall: 0.1859 - precision: 0.2512 - val_loss: 0.7791 - val_recall: 0.1665 - val_precision: 0.2229\n",
            "Epoch 386/1000\n",
            " - 2s - loss: 0.6600 - recall: 0.1833 - precision: 0.2485 - val_loss: 0.7688 - val_recall: 0.1608 - val_precision: 0.2119\n",
            "Epoch 387/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1854 - precision: 0.2436 - val_loss: 0.7714 - val_recall: 0.1711 - val_precision: 0.2266\n",
            "Epoch 388/1000\n",
            " - 2s - loss: 0.6602 - recall: 0.1858 - precision: 0.2440 - val_loss: 0.7731 - val_recall: 0.1511 - val_precision: 0.2018\n",
            "Epoch 389/1000\n",
            " - 2s - loss: 0.6597 - recall: 0.1845 - precision: 0.2479 - val_loss: 0.7636 - val_recall: 0.1688 - val_precision: 0.2195\n",
            "Epoch 390/1000\n",
            " - 2s - loss: 0.6591 - recall: 0.1890 - precision: 0.2514 - val_loss: 0.7831 - val_recall: 0.1653 - val_precision: 0.2161\n",
            "Epoch 391/1000\n",
            " - 2s - loss: 0.6587 - recall: 0.1862 - precision: 0.2503 - val_loss: 0.7692 - val_recall: 0.1546 - val_precision: 0.2099\n",
            "Epoch 392/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1819 - precision: 0.2427 - val_loss: 0.7734 - val_recall: 0.1591 - val_precision: 0.2132\n",
            "Epoch 393/1000\n",
            " - 2s - loss: 0.6597 - recall: 0.1899 - precision: 0.2552 - val_loss: 0.7730 - val_recall: 0.1591 - val_precision: 0.2084\n",
            "Epoch 394/1000\n",
            " - 2s - loss: 0.6594 - recall: 0.1888 - precision: 0.2534 - val_loss: 0.7682 - val_recall: 0.1602 - val_precision: 0.2119\n",
            "Epoch 395/1000\n",
            " - 2s - loss: 0.6598 - recall: 0.1878 - precision: 0.2468 - val_loss: 0.7739 - val_recall: 0.1598 - val_precision: 0.2119\n",
            "Epoch 396/1000\n",
            " - 2s - loss: 0.6635 - recall: 0.1832 - precision: 0.2425 - val_loss: 0.7752 - val_recall: 0.1490 - val_precision: 0.1983\n",
            "Epoch 397/1000\n",
            " - 2s - loss: 0.6579 - recall: 0.1880 - precision: 0.2548 - val_loss: 0.7859 - val_recall: 0.1681 - val_precision: 0.2216\n",
            "Epoch 398/1000\n",
            " - 2s - loss: 0.6577 - recall: 0.1864 - precision: 0.2442 - val_loss: 0.7714 - val_recall: 0.1467 - val_precision: 0.1958\n",
            "Epoch 399/1000\n",
            " - 2s - loss: 0.6576 - recall: 0.1852 - precision: 0.2477 - val_loss: 0.7777 - val_recall: 0.1558 - val_precision: 0.2056\n",
            "Epoch 400/1000\n",
            " - 2s - loss: 0.6581 - recall: 0.1918 - precision: 0.2562 - val_loss: 0.7752 - val_recall: 0.1640 - val_precision: 0.2172\n",
            "Epoch 401/1000\n",
            " - 2s - loss: 0.6640 - recall: 0.1818 - precision: 0.2420 - val_loss: 0.7730 - val_recall: 0.1558 - val_precision: 0.2060\n",
            "Epoch 402/1000\n",
            " - 2s - loss: 0.6521 - recall: 0.1889 - precision: 0.2534 - val_loss: 0.7808 - val_recall: 0.1627 - val_precision: 0.2152\n",
            "Epoch 403/1000\n",
            " - 2s - loss: 0.6576 - recall: 0.1896 - precision: 0.2498 - val_loss: 0.7824 - val_recall: 0.1608 - val_precision: 0.2072\n",
            "Epoch 404/1000\n",
            " - 2s - loss: 0.6616 - recall: 0.1905 - precision: 0.2472 - val_loss: 0.7806 - val_recall: 0.1622 - val_precision: 0.2103\n",
            "Epoch 405/1000\n",
            " - 2s - loss: 0.6600 - recall: 0.1816 - precision: 0.2400 - val_loss: 0.7716 - val_recall: 0.1535 - val_precision: 0.1987\n",
            "Epoch 406/1000\n",
            " - 2s - loss: 0.6635 - recall: 0.1844 - precision: 0.2424 - val_loss: 0.7787 - val_recall: 0.1623 - val_precision: 0.2162\n",
            "Epoch 407/1000\n",
            " - 2s - loss: 0.6568 - recall: 0.1867 - precision: 0.2477 - val_loss: 0.7837 - val_recall: 0.1563 - val_precision: 0.2071\n",
            "Epoch 408/1000\n",
            " - 2s - loss: 0.6606 - recall: 0.1837 - precision: 0.2460 - val_loss: 0.7738 - val_recall: 0.1567 - val_precision: 0.2021\n",
            "Epoch 409/1000\n",
            " - 2s - loss: 0.6641 - recall: 0.1815 - precision: 0.2469 - val_loss: 0.7688 - val_recall: 0.1552 - val_precision: 0.2067\n",
            "Epoch 410/1000\n",
            " - 2s - loss: 0.6639 - recall: 0.1790 - precision: 0.2425 - val_loss: 0.7828 - val_recall: 0.1562 - val_precision: 0.2136\n",
            "Epoch 411/1000\n",
            " - 2s - loss: 0.6554 - recall: 0.1841 - precision: 0.2460 - val_loss: 0.7851 - val_recall: 0.1593 - val_precision: 0.2178\n",
            "Epoch 412/1000\n",
            " - 2s - loss: 0.6637 - recall: 0.1854 - precision: 0.2463 - val_loss: 0.7659 - val_recall: 0.1518 - val_precision: 0.1959\n",
            "Epoch 413/1000\n",
            " - 2s - loss: 0.6600 - recall: 0.1921 - precision: 0.2534 - val_loss: 0.7713 - val_recall: 0.1469 - val_precision: 0.2006\n",
            "Epoch 414/1000\n",
            " - 2s - loss: 0.6654 - recall: 0.1829 - precision: 0.2351 - val_loss: 0.7750 - val_recall: 0.1495 - val_precision: 0.1977\n",
            "Epoch 415/1000\n",
            " - 2s - loss: 0.6570 - recall: 0.1921 - precision: 0.2546 - val_loss: 0.7821 - val_recall: 0.1518 - val_precision: 0.1954\n",
            "Epoch 416/1000\n",
            " - 2s - loss: 0.6545 - recall: 0.1883 - precision: 0.2472 - val_loss: 0.7722 - val_recall: 0.1532 - val_precision: 0.2045\n",
            "Epoch 417/1000\n",
            " - 2s - loss: 0.6594 - recall: 0.1876 - precision: 0.2519 - val_loss: 0.7777 - val_recall: 0.1546 - val_precision: 0.2101\n",
            "Epoch 418/1000\n",
            " - 2s - loss: 0.6677 - recall: 0.1817 - precision: 0.2400 - val_loss: 0.7720 - val_recall: 0.1580 - val_precision: 0.2145\n",
            "Epoch 419/1000\n",
            " - 2s - loss: 0.6588 - recall: 0.1842 - precision: 0.2449 - val_loss: 0.7752 - val_recall: 0.1496 - val_precision: 0.1987\n",
            "Epoch 420/1000\n",
            " - 2s - loss: 0.6637 - recall: 0.1867 - precision: 0.2513 - val_loss: 0.7764 - val_recall: 0.1592 - val_precision: 0.2092\n",
            "Epoch 421/1000\n",
            " - 2s - loss: 0.6609 - recall: 0.1810 - precision: 0.2419 - val_loss: 0.7745 - val_recall: 0.1658 - val_precision: 0.2149\n",
            "Epoch 422/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1865 - precision: 0.2500 - val_loss: 0.7737 - val_recall: 0.1639 - val_precision: 0.2213\n",
            "Epoch 423/1000\n",
            " - 2s - loss: 0.6589 - recall: 0.1879 - precision: 0.2511 - val_loss: 0.7799 - val_recall: 0.1599 - val_precision: 0.2158\n",
            "Epoch 424/1000\n",
            " - 2s - loss: 0.6565 - recall: 0.1878 - precision: 0.2497 - val_loss: 0.7773 - val_recall: 0.1569 - val_precision: 0.1996\n",
            "Epoch 425/1000\n",
            " - 2s - loss: 0.6582 - recall: 0.1864 - precision: 0.2496 - val_loss: 0.7843 - val_recall: 0.1533 - val_precision: 0.2056\n",
            "Epoch 426/1000\n",
            " - 2s - loss: 0.6573 - recall: 0.1846 - precision: 0.2478 - val_loss: 0.7805 - val_recall: 0.1558 - val_precision: 0.2080\n",
            "Epoch 427/1000\n",
            " - 2s - loss: 0.6586 - recall: 0.1872 - precision: 0.2472 - val_loss: 0.7790 - val_recall: 0.1600 - val_precision: 0.2075\n",
            "Epoch 428/1000\n",
            " - 2s - loss: 0.6592 - recall: 0.1917 - precision: 0.2509 - val_loss: 0.7779 - val_recall: 0.1510 - val_precision: 0.2051\n",
            "Epoch 429/1000\n",
            " - 2s - loss: 0.6589 - recall: 0.1859 - precision: 0.2442 - val_loss: 0.7843 - val_recall: 0.1683 - val_precision: 0.2278\n",
            "Epoch 430/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1904 - precision: 0.2604 - val_loss: 0.7808 - val_recall: 0.1546 - val_precision: 0.2086\n",
            "Epoch 431/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1846 - precision: 0.2433 - val_loss: 0.7866 - val_recall: 0.1563 - val_precision: 0.2058\n",
            "Epoch 432/1000\n",
            " - 2s - loss: 0.6569 - recall: 0.1880 - precision: 0.2528 - val_loss: 0.7858 - val_recall: 0.1610 - val_precision: 0.2110\n",
            "Epoch 433/1000\n",
            " - 2s - loss: 0.6601 - recall: 0.1933 - precision: 0.2485 - val_loss: 0.7842 - val_recall: 0.1625 - val_precision: 0.2195\n",
            "Epoch 434/1000\n",
            " - 2s - loss: 0.6602 - recall: 0.1902 - precision: 0.2511 - val_loss: 0.7700 - val_recall: 0.1571 - val_precision: 0.2056\n",
            "Epoch 435/1000\n",
            " - 2s - loss: 0.6520 - recall: 0.1871 - precision: 0.2470 - val_loss: 0.7780 - val_recall: 0.1557 - val_precision: 0.2079\n",
            "Epoch 436/1000\n",
            " - 2s - loss: 0.6619 - recall: 0.1855 - precision: 0.2474 - val_loss: 0.7746 - val_recall: 0.1584 - val_precision: 0.2062\n",
            "Epoch 437/1000\n",
            " - 2s - loss: 0.6557 - recall: 0.1903 - precision: 0.2545 - val_loss: 0.7761 - val_recall: 0.1564 - val_precision: 0.2052\n",
            "Epoch 438/1000\n",
            " - 2s - loss: 0.6554 - recall: 0.1852 - precision: 0.2466 - val_loss: 0.7889 - val_recall: 0.1590 - val_precision: 0.2198\n",
            "Epoch 439/1000\n",
            " - 2s - loss: 0.6631 - recall: 0.1870 - precision: 0.2499 - val_loss: 0.7721 - val_recall: 0.1522 - val_precision: 0.2108\n",
            "Epoch 440/1000\n",
            " - 2s - loss: 0.6572 - recall: 0.1799 - precision: 0.2440 - val_loss: 0.7762 - val_recall: 0.1572 - val_precision: 0.2091\n",
            "Epoch 441/1000\n",
            " - 2s - loss: 0.6646 - recall: 0.1847 - precision: 0.2472 - val_loss: 0.7744 - val_recall: 0.1531 - val_precision: 0.2098\n",
            "Epoch 442/1000\n",
            " - 2s - loss: 0.6595 - recall: 0.1843 - precision: 0.2408 - val_loss: 0.7801 - val_recall: 0.1603 - val_precision: 0.2108\n",
            "Epoch 443/1000\n",
            " - 2s - loss: 0.6579 - recall: 0.1862 - precision: 0.2444 - val_loss: 0.7732 - val_recall: 0.1566 - val_precision: 0.2142\n",
            "Epoch 444/1000\n",
            " - 2s - loss: 0.6593 - recall: 0.1861 - precision: 0.2415 - val_loss: 0.7812 - val_recall: 0.1573 - val_precision: 0.2145\n",
            "Epoch 445/1000\n",
            " - 2s - loss: 0.6597 - recall: 0.1857 - precision: 0.2438 - val_loss: 0.7715 - val_recall: 0.1505 - val_precision: 0.2022\n",
            "Epoch 446/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1864 - precision: 0.2502 - val_loss: 0.7794 - val_recall: 0.1544 - val_precision: 0.2005\n",
            "Epoch 447/1000\n",
            " - 2s - loss: 0.6598 - recall: 0.1865 - precision: 0.2457 - val_loss: 0.7815 - val_recall: 0.1649 - val_precision: 0.2145\n",
            "Epoch 448/1000\n",
            " - 2s - loss: 0.6588 - recall: 0.1850 - precision: 0.2430 - val_loss: 0.7787 - val_recall: 0.1569 - val_precision: 0.2108\n",
            "Epoch 449/1000\n",
            " - 2s - loss: 0.6559 - recall: 0.1876 - precision: 0.2525 - val_loss: 0.7816 - val_recall: 0.1619 - val_precision: 0.2092\n",
            "Epoch 450/1000\n",
            " - 2s - loss: 0.6591 - recall: 0.1871 - precision: 0.2520 - val_loss: 0.7783 - val_recall: 0.1594 - val_precision: 0.2060\n",
            "Epoch 451/1000\n",
            " - 2s - loss: 0.6522 - recall: 0.1931 - precision: 0.2563 - val_loss: 0.7891 - val_recall: 0.1696 - val_precision: 0.2215\n",
            "Epoch 452/1000\n",
            " - 2s - loss: 0.6607 - recall: 0.1898 - precision: 0.2531 - val_loss: 0.7741 - val_recall: 0.1564 - val_precision: 0.2034\n",
            "Epoch 453/1000\n",
            " - 2s - loss: 0.6554 - recall: 0.1862 - precision: 0.2477 - val_loss: 0.7764 - val_recall: 0.1613 - val_precision: 0.2101\n",
            "Epoch 454/1000\n",
            " - 2s - loss: 0.6600 - recall: 0.1841 - precision: 0.2468 - val_loss: 0.7792 - val_recall: 0.1672 - val_precision: 0.2213\n",
            "Epoch 455/1000\n",
            " - 2s - loss: 0.6613 - recall: 0.1854 - precision: 0.2464 - val_loss: 0.7760 - val_recall: 0.1523 - val_precision: 0.2015\n",
            "Epoch 456/1000\n",
            " - 2s - loss: 0.6577 - recall: 0.1891 - precision: 0.2532 - val_loss: 0.7933 - val_recall: 0.1524 - val_precision: 0.1996\n",
            "Epoch 457/1000\n",
            " - 2s - loss: 0.6604 - recall: 0.1879 - precision: 0.2475 - val_loss: 0.7783 - val_recall: 0.1485 - val_precision: 0.1992\n",
            "Epoch 458/1000\n",
            " - 2s - loss: 0.6532 - recall: 0.1874 - precision: 0.2559 - val_loss: 0.7878 - val_recall: 0.1508 - val_precision: 0.2051\n",
            "Epoch 459/1000\n",
            " - 2s - loss: 0.6548 - recall: 0.1803 - precision: 0.2402 - val_loss: 0.7790 - val_recall: 0.1588 - val_precision: 0.2042\n",
            "Epoch 460/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1935 - precision: 0.2527 - val_loss: 0.7845 - val_recall: 0.1590 - val_precision: 0.2059\n",
            "Epoch 461/1000\n",
            " - 2s - loss: 0.6553 - recall: 0.1904 - precision: 0.2533 - val_loss: 0.7946 - val_recall: 0.1628 - val_precision: 0.2078\n",
            "Epoch 462/1000\n",
            " - 2s - loss: 0.6577 - recall: 0.1882 - precision: 0.2453 - val_loss: 0.7802 - val_recall: 0.1605 - val_precision: 0.2121\n",
            "Epoch 463/1000\n",
            " - 2s - loss: 0.6533 - recall: 0.1847 - precision: 0.2508 - val_loss: 0.7748 - val_recall: 0.1654 - val_precision: 0.2085\n",
            "Epoch 464/1000\n",
            " - 2s - loss: 0.6579 - recall: 0.1875 - precision: 0.2481 - val_loss: 0.7732 - val_recall: 0.1588 - val_precision: 0.2085\n",
            "Epoch 465/1000\n",
            " - 2s - loss: 0.6606 - recall: 0.1813 - precision: 0.2411 - val_loss: 0.7867 - val_recall: 0.1665 - val_precision: 0.2068\n",
            "Epoch 466/1000\n",
            " - 2s - loss: 0.6560 - recall: 0.1864 - precision: 0.2426 - val_loss: 0.7837 - val_recall: 0.1691 - val_precision: 0.2165\n",
            "Epoch 467/1000\n",
            " - 2s - loss: 0.6538 - recall: 0.1905 - precision: 0.2538 - val_loss: 0.7743 - val_recall: 0.1549 - val_precision: 0.2044\n",
            "Epoch 468/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1864 - precision: 0.2454 - val_loss: 0.7801 - val_recall: 0.1694 - val_precision: 0.2152\n",
            "Epoch 469/1000\n",
            " - 2s - loss: 0.6564 - recall: 0.1854 - precision: 0.2452 - val_loss: 0.7756 - val_recall: 0.1546 - val_precision: 0.2039\n",
            "Epoch 470/1000\n",
            " - 2s - loss: 0.6568 - recall: 0.1838 - precision: 0.2449 - val_loss: 0.7718 - val_recall: 0.1598 - val_precision: 0.2096\n",
            "Epoch 471/1000\n",
            " - 2s - loss: 0.6557 - recall: 0.1842 - precision: 0.2503 - val_loss: 0.7801 - val_recall: 0.1540 - val_precision: 0.2081\n",
            "Epoch 472/1000\n",
            " - 2s - loss: 0.6534 - recall: 0.1881 - precision: 0.2521 - val_loss: 0.7840 - val_recall: 0.1634 - val_precision: 0.2051\n",
            "Epoch 473/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1857 - precision: 0.2422 - val_loss: 0.7851 - val_recall: 0.1652 - val_precision: 0.2136\n",
            "Epoch 474/1000\n",
            " - 2s - loss: 0.6585 - recall: 0.1842 - precision: 0.2516 - val_loss: 0.7774 - val_recall: 0.1538 - val_precision: 0.2086\n",
            "Epoch 475/1000\n",
            " - 2s - loss: 0.6603 - recall: 0.1877 - precision: 0.2455 - val_loss: 0.7723 - val_recall: 0.1559 - val_precision: 0.2079\n",
            "Epoch 476/1000\n",
            " - 2s - loss: 0.6547 - recall: 0.1853 - precision: 0.2374 - val_loss: 0.7771 - val_recall: 0.1539 - val_precision: 0.2000\n",
            "Epoch 477/1000\n",
            " - 2s - loss: 0.6603 - recall: 0.1881 - precision: 0.2542 - val_loss: 0.7812 - val_recall: 0.1523 - val_precision: 0.2037\n",
            "Epoch 478/1000\n",
            " - 2s - loss: 0.6568 - recall: 0.1960 - precision: 0.2603 - val_loss: 0.7731 - val_recall: 0.1570 - val_precision: 0.2132\n",
            "Epoch 479/1000\n",
            " - 2s - loss: 0.6547 - recall: 0.1857 - precision: 0.2443 - val_loss: 0.7855 - val_recall: 0.1482 - val_precision: 0.2012\n",
            "Epoch 480/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1838 - precision: 0.2467 - val_loss: 0.7628 - val_recall: 0.1596 - val_precision: 0.2094\n",
            "Epoch 481/1000\n",
            " - 2s - loss: 0.6559 - recall: 0.1928 - precision: 0.2579 - val_loss: 0.7702 - val_recall: 0.1593 - val_precision: 0.2099\n",
            "Epoch 482/1000\n",
            " - 2s - loss: 0.6579 - recall: 0.1866 - precision: 0.2509 - val_loss: 0.7839 - val_recall: 0.1615 - val_precision: 0.2103\n",
            "Epoch 483/1000\n",
            " - 2s - loss: 0.6524 - recall: 0.1844 - precision: 0.2415 - val_loss: 0.7763 - val_recall: 0.1522 - val_precision: 0.1968\n",
            "Epoch 484/1000\n",
            " - 2s - loss: 0.6601 - recall: 0.1900 - precision: 0.2500 - val_loss: 0.7820 - val_recall: 0.1611 - val_precision: 0.2085\n",
            "Epoch 485/1000\n",
            " - 2s - loss: 0.6539 - recall: 0.1870 - precision: 0.2535 - val_loss: 0.7697 - val_recall: 0.1543 - val_precision: 0.2065\n",
            "Epoch 486/1000\n",
            " - 2s - loss: 0.6523 - recall: 0.1956 - precision: 0.2534 - val_loss: 0.7784 - val_recall: 0.1484 - val_precision: 0.1970\n",
            "Epoch 487/1000\n",
            " - 2s - loss: 0.6573 - recall: 0.1876 - precision: 0.2487 - val_loss: 0.7785 - val_recall: 0.1621 - val_precision: 0.2126\n",
            "Epoch 488/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1913 - precision: 0.2536 - val_loss: 0.7819 - val_recall: 0.1584 - val_precision: 0.2116\n",
            "Epoch 489/1000\n",
            " - 2s - loss: 0.6529 - recall: 0.1889 - precision: 0.2512 - val_loss: 0.7852 - val_recall: 0.1579 - val_precision: 0.2078\n",
            "Epoch 490/1000\n",
            " - 2s - loss: 0.6560 - recall: 0.1883 - precision: 0.2448 - val_loss: 0.7776 - val_recall: 0.1618 - val_precision: 0.2178\n",
            "Epoch 491/1000\n",
            " - 2s - loss: 0.6563 - recall: 0.1913 - precision: 0.2579 - val_loss: 0.7827 - val_recall: 0.1618 - val_precision: 0.2191\n",
            "Epoch 492/1000\n",
            " - 2s - loss: 0.6554 - recall: 0.1906 - precision: 0.2550 - val_loss: 0.7826 - val_recall: 0.1598 - val_precision: 0.2097\n",
            "Epoch 493/1000\n",
            " - 2s - loss: 0.6604 - recall: 0.1861 - precision: 0.2439 - val_loss: 0.7715 - val_recall: 0.1606 - val_precision: 0.2136\n",
            "Epoch 494/1000\n",
            " - 2s - loss: 0.6604 - recall: 0.1843 - precision: 0.2430 - val_loss: 0.7809 - val_recall: 0.1534 - val_precision: 0.2017\n",
            "Epoch 495/1000\n",
            " - 2s - loss: 0.6592 - recall: 0.1851 - precision: 0.2436 - val_loss: 0.7786 - val_recall: 0.1593 - val_precision: 0.2071\n",
            "Epoch 496/1000\n",
            " - 2s - loss: 0.6543 - recall: 0.1876 - precision: 0.2504 - val_loss: 0.7911 - val_recall: 0.1572 - val_precision: 0.2016\n",
            "Epoch 497/1000\n",
            " - 2s - loss: 0.6592 - recall: 0.1895 - precision: 0.2503 - val_loss: 0.7876 - val_recall: 0.1663 - val_precision: 0.2090\n",
            "Epoch 498/1000\n",
            " - 2s - loss: 0.6556 - recall: 0.1851 - precision: 0.2398 - val_loss: 0.7888 - val_recall: 0.1540 - val_precision: 0.2038\n",
            "Epoch 499/1000\n",
            " - 2s - loss: 0.6532 - recall: 0.1898 - precision: 0.2524 - val_loss: 0.7900 - val_recall: 0.1555 - val_precision: 0.2023\n",
            "Epoch 500/1000\n",
            " - 2s - loss: 0.6538 - recall: 0.1871 - precision: 0.2537 - val_loss: 0.7950 - val_recall: 0.1676 - val_precision: 0.2196\n",
            "Epoch 501/1000\n",
            " - 2s - loss: 0.6576 - recall: 0.1897 - precision: 0.2460 - val_loss: 0.7776 - val_recall: 0.1555 - val_precision: 0.2069\n",
            "Epoch 502/1000\n",
            " - 2s - loss: 0.6541 - recall: 0.1868 - precision: 0.2471 - val_loss: 0.7840 - val_recall: 0.1514 - val_precision: 0.2035\n",
            "Epoch 503/1000\n",
            " - 2s - loss: 0.6545 - recall: 0.1909 - precision: 0.2576 - val_loss: 0.7871 - val_recall: 0.1638 - val_precision: 0.2163\n",
            "Epoch 504/1000\n",
            " - 2s - loss: 0.6533 - recall: 0.1893 - precision: 0.2473 - val_loss: 0.7866 - val_recall: 0.1559 - val_precision: 0.2029\n",
            "Epoch 505/1000\n",
            " - 2s - loss: 0.6545 - recall: 0.1932 - precision: 0.2592 - val_loss: 0.7942 - val_recall: 0.1608 - val_precision: 0.2078\n",
            "Epoch 506/1000\n",
            " - 2s - loss: 0.6657 - recall: 0.1910 - precision: 0.2484 - val_loss: 0.7855 - val_recall: 0.1612 - val_precision: 0.2146\n",
            "Epoch 507/1000\n",
            " - 2s - loss: 0.6639 - recall: 0.1900 - precision: 0.2467 - val_loss: 0.7909 - val_recall: 0.1574 - val_precision: 0.2102\n",
            "Epoch 508/1000\n",
            " - 2s - loss: 0.6590 - recall: 0.1872 - precision: 0.2466 - val_loss: 0.7818 - val_recall: 0.1538 - val_precision: 0.2054\n",
            "Epoch 509/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1862 - precision: 0.2458 - val_loss: 0.7896 - val_recall: 0.1598 - val_precision: 0.2129\n",
            "Epoch 510/1000\n",
            " - 2s - loss: 0.6494 - recall: 0.1890 - precision: 0.2483 - val_loss: 0.7939 - val_recall: 0.1570 - val_precision: 0.2063\n",
            "Epoch 511/1000\n",
            " - 2s - loss: 0.6561 - recall: 0.1903 - precision: 0.2578 - val_loss: 0.7910 - val_recall: 0.1608 - val_precision: 0.2087\n",
            "Epoch 512/1000\n",
            " - 2s - loss: 0.6505 - recall: 0.1879 - precision: 0.2506 - val_loss: 0.7766 - val_recall: 0.1548 - val_precision: 0.2101\n",
            "Epoch 513/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1885 - precision: 0.2571 - val_loss: 0.7862 - val_recall: 0.1626 - val_precision: 0.2169\n",
            "Epoch 514/1000\n",
            " - 2s - loss: 0.6612 - recall: 0.1883 - precision: 0.2464 - val_loss: 0.7840 - val_recall: 0.1602 - val_precision: 0.2093\n",
            "Epoch 515/1000\n",
            " - 2s - loss: 0.6495 - recall: 0.1870 - precision: 0.2520 - val_loss: 0.7928 - val_recall: 0.1551 - val_precision: 0.2053\n",
            "Epoch 516/1000\n",
            " - 2s - loss: 0.6614 - recall: 0.1850 - precision: 0.2421 - val_loss: 0.7803 - val_recall: 0.1525 - val_precision: 0.2019\n",
            "Epoch 517/1000\n",
            " - 2s - loss: 0.6544 - recall: 0.1909 - precision: 0.2555 - val_loss: 0.7833 - val_recall: 0.1654 - val_precision: 0.2145\n",
            "Epoch 518/1000\n",
            " - 2s - loss: 0.6572 - recall: 0.1907 - precision: 0.2555 - val_loss: 0.7692 - val_recall: 0.1554 - val_precision: 0.2011\n",
            "Epoch 519/1000\n",
            " - 2s - loss: 0.6531 - recall: 0.1818 - precision: 0.2430 - val_loss: 0.7807 - val_recall: 0.1591 - val_precision: 0.2180\n",
            "Epoch 520/1000\n",
            " - 2s - loss: 0.6542 - recall: 0.1918 - precision: 0.2577 - val_loss: 0.7912 - val_recall: 0.1594 - val_precision: 0.2044\n",
            "Epoch 521/1000\n",
            " - 2s - loss: 0.6513 - recall: 0.1857 - precision: 0.2498 - val_loss: 0.7825 - val_recall: 0.1610 - val_precision: 0.2142\n",
            "Epoch 522/1000\n",
            " - 2s - loss: 0.6596 - recall: 0.1854 - precision: 0.2463 - val_loss: 0.7909 - val_recall: 0.1514 - val_precision: 0.1971\n",
            "Epoch 523/1000\n",
            " - 2s - loss: 0.6595 - recall: 0.1841 - precision: 0.2417 - val_loss: 0.7849 - val_recall: 0.1583 - val_precision: 0.2019\n",
            "Epoch 524/1000\n",
            " - 2s - loss: 0.6523 - recall: 0.1960 - precision: 0.2610 - val_loss: 0.7860 - val_recall: 0.1631 - val_precision: 0.2158\n",
            "Epoch 525/1000\n",
            " - 2s - loss: 0.6551 - recall: 0.1966 - precision: 0.2623 - val_loss: 0.8036 - val_recall: 0.1574 - val_precision: 0.2079\n",
            "Epoch 526/1000\n",
            " - 2s - loss: 0.6560 - recall: 0.1916 - precision: 0.2547 - val_loss: 0.7882 - val_recall: 0.1555 - val_precision: 0.2016\n",
            "Epoch 527/1000\n",
            " - 2s - loss: 0.6522 - recall: 0.1863 - precision: 0.2487 - val_loss: 0.7969 - val_recall: 0.1650 - val_precision: 0.2114\n",
            "Epoch 528/1000\n",
            " - 2s - loss: 0.6545 - recall: 0.1870 - precision: 0.2498 - val_loss: 0.7757 - val_recall: 0.1679 - val_precision: 0.2111\n",
            "Epoch 529/1000\n",
            " - 2s - loss: 0.6568 - recall: 0.1895 - precision: 0.2483 - val_loss: 0.7895 - val_recall: 0.1631 - val_precision: 0.2158\n",
            "Epoch 530/1000\n",
            " - 2s - loss: 0.6622 - recall: 0.1867 - precision: 0.2506 - val_loss: 0.7934 - val_recall: 0.1526 - val_precision: 0.1950\n",
            "Epoch 531/1000\n",
            " - 2s - loss: 0.6558 - recall: 0.1858 - precision: 0.2467 - val_loss: 0.7824 - val_recall: 0.1545 - val_precision: 0.2097\n",
            "Epoch 532/1000\n",
            " - 2s - loss: 0.6539 - recall: 0.1884 - precision: 0.2554 - val_loss: 0.7824 - val_recall: 0.1508 - val_precision: 0.2092\n",
            "Epoch 533/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1877 - precision: 0.2432 - val_loss: 0.7816 - val_recall: 0.1591 - val_precision: 0.2180\n",
            "Epoch 534/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1855 - precision: 0.2470 - val_loss: 0.8054 - val_recall: 0.1557 - val_precision: 0.2098\n",
            "Epoch 535/1000\n",
            " - 2s - loss: 0.6602 - recall: 0.1872 - precision: 0.2485 - val_loss: 0.7778 - val_recall: 0.1610 - val_precision: 0.2036\n",
            "Epoch 536/1000\n",
            " - 2s - loss: 0.6534 - recall: 0.1863 - precision: 0.2456 - val_loss: 0.7921 - val_recall: 0.1533 - val_precision: 0.1992\n",
            "Epoch 537/1000\n",
            " - 2s - loss: 0.6550 - recall: 0.1881 - precision: 0.2520 - val_loss: 0.7867 - val_recall: 0.1578 - val_precision: 0.2034\n",
            "Epoch 538/1000\n",
            " - 2s - loss: 0.6581 - recall: 0.1861 - precision: 0.2460 - val_loss: 0.7803 - val_recall: 0.1622 - val_precision: 0.2112\n",
            "Epoch 539/1000\n",
            " - 2s - loss: 0.6537 - recall: 0.1917 - precision: 0.2553 - val_loss: 0.7743 - val_recall: 0.1591 - val_precision: 0.2068\n",
            "Epoch 540/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1855 - precision: 0.2491 - val_loss: 0.7944 - val_recall: 0.1614 - val_precision: 0.2212\n",
            "Epoch 541/1000\n",
            " - 2s - loss: 0.6539 - recall: 0.1872 - precision: 0.2510 - val_loss: 0.7839 - val_recall: 0.1519 - val_precision: 0.2006\n",
            "Epoch 542/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1908 - precision: 0.2563 - val_loss: 0.7854 - val_recall: 0.1573 - val_precision: 0.2072\n",
            "Epoch 543/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1956 - precision: 0.2600 - val_loss: 0.7920 - val_recall: 0.1636 - val_precision: 0.2078\n",
            "Epoch 544/1000\n",
            " - 2s - loss: 0.6559 - recall: 0.1976 - precision: 0.2619 - val_loss: 0.7868 - val_recall: 0.1502 - val_precision: 0.1950\n",
            "Epoch 545/1000\n",
            " - 2s - loss: 0.6515 - recall: 0.1856 - precision: 0.2472 - val_loss: 0.7906 - val_recall: 0.1586 - val_precision: 0.2098\n",
            "Epoch 546/1000\n",
            " - 2s - loss: 0.6524 - recall: 0.1916 - precision: 0.2514 - val_loss: 0.7789 - val_recall: 0.1541 - val_precision: 0.2063\n",
            "Epoch 547/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1904 - precision: 0.2502 - val_loss: 0.7891 - val_recall: 0.1555 - val_precision: 0.2044\n",
            "Epoch 548/1000\n",
            " - 2s - loss: 0.6552 - recall: 0.1929 - precision: 0.2515 - val_loss: 0.7935 - val_recall: 0.1572 - val_precision: 0.2026\n",
            "Epoch 549/1000\n",
            " - 2s - loss: 0.6561 - recall: 0.1886 - precision: 0.2520 - val_loss: 0.7880 - val_recall: 0.1537 - val_precision: 0.2061\n",
            "Epoch 550/1000\n",
            " - 2s - loss: 0.6555 - recall: 0.1882 - precision: 0.2476 - val_loss: 0.7890 - val_recall: 0.1477 - val_precision: 0.2035\n",
            "Epoch 551/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1931 - precision: 0.2605 - val_loss: 0.7833 - val_recall: 0.1570 - val_precision: 0.2140\n",
            "Epoch 552/1000\n",
            " - 2s - loss: 0.6531 - recall: 0.1859 - precision: 0.2532 - val_loss: 0.7867 - val_recall: 0.1596 - val_precision: 0.2047\n",
            "Epoch 553/1000\n",
            " - 2s - loss: 0.6507 - recall: 0.1926 - precision: 0.2546 - val_loss: 0.7877 - val_recall: 0.1514 - val_precision: 0.2005\n",
            "Epoch 554/1000\n",
            " - 2s - loss: 0.6542 - recall: 0.1866 - precision: 0.2472 - val_loss: 0.7883 - val_recall: 0.1608 - val_precision: 0.2088\n",
            "Epoch 555/1000\n",
            " - 2s - loss: 0.6504 - recall: 0.1875 - precision: 0.2453 - val_loss: 0.7864 - val_recall: 0.1514 - val_precision: 0.1967\n",
            "Epoch 556/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1817 - precision: 0.2480 - val_loss: 0.7800 - val_recall: 0.1604 - val_precision: 0.2143\n",
            "Epoch 557/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1885 - precision: 0.2497 - val_loss: 0.7832 - val_recall: 0.1565 - val_precision: 0.2077\n",
            "Epoch 558/1000\n",
            " - 2s - loss: 0.6536 - recall: 0.1908 - precision: 0.2492 - val_loss: 0.7721 - val_recall: 0.1583 - val_precision: 0.2069\n",
            "Epoch 559/1000\n",
            " - 2s - loss: 0.6514 - recall: 0.1897 - precision: 0.2538 - val_loss: 0.7777 - val_recall: 0.1621 - val_precision: 0.2170\n",
            "Epoch 560/1000\n",
            " - 2s - loss: 0.6482 - recall: 0.1898 - precision: 0.2496 - val_loss: 0.7869 - val_recall: 0.1612 - val_precision: 0.2120\n",
            "Epoch 561/1000\n",
            " - 2s - loss: 0.6535 - recall: 0.1925 - precision: 0.2549 - val_loss: 0.7850 - val_recall: 0.1536 - val_precision: 0.2037\n",
            "Epoch 562/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1915 - precision: 0.2556 - val_loss: 0.7804 - val_recall: 0.1558 - val_precision: 0.2120\n",
            "Epoch 563/1000\n",
            " - 2s - loss: 0.6544 - recall: 0.1873 - precision: 0.2519 - val_loss: 0.7885 - val_recall: 0.1623 - val_precision: 0.2140\n",
            "Epoch 564/1000\n",
            " - 2s - loss: 0.6515 - recall: 0.1913 - precision: 0.2500 - val_loss: 0.7912 - val_recall: 0.1601 - val_precision: 0.2134\n",
            "Epoch 565/1000\n",
            " - 2s - loss: 0.6570 - recall: 0.1884 - precision: 0.2534 - val_loss: 0.7797 - val_recall: 0.1587 - val_precision: 0.2140\n",
            "Epoch 566/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1897 - precision: 0.2535 - val_loss: 0.7886 - val_recall: 0.1588 - val_precision: 0.2105\n",
            "Epoch 567/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1901 - precision: 0.2464 - val_loss: 0.7809 - val_recall: 0.1548 - val_precision: 0.2031\n",
            "Epoch 568/1000\n",
            " - 2s - loss: 0.6576 - recall: 0.1947 - precision: 0.2597 - val_loss: 0.7899 - val_recall: 0.1488 - val_precision: 0.1906\n",
            "Epoch 569/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1852 - precision: 0.2449 - val_loss: 0.7993 - val_recall: 0.1579 - val_precision: 0.2059\n",
            "Epoch 570/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1849 - precision: 0.2458 - val_loss: 0.7920 - val_recall: 0.1581 - val_precision: 0.1996\n",
            "Epoch 571/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1900 - precision: 0.2553 - val_loss: 0.7879 - val_recall: 0.1623 - val_precision: 0.2109\n",
            "Epoch 572/1000\n",
            " - 2s - loss: 0.6592 - recall: 0.1856 - precision: 0.2420 - val_loss: 0.7787 - val_recall: 0.1560 - val_precision: 0.2040\n",
            "Epoch 573/1000\n",
            " - 2s - loss: 0.6521 - recall: 0.1920 - precision: 0.2593 - val_loss: 0.7939 - val_recall: 0.1560 - val_precision: 0.2086\n",
            "Epoch 574/1000\n",
            " - 2s - loss: 0.6515 - recall: 0.1940 - precision: 0.2552 - val_loss: 0.7940 - val_recall: 0.1636 - val_precision: 0.2114\n",
            "Epoch 575/1000\n",
            " - 2s - loss: 0.6496 - recall: 0.1896 - precision: 0.2509 - val_loss: 0.7835 - val_recall: 0.1556 - val_precision: 0.2023\n",
            "Epoch 576/1000\n",
            " - 2s - loss: 0.6601 - recall: 0.1895 - precision: 0.2534 - val_loss: 0.7855 - val_recall: 0.1558 - val_precision: 0.2046\n",
            "Epoch 577/1000\n",
            " - 2s - loss: 0.6550 - recall: 0.1960 - precision: 0.2602 - val_loss: 0.7911 - val_recall: 0.1609 - val_precision: 0.2133\n",
            "Epoch 578/1000\n",
            " - 2s - loss: 0.6513 - recall: 0.1946 - precision: 0.2604 - val_loss: 0.7968 - val_recall: 0.1569 - val_precision: 0.2061\n",
            "Epoch 579/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1947 - precision: 0.2589 - val_loss: 0.7838 - val_recall: 0.1532 - val_precision: 0.1970\n",
            "Epoch 580/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.2024 - precision: 0.2633 - val_loss: 0.7906 - val_recall: 0.1592 - val_precision: 0.2136\n",
            "Epoch 581/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1894 - precision: 0.2605 - val_loss: 0.7982 - val_recall: 0.1602 - val_precision: 0.2111\n",
            "Epoch 582/1000\n",
            " - 2s - loss: 0.6561 - recall: 0.1924 - precision: 0.2569 - val_loss: 0.7991 - val_recall: 0.1605 - val_precision: 0.2057\n",
            "Epoch 583/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1810 - precision: 0.2417 - val_loss: 0.7862 - val_recall: 0.1611 - val_precision: 0.2070\n",
            "Epoch 584/1000\n",
            " - 2s - loss: 0.6509 - recall: 0.1854 - precision: 0.2520 - val_loss: 0.8094 - val_recall: 0.1631 - val_precision: 0.2173\n",
            "Epoch 585/1000\n",
            " - 2s - loss: 0.6585 - recall: 0.1897 - precision: 0.2485 - val_loss: 0.7922 - val_recall: 0.1569 - val_precision: 0.2074\n",
            "Epoch 586/1000\n",
            " - 2s - loss: 0.6553 - recall: 0.1865 - precision: 0.2472 - val_loss: 0.7878 - val_recall: 0.1581 - val_precision: 0.2058\n",
            "Epoch 587/1000\n",
            " - 2s - loss: 0.6528 - recall: 0.1841 - precision: 0.2423 - val_loss: 0.7870 - val_recall: 0.1534 - val_precision: 0.1966\n",
            "Epoch 588/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.1947 - precision: 0.2553 - val_loss: 0.7828 - val_recall: 0.1605 - val_precision: 0.2083\n",
            "Epoch 589/1000\n",
            " - 2s - loss: 0.6490 - recall: 0.1949 - precision: 0.2586 - val_loss: 0.7999 - val_recall: 0.1579 - val_precision: 0.2036\n",
            "Epoch 590/1000\n",
            " - 2s - loss: 0.6531 - recall: 0.1927 - precision: 0.2535 - val_loss: 0.7872 - val_recall: 0.1584 - val_precision: 0.2093\n",
            "Epoch 591/1000\n",
            " - 2s - loss: 0.6505 - recall: 0.1972 - precision: 0.2577 - val_loss: 0.7879 - val_recall: 0.1536 - val_precision: 0.2096\n",
            "Epoch 592/1000\n",
            " - 2s - loss: 0.6593 - recall: 0.1816 - precision: 0.2385 - val_loss: 0.7827 - val_recall: 0.1491 - val_precision: 0.1979\n",
            "Epoch 593/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1922 - precision: 0.2596 - val_loss: 0.7904 - val_recall: 0.1537 - val_precision: 0.2099\n",
            "Epoch 594/1000\n",
            " - 2s - loss: 0.6570 - recall: 0.1912 - precision: 0.2554 - val_loss: 0.7852 - val_recall: 0.1528 - val_precision: 0.2092\n",
            "Epoch 595/1000\n",
            " - 2s - loss: 0.6513 - recall: 0.1892 - precision: 0.2482 - val_loss: 0.7879 - val_recall: 0.1587 - val_precision: 0.2065\n",
            "Epoch 596/1000\n",
            " - 2s - loss: 0.6538 - recall: 0.1888 - precision: 0.2453 - val_loss: 0.7919 - val_recall: 0.1479 - val_precision: 0.1887\n",
            "Epoch 597/1000\n",
            " - 2s - loss: 0.6547 - recall: 0.1881 - precision: 0.2528 - val_loss: 0.7765 - val_recall: 0.1615 - val_precision: 0.2106\n",
            "Epoch 598/1000\n",
            " - 2s - loss: 0.6552 - recall: 0.1883 - precision: 0.2493 - val_loss: 0.7881 - val_recall: 0.1552 - val_precision: 0.2035\n",
            "Epoch 599/1000\n",
            " - 2s - loss: 0.6513 - recall: 0.1887 - precision: 0.2470 - val_loss: 0.7874 - val_recall: 0.1641 - val_precision: 0.2097\n",
            "Epoch 600/1000\n",
            " - 2s - loss: 0.6518 - recall: 0.1921 - precision: 0.2534 - val_loss: 0.7856 - val_recall: 0.1582 - val_precision: 0.2048\n",
            "Epoch 601/1000\n",
            " - 2s - loss: 0.6539 - recall: 0.1867 - precision: 0.2519 - val_loss: 0.7912 - val_recall: 0.1710 - val_precision: 0.2241\n",
            "Epoch 602/1000\n",
            " - 2s - loss: 0.6502 - recall: 0.1873 - precision: 0.2507 - val_loss: 0.7910 - val_recall: 0.1600 - val_precision: 0.2126\n",
            "Epoch 603/1000\n",
            " - 2s - loss: 0.6557 - recall: 0.1818 - precision: 0.2487 - val_loss: 0.7866 - val_recall: 0.1610 - val_precision: 0.2117\n",
            "Epoch 604/1000\n",
            " - 2s - loss: 0.6504 - recall: 0.1926 - precision: 0.2527 - val_loss: 0.7849 - val_recall: 0.1530 - val_precision: 0.2004\n",
            "Epoch 605/1000\n",
            " - 2s - loss: 0.6462 - recall: 0.1949 - precision: 0.2561 - val_loss: 0.7883 - val_recall: 0.1544 - val_precision: 0.2073\n",
            "Epoch 606/1000\n",
            " - 2s - loss: 0.6635 - recall: 0.1824 - precision: 0.2477 - val_loss: 0.7855 - val_recall: 0.1534 - val_precision: 0.1987\n",
            "Epoch 607/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1835 - precision: 0.2521 - val_loss: 0.7896 - val_recall: 0.1602 - val_precision: 0.2145\n",
            "Epoch 608/1000\n",
            " - 2s - loss: 0.6520 - recall: 0.1885 - precision: 0.2523 - val_loss: 0.7939 - val_recall: 0.1635 - val_precision: 0.2152\n",
            "Epoch 609/1000\n",
            " - 2s - loss: 0.6560 - recall: 0.1971 - precision: 0.2583 - val_loss: 0.7904 - val_recall: 0.1526 - val_precision: 0.1953\n",
            "Epoch 610/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1880 - precision: 0.2446 - val_loss: 0.7887 - val_recall: 0.1586 - val_precision: 0.2042\n",
            "Epoch 611/1000\n",
            " - 2s - loss: 0.6502 - recall: 0.1924 - precision: 0.2655 - val_loss: 0.7811 - val_recall: 0.1522 - val_precision: 0.2056\n",
            "Epoch 612/1000\n",
            " - 2s - loss: 0.6520 - recall: 0.1887 - precision: 0.2521 - val_loss: 0.7973 - val_recall: 0.1563 - val_precision: 0.2026\n",
            "Epoch 613/1000\n",
            " - 2s - loss: 0.6531 - recall: 0.1920 - precision: 0.2624 - val_loss: 0.7826 - val_recall: 0.1579 - val_precision: 0.2015\n",
            "Epoch 614/1000\n",
            " - 2s - loss: 0.6492 - recall: 0.1950 - precision: 0.2563 - val_loss: 0.7948 - val_recall: 0.1695 - val_precision: 0.2163\n",
            "Epoch 615/1000\n",
            " - 2s - loss: 0.6582 - recall: 0.1873 - precision: 0.2511 - val_loss: 0.7849 - val_recall: 0.1557 - val_precision: 0.2016\n",
            "Epoch 616/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1925 - precision: 0.2607 - val_loss: 0.7867 - val_recall: 0.1520 - val_precision: 0.1975\n",
            "Epoch 617/1000\n",
            " - 2s - loss: 0.6506 - recall: 0.1864 - precision: 0.2491 - val_loss: 0.7845 - val_recall: 0.1593 - val_precision: 0.2104\n",
            "Epoch 618/1000\n",
            " - 2s - loss: 0.6529 - recall: 0.1890 - precision: 0.2468 - val_loss: 0.7782 - val_recall: 0.1622 - val_precision: 0.2108\n",
            "Epoch 619/1000\n",
            " - 2s - loss: 0.6519 - recall: 0.1931 - precision: 0.2571 - val_loss: 0.7870 - val_recall: 0.1588 - val_precision: 0.2117\n",
            "Epoch 620/1000\n",
            " - 2s - loss: 0.6557 - recall: 0.1922 - precision: 0.2532 - val_loss: 0.7805 - val_recall: 0.1508 - val_precision: 0.2026\n",
            "Epoch 621/1000\n",
            " - 2s - loss: 0.6518 - recall: 0.1956 - precision: 0.2554 - val_loss: 0.7877 - val_recall: 0.1573 - val_precision: 0.2039\n",
            "Epoch 622/1000\n",
            " - 2s - loss: 0.6522 - recall: 0.1923 - precision: 0.2603 - val_loss: 0.7819 - val_recall: 0.1543 - val_precision: 0.2101\n",
            "Epoch 623/1000\n",
            " - 2s - loss: 0.6509 - recall: 0.1947 - precision: 0.2558 - val_loss: 0.7858 - val_recall: 0.1616 - val_precision: 0.2153\n",
            "Epoch 624/1000\n",
            " - 2s - loss: 0.6543 - recall: 0.1896 - precision: 0.2569 - val_loss: 0.7923 - val_recall: 0.1501 - val_precision: 0.1995\n",
            "Epoch 625/1000\n",
            " - 2s - loss: 0.6521 - recall: 0.1911 - precision: 0.2493 - val_loss: 0.7841 - val_recall: 0.1570 - val_precision: 0.2104\n",
            "Epoch 626/1000\n",
            " - 2s - loss: 0.6496 - recall: 0.1876 - precision: 0.2475 - val_loss: 0.7999 - val_recall: 0.1542 - val_precision: 0.2010\n",
            "Epoch 627/1000\n",
            " - 2s - loss: 0.6538 - recall: 0.1941 - precision: 0.2593 - val_loss: 0.7981 - val_recall: 0.1533 - val_precision: 0.2024\n",
            "Epoch 628/1000\n",
            " - 2s - loss: 0.6572 - recall: 0.1884 - precision: 0.2516 - val_loss: 0.7869 - val_recall: 0.1666 - val_precision: 0.2224\n",
            "Epoch 629/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1894 - precision: 0.2491 - val_loss: 0.7860 - val_recall: 0.1547 - val_precision: 0.2023\n",
            "Epoch 630/1000\n",
            " - 2s - loss: 0.6474 - recall: 0.1943 - precision: 0.2585 - val_loss: 0.7905 - val_recall: 0.1612 - val_precision: 0.2050\n",
            "Epoch 631/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1845 - precision: 0.2485 - val_loss: 0.7914 - val_recall: 0.1587 - val_precision: 0.2113\n",
            "Epoch 632/1000\n",
            " - 2s - loss: 0.6519 - recall: 0.1995 - precision: 0.2600 - val_loss: 0.7851 - val_recall: 0.1640 - val_precision: 0.2115\n",
            "Epoch 633/1000\n",
            " - 2s - loss: 0.6480 - recall: 0.1920 - precision: 0.2585 - val_loss: 0.7842 - val_recall: 0.1546 - val_precision: 0.2036\n",
            "Epoch 634/1000\n",
            " - 2s - loss: 0.6562 - recall: 0.1966 - precision: 0.2592 - val_loss: 0.7779 - val_recall: 0.1580 - val_precision: 0.2070\n",
            "Epoch 635/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1955 - precision: 0.2589 - val_loss: 0.7819 - val_recall: 0.1573 - val_precision: 0.2012\n",
            "Epoch 636/1000\n",
            " - 2s - loss: 0.6493 - recall: 0.1973 - precision: 0.2665 - val_loss: 0.7851 - val_recall: 0.1647 - val_precision: 0.2112\n",
            "Epoch 637/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1900 - precision: 0.2531 - val_loss: 0.7868 - val_recall: 0.1619 - val_precision: 0.2170\n",
            "Epoch 638/1000\n",
            " - 2s - loss: 0.6568 - recall: 0.1856 - precision: 0.2509 - val_loss: 0.7818 - val_recall: 0.1590 - val_precision: 0.2082\n",
            "Epoch 639/1000\n",
            " - 2s - loss: 0.6502 - recall: 0.1937 - precision: 0.2591 - val_loss: 0.7898 - val_recall: 0.1572 - val_precision: 0.2026\n",
            "Epoch 640/1000\n",
            " - 2s - loss: 0.6571 - recall: 0.1903 - precision: 0.2476 - val_loss: 0.7832 - val_recall: 0.1519 - val_precision: 0.1929\n",
            "Epoch 641/1000\n",
            " - 2s - loss: 0.6523 - recall: 0.1857 - precision: 0.2506 - val_loss: 0.7859 - val_recall: 0.1547 - val_precision: 0.1991\n",
            "Epoch 642/1000\n",
            " - 2s - loss: 0.6495 - recall: 0.1923 - precision: 0.2558 - val_loss: 0.7930 - val_recall: 0.1495 - val_precision: 0.1937\n",
            "Epoch 643/1000\n",
            " - 2s - loss: 0.6528 - recall: 0.1942 - precision: 0.2642 - val_loss: 0.7792 - val_recall: 0.1551 - val_precision: 0.2071\n",
            "Epoch 644/1000\n",
            " - 2s - loss: 0.6510 - recall: 0.1934 - precision: 0.2535 - val_loss: 0.7882 - val_recall: 0.1566 - val_precision: 0.2061\n",
            "Epoch 645/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1926 - precision: 0.2560 - val_loss: 0.7832 - val_recall: 0.1605 - val_precision: 0.2086\n",
            "Epoch 646/1000\n",
            " - 2s - loss: 0.6515 - recall: 0.1989 - precision: 0.2562 - val_loss: 0.7801 - val_recall: 0.1676 - val_precision: 0.2217\n",
            "Epoch 647/1000\n",
            " - 2s - loss: 0.6549 - recall: 0.1887 - precision: 0.2516 - val_loss: 0.7863 - val_recall: 0.1525 - val_precision: 0.2077\n",
            "Epoch 648/1000\n",
            " - 2s - loss: 0.6537 - recall: 0.1912 - precision: 0.2540 - val_loss: 0.8006 - val_recall: 0.1701 - val_precision: 0.2176\n",
            "Epoch 649/1000\n",
            " - 2s - loss: 0.6573 - recall: 0.1844 - precision: 0.2354 - val_loss: 0.7948 - val_recall: 0.1747 - val_precision: 0.2288\n",
            "Epoch 650/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1914 - precision: 0.2552 - val_loss: 0.7743 - val_recall: 0.1558 - val_precision: 0.1988\n",
            "Epoch 651/1000\n",
            " - 2s - loss: 0.6486 - recall: 0.1855 - precision: 0.2490 - val_loss: 0.7755 - val_recall: 0.1603 - val_precision: 0.2138\n",
            "Epoch 652/1000\n",
            " - 2s - loss: 0.6524 - recall: 0.1931 - precision: 0.2503 - val_loss: 0.7846 - val_recall: 0.1556 - val_precision: 0.2106\n",
            "Epoch 653/1000\n",
            " - 2s - loss: 0.6531 - recall: 0.1899 - precision: 0.2532 - val_loss: 0.7729 - val_recall: 0.1621 - val_precision: 0.2156\n",
            "Epoch 654/1000\n",
            " - 2s - loss: 0.6532 - recall: 0.1931 - precision: 0.2508 - val_loss: 0.7865 - val_recall: 0.1598 - val_precision: 0.2181\n",
            "Epoch 655/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.1886 - precision: 0.2556 - val_loss: 0.7913 - val_recall: 0.1648 - val_precision: 0.2211\n",
            "Epoch 656/1000\n",
            " - 2s - loss: 0.6574 - recall: 0.1871 - precision: 0.2533 - val_loss: 0.7833 - val_recall: 0.1539 - val_precision: 0.2016\n",
            "Epoch 657/1000\n",
            " - 2s - loss: 0.6532 - recall: 0.1936 - precision: 0.2566 - val_loss: 0.7855 - val_recall: 0.1595 - val_precision: 0.2142\n",
            "Epoch 658/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1925 - precision: 0.2615 - val_loss: 0.7876 - val_recall: 0.1621 - val_precision: 0.2148\n",
            "Epoch 659/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1924 - precision: 0.2580 - val_loss: 0.7915 - val_recall: 0.1569 - val_precision: 0.2129\n",
            "Epoch 660/1000\n",
            " - 2s - loss: 0.6451 - recall: 0.1940 - precision: 0.2554 - val_loss: 0.7964 - val_recall: 0.1574 - val_precision: 0.2111\n",
            "Epoch 661/1000\n",
            " - 2s - loss: 0.6476 - recall: 0.1892 - precision: 0.2557 - val_loss: 0.7994 - val_recall: 0.1634 - val_precision: 0.2119\n",
            "Epoch 662/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1877 - precision: 0.2485 - val_loss: 0.7956 - val_recall: 0.1557 - val_precision: 0.2021\n",
            "Epoch 663/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.1905 - precision: 0.2570 - val_loss: 0.7925 - val_recall: 0.1603 - val_precision: 0.2060\n",
            "Epoch 664/1000\n",
            " - 2s - loss: 0.6591 - recall: 0.1874 - precision: 0.2492 - val_loss: 0.7812 - val_recall: 0.1631 - val_precision: 0.2211\n",
            "Epoch 665/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1889 - precision: 0.2498 - val_loss: 0.7830 - val_recall: 0.1613 - val_precision: 0.2078\n",
            "Epoch 666/1000\n",
            " - 2s - loss: 0.6493 - recall: 0.1888 - precision: 0.2469 - val_loss: 0.7809 - val_recall: 0.1602 - val_precision: 0.2180\n",
            "Epoch 667/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.1910 - precision: 0.2525 - val_loss: 0.7992 - val_recall: 0.1594 - val_precision: 0.2119\n",
            "Epoch 668/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.1890 - precision: 0.2486 - val_loss: 0.7980 - val_recall: 0.1645 - val_precision: 0.2171\n",
            "Epoch 669/1000\n",
            " - 2s - loss: 0.6467 - recall: 0.1910 - precision: 0.2561 - val_loss: 0.7979 - val_recall: 0.1621 - val_precision: 0.2160\n",
            "Epoch 670/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.1972 - precision: 0.2606 - val_loss: 0.7967 - val_recall: 0.1631 - val_precision: 0.2103\n",
            "Epoch 671/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1916 - precision: 0.2518 - val_loss: 0.7844 - val_recall: 0.1606 - val_precision: 0.2196\n",
            "Epoch 672/1000\n",
            " - 2s - loss: 0.6446 - recall: 0.1972 - precision: 0.2644 - val_loss: 0.7943 - val_recall: 0.1674 - val_precision: 0.2179\n",
            "Epoch 673/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1890 - precision: 0.2552 - val_loss: 0.7843 - val_recall: 0.1539 - val_precision: 0.2040\n",
            "Epoch 674/1000\n",
            " - 2s - loss: 0.6612 - recall: 0.1877 - precision: 0.2564 - val_loss: 0.8044 - val_recall: 0.1606 - val_precision: 0.2112\n",
            "Epoch 675/1000\n",
            " - 2s - loss: 0.6586 - recall: 0.1891 - precision: 0.2499 - val_loss: 0.7961 - val_recall: 0.1593 - val_precision: 0.2134\n",
            "Epoch 676/1000\n",
            " - 2s - loss: 0.6500 - recall: 0.1919 - precision: 0.2535 - val_loss: 0.7889 - val_recall: 0.1626 - val_precision: 0.2129\n",
            "Epoch 677/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1907 - precision: 0.2487 - val_loss: 0.7837 - val_recall: 0.1544 - val_precision: 0.2098\n",
            "Epoch 678/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1895 - precision: 0.2583 - val_loss: 0.7852 - val_recall: 0.1724 - val_precision: 0.2188\n",
            "Epoch 679/1000\n",
            " - 2s - loss: 0.6523 - recall: 0.1948 - precision: 0.2637 - val_loss: 0.7910 - val_recall: 0.1608 - val_precision: 0.2103\n",
            "Epoch 680/1000\n",
            " - 2s - loss: 0.6490 - recall: 0.1875 - precision: 0.2484 - val_loss: 0.7831 - val_recall: 0.1593 - val_precision: 0.2143\n",
            "Epoch 681/1000\n",
            " - 2s - loss: 0.6504 - recall: 0.1901 - precision: 0.2503 - val_loss: 0.7808 - val_recall: 0.1570 - val_precision: 0.2006\n",
            "Epoch 682/1000\n",
            " - 2s - loss: 0.6602 - recall: 0.1847 - precision: 0.2478 - val_loss: 0.7844 - val_recall: 0.1538 - val_precision: 0.2043\n",
            "Epoch 683/1000\n",
            " - 2s - loss: 0.6536 - recall: 0.1933 - precision: 0.2585 - val_loss: 0.7791 - val_recall: 0.1616 - val_precision: 0.2177\n",
            "Epoch 684/1000\n",
            " - 2s - loss: 0.6560 - recall: 0.1956 - precision: 0.2664 - val_loss: 0.7856 - val_recall: 0.1560 - val_precision: 0.2071\n",
            "Epoch 685/1000\n",
            " - 2s - loss: 0.6547 - recall: 0.1872 - precision: 0.2509 - val_loss: 0.7868 - val_recall: 0.1643 - val_precision: 0.2137\n",
            "Epoch 686/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1956 - precision: 0.2584 - val_loss: 0.7806 - val_recall: 0.1610 - val_precision: 0.2078\n",
            "Epoch 687/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.2017 - precision: 0.2684 - val_loss: 0.7911 - val_recall: 0.1588 - val_precision: 0.2023\n",
            "Epoch 688/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1921 - precision: 0.2579 - val_loss: 0.7850 - val_recall: 0.1573 - val_precision: 0.2094\n",
            "Epoch 689/1000\n",
            " - 2s - loss: 0.6518 - recall: 0.1870 - precision: 0.2479 - val_loss: 0.7810 - val_recall: 0.1572 - val_precision: 0.2109\n",
            "Epoch 690/1000\n",
            " - 2s - loss: 0.6534 - recall: 0.1889 - precision: 0.2499 - val_loss: 0.7721 - val_recall: 0.1547 - val_precision: 0.2031\n",
            "Epoch 691/1000\n",
            " - 2s - loss: 0.6527 - recall: 0.1914 - precision: 0.2579 - val_loss: 0.7872 - val_recall: 0.1525 - val_precision: 0.2050\n",
            "Epoch 692/1000\n",
            " - 2s - loss: 0.6543 - recall: 0.1857 - precision: 0.2511 - val_loss: 0.7859 - val_recall: 0.1563 - val_precision: 0.2153\n",
            "Epoch 693/1000\n",
            " - 2s - loss: 0.6491 - recall: 0.1897 - precision: 0.2635 - val_loss: 0.7920 - val_recall: 0.1569 - val_precision: 0.2084\n",
            "Epoch 694/1000\n",
            " - 2s - loss: 0.6583 - recall: 0.1878 - precision: 0.2520 - val_loss: 0.7759 - val_recall: 0.1639 - val_precision: 0.2172\n",
            "Epoch 695/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.1964 - precision: 0.2558 - val_loss: 0.7792 - val_recall: 0.1630 - val_precision: 0.2178\n",
            "Epoch 696/1000\n",
            " - 2s - loss: 0.6485 - recall: 0.1954 - precision: 0.2572 - val_loss: 0.7831 - val_recall: 0.1606 - val_precision: 0.2079\n",
            "Epoch 697/1000\n",
            " - 2s - loss: 0.6484 - recall: 0.1904 - precision: 0.2538 - val_loss: 0.8001 - val_recall: 0.1598 - val_precision: 0.2046\n",
            "Epoch 698/1000\n",
            " - 2s - loss: 0.6523 - recall: 0.1916 - precision: 0.2593 - val_loss: 0.7818 - val_recall: 0.1492 - val_precision: 0.1935\n",
            "Epoch 699/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.1931 - precision: 0.2530 - val_loss: 0.7931 - val_recall: 0.1601 - val_precision: 0.2124\n",
            "Epoch 700/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1944 - precision: 0.2645 - val_loss: 0.8000 - val_recall: 0.1603 - val_precision: 0.2014\n",
            "Epoch 701/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1898 - precision: 0.2519 - val_loss: 0.7979 - val_recall: 0.1577 - val_precision: 0.2114\n",
            "Epoch 702/1000\n",
            " - 2s - loss: 0.6496 - recall: 0.1923 - precision: 0.2552 - val_loss: 0.7994 - val_recall: 0.1650 - val_precision: 0.2182\n",
            "Epoch 703/1000\n",
            " - 2s - loss: 0.6500 - recall: 0.1961 - precision: 0.2618 - val_loss: 0.7923 - val_recall: 0.1541 - val_precision: 0.2096\n",
            "Epoch 704/1000\n",
            " - 2s - loss: 0.6510 - recall: 0.1950 - precision: 0.2614 - val_loss: 0.7874 - val_recall: 0.1508 - val_precision: 0.2010\n",
            "Epoch 705/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1909 - precision: 0.2551 - val_loss: 0.7916 - val_recall: 0.1546 - val_precision: 0.2059\n",
            "Epoch 706/1000\n",
            " - 2s - loss: 0.6442 - recall: 0.1929 - precision: 0.2618 - val_loss: 0.7995 - val_recall: 0.1593 - val_precision: 0.2097\n",
            "Epoch 707/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.1956 - precision: 0.2598 - val_loss: 0.8127 - val_recall: 0.1611 - val_precision: 0.2114\n",
            "Epoch 708/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.2000 - precision: 0.2650 - val_loss: 0.7973 - val_recall: 0.1581 - val_precision: 0.2108\n",
            "Epoch 709/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1981 - precision: 0.2656 - val_loss: 0.7892 - val_recall: 0.1578 - val_precision: 0.2137\n",
            "Epoch 710/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.1956 - precision: 0.2583 - val_loss: 0.8023 - val_recall: 0.1605 - val_precision: 0.2053\n",
            "Epoch 711/1000\n",
            " - 2s - loss: 0.6536 - recall: 0.1960 - precision: 0.2631 - val_loss: 0.7953 - val_recall: 0.1501 - val_precision: 0.2004\n",
            "Epoch 712/1000\n",
            " - 2s - loss: 0.6532 - recall: 0.1918 - precision: 0.2582 - val_loss: 0.7847 - val_recall: 0.1495 - val_precision: 0.2012\n",
            "Epoch 713/1000\n",
            " - 2s - loss: 0.6548 - recall: 0.1887 - precision: 0.2511 - val_loss: 0.7990 - val_recall: 0.1652 - val_precision: 0.2121\n",
            "Epoch 714/1000\n",
            " - 2s - loss: 0.6530 - recall: 0.1882 - precision: 0.2550 - val_loss: 0.7878 - val_recall: 0.1618 - val_precision: 0.2155\n",
            "Epoch 715/1000\n",
            " - 2s - loss: 0.6541 - recall: 0.1870 - precision: 0.2536 - val_loss: 0.7917 - val_recall: 0.1593 - val_precision: 0.2128\n",
            "Epoch 716/1000\n",
            " - 2s - loss: 0.6464 - recall: 0.1933 - precision: 0.2579 - val_loss: 0.7848 - val_recall: 0.1568 - val_precision: 0.1996\n",
            "Epoch 717/1000\n",
            " - 2s - loss: 0.6528 - recall: 0.1881 - precision: 0.2463 - val_loss: 0.7900 - val_recall: 0.1636 - val_precision: 0.2165\n",
            "Epoch 718/1000\n",
            " - 2s - loss: 0.6494 - recall: 0.1977 - precision: 0.2629 - val_loss: 0.7895 - val_recall: 0.1618 - val_precision: 0.2105\n",
            "Epoch 719/1000\n",
            " - 2s - loss: 0.6577 - recall: 0.1883 - precision: 0.2516 - val_loss: 0.7934 - val_recall: 0.1549 - val_precision: 0.2104\n",
            "Epoch 720/1000\n",
            " - 2s - loss: 0.6501 - recall: 0.1877 - precision: 0.2468 - val_loss: 0.8002 - val_recall: 0.1630 - val_precision: 0.2095\n",
            "Epoch 721/1000\n",
            " - 2s - loss: 0.6511 - recall: 0.1859 - precision: 0.2483 - val_loss: 0.7902 - val_recall: 0.1535 - val_precision: 0.2016\n",
            "Epoch 722/1000\n",
            " - 2s - loss: 0.6538 - recall: 0.1949 - precision: 0.2584 - val_loss: 0.7870 - val_recall: 0.1633 - val_precision: 0.2141\n",
            "Epoch 723/1000\n",
            " - 2s - loss: 0.6526 - recall: 0.1883 - precision: 0.2517 - val_loss: 0.7799 - val_recall: 0.1581 - val_precision: 0.2060\n",
            "Epoch 724/1000\n",
            " - 2s - loss: 0.6445 - recall: 0.1968 - precision: 0.2604 - val_loss: 0.7912 - val_recall: 0.1637 - val_precision: 0.2185\n",
            "Epoch 725/1000\n",
            " - 2s - loss: 0.6456 - recall: 0.1936 - precision: 0.2637 - val_loss: 0.7888 - val_recall: 0.1593 - val_precision: 0.2176\n",
            "Epoch 726/1000\n",
            " - 2s - loss: 0.6509 - recall: 0.1921 - precision: 0.2598 - val_loss: 0.8037 - val_recall: 0.1630 - val_precision: 0.2159\n",
            "Epoch 727/1000\n",
            " - 2s - loss: 0.6556 - recall: 0.1917 - precision: 0.2560 - val_loss: 0.7905 - val_recall: 0.1601 - val_precision: 0.2032\n",
            "Epoch 728/1000\n",
            " - 2s - loss: 0.6487 - recall: 0.1845 - precision: 0.2465 - val_loss: 0.7971 - val_recall: 0.1538 - val_precision: 0.2035\n",
            "Epoch 729/1000\n",
            " - 2s - loss: 0.6566 - recall: 0.1914 - precision: 0.2542 - val_loss: 0.7962 - val_recall: 0.1588 - val_precision: 0.2122\n",
            "Epoch 730/1000\n",
            " - 2s - loss: 0.6451 - recall: 0.1944 - precision: 0.2651 - val_loss: 0.7851 - val_recall: 0.1546 - val_precision: 0.2014\n",
            "Epoch 731/1000\n",
            " - 2s - loss: 0.6471 - recall: 0.1938 - precision: 0.2596 - val_loss: 0.7998 - val_recall: 0.1518 - val_precision: 0.2002\n",
            "Epoch 732/1000\n",
            " - 2s - loss: 0.6500 - recall: 0.1848 - precision: 0.2439 - val_loss: 0.7937 - val_recall: 0.1548 - val_precision: 0.2033\n",
            "Epoch 733/1000\n",
            " - 2s - loss: 0.6488 - recall: 0.1939 - precision: 0.2645 - val_loss: 0.7962 - val_recall: 0.1633 - val_precision: 0.2064\n",
            "Epoch 734/1000\n",
            " - 2s - loss: 0.6536 - recall: 0.1869 - precision: 0.2424 - val_loss: 0.8000 - val_recall: 0.1628 - val_precision: 0.2177\n",
            "Epoch 735/1000\n",
            " - 2s - loss: 0.6493 - recall: 0.1934 - precision: 0.2588 - val_loss: 0.7973 - val_recall: 0.1558 - val_precision: 0.2090\n",
            "Epoch 736/1000\n",
            " - 2s - loss: 0.6450 - recall: 0.1929 - precision: 0.2579 - val_loss: 0.7875 - val_recall: 0.1632 - val_precision: 0.2124\n",
            "Epoch 737/1000\n",
            " - 2s - loss: 0.6440 - recall: 0.1990 - precision: 0.2686 - val_loss: 0.7775 - val_recall: 0.1594 - val_precision: 0.2095\n",
            "Epoch 738/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1926 - precision: 0.2482 - val_loss: 0.7823 - val_recall: 0.1550 - val_precision: 0.1987\n",
            "Epoch 739/1000\n",
            " - 2s - loss: 0.6505 - recall: 0.1833 - precision: 0.2435 - val_loss: 0.7834 - val_recall: 0.1606 - val_precision: 0.2088\n",
            "Epoch 740/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1937 - precision: 0.2560 - val_loss: 0.7856 - val_recall: 0.1552 - val_precision: 0.2022\n",
            "Epoch 741/1000\n",
            " - 2s - loss: 0.6474 - recall: 0.1944 - precision: 0.2556 - val_loss: 0.7954 - val_recall: 0.1529 - val_precision: 0.2045\n",
            "Epoch 742/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1864 - precision: 0.2478 - val_loss: 0.7841 - val_recall: 0.1526 - val_precision: 0.2031\n",
            "Epoch 743/1000\n",
            " - 2s - loss: 0.6615 - recall: 0.1808 - precision: 0.2442 - val_loss: 0.7831 - val_recall: 0.1577 - val_precision: 0.2103\n",
            "Epoch 744/1000\n",
            " - 2s - loss: 0.6541 - recall: 0.1910 - precision: 0.2584 - val_loss: 0.7741 - val_recall: 0.1645 - val_precision: 0.2146\n",
            "Epoch 745/1000\n",
            " - 2s - loss: 0.6518 - recall: 0.1909 - precision: 0.2538 - val_loss: 0.7884 - val_recall: 0.1645 - val_precision: 0.2178\n",
            "Epoch 746/1000\n",
            " - 2s - loss: 0.6480 - recall: 0.1972 - precision: 0.2677 - val_loss: 0.7968 - val_recall: 0.1596 - val_precision: 0.2082\n",
            "Epoch 747/1000\n",
            " - 2s - loss: 0.6494 - recall: 0.1942 - precision: 0.2530 - val_loss: 0.7985 - val_recall: 0.1646 - val_precision: 0.2169\n",
            "Epoch 748/1000\n",
            " - 2s - loss: 0.6460 - recall: 0.1942 - precision: 0.2623 - val_loss: 0.8146 - val_recall: 0.1584 - val_precision: 0.2085\n",
            "Epoch 749/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1900 - precision: 0.2535 - val_loss: 0.8004 - val_recall: 0.1581 - val_precision: 0.2111\n",
            "Epoch 750/1000\n",
            " - 2s - loss: 0.6537 - recall: 0.1897 - precision: 0.2547 - val_loss: 0.7975 - val_recall: 0.1597 - val_precision: 0.2070\n",
            "Epoch 751/1000\n",
            " - 2s - loss: 0.6632 - recall: 0.1854 - precision: 0.2471 - val_loss: 0.7858 - val_recall: 0.1505 - val_precision: 0.2081\n",
            "Epoch 752/1000\n",
            " - 2s - loss: 0.6471 - recall: 0.1882 - precision: 0.2509 - val_loss: 0.7869 - val_recall: 0.1612 - val_precision: 0.2151\n",
            "Epoch 753/1000\n",
            " - 2s - loss: 0.6495 - recall: 0.1884 - precision: 0.2507 - val_loss: 0.7770 - val_recall: 0.1515 - val_precision: 0.1996\n",
            "Epoch 754/1000\n",
            " - 2s - loss: 0.6449 - recall: 0.1933 - precision: 0.2584 - val_loss: 0.7798 - val_recall: 0.1591 - val_precision: 0.2027\n",
            "Epoch 755/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.1926 - precision: 0.2581 - val_loss: 0.7843 - val_recall: 0.1602 - val_precision: 0.2145\n",
            "Epoch 756/1000\n",
            " - 2s - loss: 0.6440 - recall: 0.1912 - precision: 0.2535 - val_loss: 0.8043 - val_recall: 0.1606 - val_precision: 0.2130\n",
            "Epoch 757/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1935 - precision: 0.2632 - val_loss: 0.7938 - val_recall: 0.1626 - val_precision: 0.2182\n",
            "Epoch 758/1000\n",
            " - 2s - loss: 0.6441 - recall: 0.1997 - precision: 0.2672 - val_loss: 0.7859 - val_recall: 0.1568 - val_precision: 0.2064\n",
            "Epoch 759/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.1962 - precision: 0.2646 - val_loss: 0.7946 - val_recall: 0.1577 - val_precision: 0.2213\n",
            "Epoch 760/1000\n",
            " - 2s - loss: 0.6449 - recall: 0.1971 - precision: 0.2650 - val_loss: 0.7975 - val_recall: 0.1558 - val_precision: 0.2128\n",
            "Epoch 761/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.2005 - precision: 0.2710 - val_loss: 0.7906 - val_recall: 0.1585 - val_precision: 0.2135\n",
            "Epoch 762/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.1985 - precision: 0.2614 - val_loss: 0.8070 - val_recall: 0.1602 - val_precision: 0.2089\n",
            "Epoch 763/1000\n",
            " - 2s - loss: 0.6459 - recall: 0.1952 - precision: 0.2636 - val_loss: 0.7910 - val_recall: 0.1601 - val_precision: 0.2114\n",
            "Epoch 764/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1968 - precision: 0.2621 - val_loss: 0.7991 - val_recall: 0.1579 - val_precision: 0.2065\n",
            "Epoch 765/1000\n",
            " - 2s - loss: 0.6609 - recall: 0.1928 - precision: 0.2600 - val_loss: 0.7948 - val_recall: 0.1680 - val_precision: 0.2224\n",
            "Epoch 766/1000\n",
            " - 2s - loss: 0.6544 - recall: 0.1858 - precision: 0.2531 - val_loss: 0.7957 - val_recall: 0.1656 - val_precision: 0.2159\n",
            "Epoch 767/1000\n",
            " - 2s - loss: 0.6438 - recall: 0.1982 - precision: 0.2577 - val_loss: 0.7790 - val_recall: 0.1594 - val_precision: 0.2090\n",
            "Epoch 768/1000\n",
            " - 2s - loss: 0.6422 - recall: 0.1955 - precision: 0.2622 - val_loss: 0.7886 - val_recall: 0.1586 - val_precision: 0.2124\n",
            "Epoch 769/1000\n",
            " - 2s - loss: 0.6424 - recall: 0.1972 - precision: 0.2642 - val_loss: 0.7894 - val_recall: 0.1614 - val_precision: 0.2168\n",
            "Epoch 770/1000\n",
            " - 2s - loss: 0.6509 - recall: 0.1937 - precision: 0.2533 - val_loss: 0.8016 - val_recall: 0.1721 - val_precision: 0.2220\n",
            "Epoch 771/1000\n",
            " - 2s - loss: 0.6485 - recall: 0.1899 - precision: 0.2546 - val_loss: 0.7976 - val_recall: 0.1623 - val_precision: 0.2142\n",
            "Epoch 772/1000\n",
            " - 2s - loss: 0.6434 - recall: 0.1909 - precision: 0.2601 - val_loss: 0.7951 - val_recall: 0.1692 - val_precision: 0.2255\n",
            "Epoch 773/1000\n",
            " - 2s - loss: 0.6491 - recall: 0.1899 - precision: 0.2468 - val_loss: 0.7993 - val_recall: 0.1572 - val_precision: 0.2065\n",
            "Epoch 774/1000\n",
            " - 2s - loss: 0.6501 - recall: 0.1920 - precision: 0.2541 - val_loss: 0.8018 - val_recall: 0.1770 - val_precision: 0.2262\n",
            "Epoch 775/1000\n",
            " - 2s - loss: 0.6487 - recall: 0.1842 - precision: 0.2515 - val_loss: 0.7948 - val_recall: 0.1638 - val_precision: 0.2114\n",
            "Epoch 776/1000\n",
            " - 2s - loss: 0.6463 - recall: 0.1890 - precision: 0.2578 - val_loss: 0.7995 - val_recall: 0.1614 - val_precision: 0.2105\n",
            "Epoch 777/1000\n",
            " - 2s - loss: 0.6536 - recall: 0.1911 - precision: 0.2498 - val_loss: 0.7852 - val_recall: 0.1632 - val_precision: 0.2096\n",
            "Epoch 778/1000\n",
            " - 2s - loss: 0.6521 - recall: 0.1909 - precision: 0.2552 - val_loss: 0.7842 - val_recall: 0.1613 - val_precision: 0.2158\n",
            "Epoch 779/1000\n",
            " - 2s - loss: 0.6455 - recall: 0.1923 - precision: 0.2542 - val_loss: 0.7910 - val_recall: 0.1564 - val_precision: 0.2098\n",
            "Epoch 780/1000\n",
            " - 2s - loss: 0.6524 - recall: 0.1894 - precision: 0.2530 - val_loss: 0.7816 - val_recall: 0.1592 - val_precision: 0.2132\n",
            "Epoch 781/1000\n",
            " - 2s - loss: 0.6488 - recall: 0.1869 - precision: 0.2481 - val_loss: 0.7884 - val_recall: 0.1605 - val_precision: 0.2086\n",
            "Epoch 782/1000\n",
            " - 2s - loss: 0.6544 - recall: 0.1904 - precision: 0.2533 - val_loss: 0.7803 - val_recall: 0.1567 - val_precision: 0.2053\n",
            "Epoch 783/1000\n",
            " - 2s - loss: 0.6492 - recall: 0.1898 - precision: 0.2569 - val_loss: 0.7832 - val_recall: 0.1589 - val_precision: 0.2089\n",
            "Epoch 784/1000\n",
            " - 2s - loss: 0.6484 - recall: 0.1926 - precision: 0.2540 - val_loss: 0.7824 - val_recall: 0.1689 - val_precision: 0.2219\n",
            "Epoch 785/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1947 - precision: 0.2593 - val_loss: 0.7811 - val_recall: 0.1615 - val_precision: 0.2123\n",
            "Epoch 786/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1876 - precision: 0.2541 - val_loss: 0.7815 - val_recall: 0.1569 - val_precision: 0.2157\n",
            "Epoch 787/1000\n",
            " - 2s - loss: 0.6441 - recall: 0.1958 - precision: 0.2580 - val_loss: 0.8106 - val_recall: 0.1563 - val_precision: 0.2117\n",
            "Epoch 788/1000\n",
            " - 2s - loss: 0.6449 - recall: 0.1923 - precision: 0.2577 - val_loss: 0.8033 - val_recall: 0.1662 - val_precision: 0.2165\n",
            "Epoch 789/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.1909 - precision: 0.2512 - val_loss: 0.7851 - val_recall: 0.1564 - val_precision: 0.2091\n",
            "Epoch 790/1000\n",
            " - 2s - loss: 0.6456 - recall: 0.1879 - precision: 0.2546 - val_loss: 0.7904 - val_recall: 0.1614 - val_precision: 0.2123\n",
            "Epoch 791/1000\n",
            " - 2s - loss: 0.6476 - recall: 0.1973 - precision: 0.2665 - val_loss: 0.7724 - val_recall: 0.1641 - val_precision: 0.2172\n",
            "Epoch 792/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1941 - precision: 0.2544 - val_loss: 0.7856 - val_recall: 0.1656 - val_precision: 0.2086\n",
            "Epoch 793/1000\n",
            " - 2s - loss: 0.6502 - recall: 0.1960 - precision: 0.2571 - val_loss: 0.7873 - val_recall: 0.1618 - val_precision: 0.2103\n",
            "Epoch 794/1000\n",
            " - 2s - loss: 0.6455 - recall: 0.1953 - precision: 0.2647 - val_loss: 0.7983 - val_recall: 0.1647 - val_precision: 0.2141\n",
            "Epoch 795/1000\n",
            " - 2s - loss: 0.6467 - recall: 0.1919 - precision: 0.2543 - val_loss: 0.7913 - val_recall: 0.1728 - val_precision: 0.2200\n",
            "Epoch 796/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1946 - precision: 0.2589 - val_loss: 0.7879 - val_recall: 0.1577 - val_precision: 0.2164\n",
            "Epoch 797/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1854 - precision: 0.2514 - val_loss: 0.7853 - val_recall: 0.1641 - val_precision: 0.2128\n",
            "Epoch 798/1000\n",
            " - 2s - loss: 0.6588 - recall: 0.1904 - precision: 0.2580 - val_loss: 0.7827 - val_recall: 0.1528 - val_precision: 0.2024\n",
            "Epoch 799/1000\n",
            " - 2s - loss: 0.6486 - recall: 0.1870 - precision: 0.2532 - val_loss: 0.7924 - val_recall: 0.1588 - val_precision: 0.2143\n",
            "Epoch 800/1000\n",
            " - 2s - loss: 0.6466 - recall: 0.1926 - precision: 0.2544 - val_loss: 0.7939 - val_recall: 0.1627 - val_precision: 0.2191\n",
            "Epoch 801/1000\n",
            " - 2s - loss: 0.6509 - recall: 0.1860 - precision: 0.2563 - val_loss: 0.7886 - val_recall: 0.1644 - val_precision: 0.2134\n",
            "Epoch 802/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1884 - precision: 0.2559 - val_loss: 0.7922 - val_recall: 0.1528 - val_precision: 0.2028\n",
            "Epoch 803/1000\n",
            " - 2s - loss: 0.6493 - recall: 0.1983 - precision: 0.2600 - val_loss: 0.8016 - val_recall: 0.1590 - val_precision: 0.2093\n",
            "Epoch 804/1000\n",
            " - 2s - loss: 0.6486 - recall: 0.1912 - precision: 0.2576 - val_loss: 0.7996 - val_recall: 0.1652 - val_precision: 0.2151\n",
            "Epoch 805/1000\n",
            " - 2s - loss: 0.6513 - recall: 0.1920 - precision: 0.2568 - val_loss: 0.7854 - val_recall: 0.1642 - val_precision: 0.2200\n",
            "Epoch 806/1000\n",
            " - 2s - loss: 0.6491 - recall: 0.1925 - precision: 0.2574 - val_loss: 0.7946 - val_recall: 0.1601 - val_precision: 0.2129\n",
            "Epoch 807/1000\n",
            " - 2s - loss: 0.6446 - recall: 0.1947 - precision: 0.2724 - val_loss: 0.7978 - val_recall: 0.1562 - val_precision: 0.2022\n",
            "Epoch 808/1000\n",
            " - 2s - loss: 0.6475 - recall: 0.1877 - precision: 0.2522 - val_loss: 0.7894 - val_recall: 0.1529 - val_precision: 0.2028\n",
            "Epoch 809/1000\n",
            " - 2s - loss: 0.6468 - recall: 0.1848 - precision: 0.2489 - val_loss: 0.8005 - val_recall: 0.1686 - val_precision: 0.2219\n",
            "Epoch 810/1000\n",
            " - 2s - loss: 0.6522 - recall: 0.1894 - precision: 0.2559 - val_loss: 0.7867 - val_recall: 0.1655 - val_precision: 0.2242\n",
            "Epoch 811/1000\n",
            " - 2s - loss: 0.6423 - recall: 0.1966 - precision: 0.2661 - val_loss: 0.7950 - val_recall: 0.1533 - val_precision: 0.2037\n",
            "Epoch 812/1000\n",
            " - 2s - loss: 0.6478 - recall: 0.1923 - precision: 0.2532 - val_loss: 0.7885 - val_recall: 0.1526 - val_precision: 0.1988\n",
            "Epoch 813/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1892 - precision: 0.2483 - val_loss: 0.8011 - val_recall: 0.1715 - val_precision: 0.2220\n",
            "Epoch 814/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.2016 - precision: 0.2665 - val_loss: 0.7985 - val_recall: 0.1654 - val_precision: 0.2210\n",
            "Epoch 815/1000\n",
            " - 2s - loss: 0.6470 - recall: 0.2000 - precision: 0.2623 - val_loss: 0.7961 - val_recall: 0.1640 - val_precision: 0.2118\n",
            "Epoch 816/1000\n",
            " - 2s - loss: 0.6433 - recall: 0.1880 - precision: 0.2538 - val_loss: 0.7987 - val_recall: 0.1565 - val_precision: 0.2132\n",
            "Epoch 817/1000\n",
            " - 2s - loss: 0.6522 - recall: 0.1930 - precision: 0.2559 - val_loss: 0.8019 - val_recall: 0.1592 - val_precision: 0.2082\n",
            "Epoch 818/1000\n",
            " - 2s - loss: 0.6442 - recall: 0.1937 - precision: 0.2581 - val_loss: 0.8040 - val_recall: 0.1596 - val_precision: 0.2057\n",
            "Epoch 819/1000\n",
            " - 2s - loss: 0.6537 - recall: 0.1929 - precision: 0.2551 - val_loss: 0.7921 - val_recall: 0.1728 - val_precision: 0.2280\n",
            "Epoch 820/1000\n",
            " - 2s - loss: 0.6460 - recall: 0.1966 - precision: 0.2641 - val_loss: 0.7859 - val_recall: 0.1598 - val_precision: 0.2066\n",
            "Epoch 821/1000\n",
            " - 2s - loss: 0.6497 - recall: 0.1939 - precision: 0.2551 - val_loss: 0.7915 - val_recall: 0.1501 - val_precision: 0.2042\n",
            "Epoch 822/1000\n",
            " - 2s - loss: 0.6478 - recall: 0.1893 - precision: 0.2526 - val_loss: 0.7916 - val_recall: 0.1590 - val_precision: 0.2131\n",
            "Epoch 823/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1872 - precision: 0.2502 - val_loss: 0.8009 - val_recall: 0.1606 - val_precision: 0.2147\n",
            "Epoch 824/1000\n",
            " - 2s - loss: 0.6506 - recall: 0.1897 - precision: 0.2570 - val_loss: 0.7803 - val_recall: 0.1674 - val_precision: 0.2289\n",
            "Epoch 825/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.1989 - precision: 0.2650 - val_loss: 0.7950 - val_recall: 0.1619 - val_precision: 0.2197\n",
            "Epoch 826/1000\n",
            " - 2s - loss: 0.6495 - recall: 0.1883 - precision: 0.2507 - val_loss: 0.7844 - val_recall: 0.1630 - val_precision: 0.2138\n",
            "Epoch 827/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.1972 - precision: 0.2596 - val_loss: 0.7790 - val_recall: 0.1548 - val_precision: 0.2024\n",
            "Epoch 828/1000\n",
            " - 2s - loss: 0.6472 - recall: 0.1978 - precision: 0.2600 - val_loss: 0.7856 - val_recall: 0.1597 - val_precision: 0.2152\n",
            "Epoch 829/1000\n",
            " - 2s - loss: 0.6507 - recall: 0.1860 - precision: 0.2516 - val_loss: 0.7818 - val_recall: 0.1620 - val_precision: 0.2142\n",
            "Epoch 830/1000\n",
            " - 2s - loss: 0.6463 - recall: 0.1929 - precision: 0.2606 - val_loss: 0.7923 - val_recall: 0.1612 - val_precision: 0.2152\n",
            "Epoch 831/1000\n",
            " - 2s - loss: 0.6464 - recall: 0.1955 - precision: 0.2614 - val_loss: 0.7936 - val_recall: 0.1649 - val_precision: 0.2154\n",
            "Epoch 832/1000\n",
            " - 2s - loss: 0.6567 - recall: 0.1910 - precision: 0.2539 - val_loss: 0.8050 - val_recall: 0.1552 - val_precision: 0.2060\n",
            "Epoch 833/1000\n",
            " - 2s - loss: 0.6461 - recall: 0.1900 - precision: 0.2581 - val_loss: 0.7937 - val_recall: 0.1659 - val_precision: 0.2107\n",
            "Epoch 834/1000\n",
            " - 2s - loss: 0.6461 - recall: 0.1936 - precision: 0.2540 - val_loss: 0.7907 - val_recall: 0.1611 - val_precision: 0.2084\n",
            "Epoch 835/1000\n",
            " - 2s - loss: 0.6508 - recall: 0.1952 - precision: 0.2653 - val_loss: 0.7860 - val_recall: 0.1616 - val_precision: 0.2090\n",
            "Epoch 836/1000\n",
            " - 2s - loss: 0.6525 - recall: 0.1907 - precision: 0.2548 - val_loss: 0.8029 - val_recall: 0.1585 - val_precision: 0.2087\n",
            "Epoch 837/1000\n",
            " - 2s - loss: 0.6516 - recall: 0.1951 - precision: 0.2617 - val_loss: 0.8248 - val_recall: 0.1593 - val_precision: 0.2107\n",
            "Epoch 838/1000\n",
            " - 2s - loss: 0.6476 - recall: 0.1922 - precision: 0.2662 - val_loss: 0.7876 - val_recall: 0.1661 - val_precision: 0.2207\n",
            "Epoch 839/1000\n",
            " - 2s - loss: 0.6488 - recall: 0.1915 - precision: 0.2531 - val_loss: 0.7844 - val_recall: 0.1612 - val_precision: 0.2116\n",
            "Epoch 840/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1886 - precision: 0.2506 - val_loss: 0.7990 - val_recall: 0.1623 - val_precision: 0.2116\n",
            "Epoch 841/1000\n",
            " - 2s - loss: 0.6439 - recall: 0.1977 - precision: 0.2622 - val_loss: 0.7965 - val_recall: 0.1650 - val_precision: 0.2188\n",
            "Epoch 842/1000\n",
            " - 2s - loss: 0.6492 - recall: 0.1977 - precision: 0.2659 - val_loss: 0.7898 - val_recall: 0.1630 - val_precision: 0.2174\n",
            "Epoch 843/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.1936 - precision: 0.2595 - val_loss: 0.8023 - val_recall: 0.1574 - val_precision: 0.2089\n",
            "Epoch 844/1000\n",
            " - 2s - loss: 0.6548 - recall: 0.1924 - precision: 0.2540 - val_loss: 0.8021 - val_recall: 0.1646 - val_precision: 0.2146\n",
            "Epoch 845/1000\n",
            " - 2s - loss: 0.6485 - recall: 0.1927 - precision: 0.2572 - val_loss: 0.7874 - val_recall: 0.1621 - val_precision: 0.2175\n",
            "Epoch 846/1000\n",
            " - 2s - loss: 0.6440 - recall: 0.1962 - precision: 0.2612 - val_loss: 0.7852 - val_recall: 0.1492 - val_precision: 0.2078\n",
            "Epoch 847/1000\n",
            " - 2s - loss: 0.6446 - recall: 0.1908 - precision: 0.2474 - val_loss: 0.8007 - val_recall: 0.1638 - val_precision: 0.2193\n",
            "Epoch 848/1000\n",
            " - 2s - loss: 0.6453 - recall: 0.1933 - precision: 0.2607 - val_loss: 0.7953 - val_recall: 0.1613 - val_precision: 0.2154\n",
            "Epoch 849/1000\n",
            " - 2s - loss: 0.6467 - recall: 0.2015 - precision: 0.2643 - val_loss: 0.7907 - val_recall: 0.1717 - val_precision: 0.2200\n",
            "Epoch 850/1000\n",
            " - 2s - loss: 0.6472 - recall: 0.1929 - precision: 0.2554 - val_loss: 0.8135 - val_recall: 0.1637 - val_precision: 0.2103\n",
            "Epoch 851/1000\n",
            " - 2s - loss: 0.6487 - recall: 0.1931 - precision: 0.2515 - val_loss: 0.7975 - val_recall: 0.1666 - val_precision: 0.2182\n",
            "Epoch 852/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.2001 - precision: 0.2662 - val_loss: 0.7847 - val_recall: 0.1621 - val_precision: 0.2193\n",
            "Epoch 853/1000\n",
            " - 2s - loss: 0.6399 - recall: 0.1894 - precision: 0.2553 - val_loss: 0.8023 - val_recall: 0.1593 - val_precision: 0.2126\n",
            "Epoch 854/1000\n",
            " - 2s - loss: 0.6492 - recall: 0.1887 - precision: 0.2529 - val_loss: 0.7924 - val_recall: 0.1648 - val_precision: 0.2166\n",
            "Epoch 855/1000\n",
            " - 2s - loss: 0.6467 - recall: 0.1946 - precision: 0.2578 - val_loss: 0.7864 - val_recall: 0.1561 - val_precision: 0.2021\n",
            "Epoch 856/1000\n",
            " - 2s - loss: 0.6505 - recall: 0.1983 - precision: 0.2621 - val_loss: 0.7991 - val_recall: 0.1576 - val_precision: 0.2111\n",
            "Epoch 857/1000\n",
            " - 2s - loss: 0.6529 - recall: 0.1924 - precision: 0.2564 - val_loss: 0.7908 - val_recall: 0.1659 - val_precision: 0.2201\n",
            "Epoch 858/1000\n",
            " - 2s - loss: 0.6478 - recall: 0.1915 - precision: 0.2635 - val_loss: 0.7924 - val_recall: 0.1540 - val_precision: 0.2036\n",
            "Epoch 859/1000\n",
            " - 2s - loss: 0.6442 - recall: 0.1958 - precision: 0.2635 - val_loss: 0.8175 - val_recall: 0.1540 - val_precision: 0.2011\n",
            "Epoch 860/1000\n",
            " - 2s - loss: 0.6517 - recall: 0.1945 - precision: 0.2551 - val_loss: 0.8113 - val_recall: 0.1542 - val_precision: 0.2116\n",
            "Epoch 861/1000\n",
            " - 2s - loss: 0.6500 - recall: 0.1891 - precision: 0.2579 - val_loss: 0.8016 - val_recall: 0.1660 - val_precision: 0.2140\n",
            "Epoch 862/1000\n",
            " - 2s - loss: 0.6534 - recall: 0.1926 - precision: 0.2568 - val_loss: 0.7983 - val_recall: 0.1597 - val_precision: 0.2080\n",
            "Epoch 863/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1891 - precision: 0.2574 - val_loss: 0.7892 - val_recall: 0.1632 - val_precision: 0.2237\n",
            "Epoch 864/1000\n",
            " - 2s - loss: 0.6438 - recall: 0.1903 - precision: 0.2481 - val_loss: 0.7994 - val_recall: 0.1654 - val_precision: 0.2170\n",
            "Epoch 865/1000\n",
            " - 2s - loss: 0.6426 - recall: 0.1953 - precision: 0.2604 - val_loss: 0.8074 - val_recall: 0.1622 - val_precision: 0.2087\n",
            "Epoch 866/1000\n",
            " - 2s - loss: 0.6444 - recall: 0.2017 - precision: 0.2685 - val_loss: 0.7811 - val_recall: 0.1597 - val_precision: 0.2088\n",
            "Epoch 867/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1907 - precision: 0.2572 - val_loss: 0.7970 - val_recall: 0.1679 - val_precision: 0.2247\n",
            "Epoch 868/1000\n",
            " - 2s - loss: 0.6464 - recall: 0.1962 - precision: 0.2629 - val_loss: 0.7979 - val_recall: 0.1612 - val_precision: 0.2041\n",
            "Epoch 869/1000\n",
            " - 2s - loss: 0.6452 - recall: 0.1959 - precision: 0.2612 - val_loss: 0.8212 - val_recall: 0.1663 - val_precision: 0.2166\n",
            "Epoch 870/1000\n",
            " - 2s - loss: 0.6493 - recall: 0.1900 - precision: 0.2535 - val_loss: 0.8037 - val_recall: 0.1704 - val_precision: 0.2253\n",
            "Epoch 871/1000\n",
            " - 2s - loss: 0.6512 - recall: 0.1980 - precision: 0.2641 - val_loss: 0.7974 - val_recall: 0.1589 - val_precision: 0.2103\n",
            "Epoch 872/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1885 - precision: 0.2469 - val_loss: 0.7963 - val_recall: 0.1676 - val_precision: 0.2189\n",
            "Epoch 873/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1940 - precision: 0.2560 - val_loss: 0.7873 - val_recall: 0.1702 - val_precision: 0.2213\n",
            "Epoch 874/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.1960 - precision: 0.2584 - val_loss: 0.7919 - val_recall: 0.1623 - val_precision: 0.2179\n",
            "Epoch 875/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1897 - precision: 0.2546 - val_loss: 0.7993 - val_recall: 0.1620 - val_precision: 0.2176\n",
            "Epoch 876/1000\n",
            " - 2s - loss: 0.6553 - recall: 0.2015 - precision: 0.2651 - val_loss: 0.7947 - val_recall: 0.1498 - val_precision: 0.2065\n",
            "Epoch 877/1000\n",
            " - 2s - loss: 0.6547 - recall: 0.1823 - precision: 0.2461 - val_loss: 0.7912 - val_recall: 0.1681 - val_precision: 0.2214\n",
            "Epoch 878/1000\n",
            " - 2s - loss: 0.6437 - recall: 0.2007 - precision: 0.2639 - val_loss: 0.7864 - val_recall: 0.1646 - val_precision: 0.2118\n",
            "Epoch 879/1000\n",
            " - 2s - loss: 0.6477 - recall: 0.1888 - precision: 0.2454 - val_loss: 0.7818 - val_recall: 0.1681 - val_precision: 0.2278\n",
            "Epoch 880/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1932 - precision: 0.2606 - val_loss: 0.7855 - val_recall: 0.1611 - val_precision: 0.2105\n",
            "Epoch 881/1000\n",
            " - 2s - loss: 0.6428 - recall: 0.1941 - precision: 0.2602 - val_loss: 0.7976 - val_recall: 0.1636 - val_precision: 0.2112\n",
            "Epoch 882/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1827 - precision: 0.2469 - val_loss: 0.7807 - val_recall: 0.1679 - val_precision: 0.2172\n",
            "Epoch 883/1000\n",
            " - 2s - loss: 0.6482 - recall: 0.1950 - precision: 0.2596 - val_loss: 0.8016 - val_recall: 0.1556 - val_precision: 0.2126\n",
            "Epoch 884/1000\n",
            " - 2s - loss: 0.6430 - recall: 0.1897 - precision: 0.2493 - val_loss: 0.8086 - val_recall: 0.1603 - val_precision: 0.2023\n",
            "Epoch 885/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.1929 - precision: 0.2531 - val_loss: 0.7986 - val_recall: 0.1608 - val_precision: 0.2154\n",
            "Epoch 886/1000\n",
            " - 2s - loss: 0.6477 - recall: 0.1935 - precision: 0.2614 - val_loss: 0.8011 - val_recall: 0.1604 - val_precision: 0.2065\n",
            "Epoch 887/1000\n",
            " - 2s - loss: 0.6445 - recall: 0.1944 - precision: 0.2595 - val_loss: 0.7945 - val_recall: 0.1607 - val_precision: 0.2172\n",
            "Epoch 888/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.2009 - precision: 0.2711 - val_loss: 0.8030 - val_recall: 0.1656 - val_precision: 0.2144\n",
            "Epoch 889/1000\n",
            " - 2s - loss: 0.6480 - recall: 0.1900 - precision: 0.2527 - val_loss: 0.8085 - val_recall: 0.1612 - val_precision: 0.2173\n",
            "Epoch 890/1000\n",
            " - 2s - loss: 0.6482 - recall: 0.1892 - precision: 0.2515 - val_loss: 0.7895 - val_recall: 0.1640 - val_precision: 0.2233\n",
            "Epoch 891/1000\n",
            " - 2s - loss: 0.6550 - recall: 0.1883 - precision: 0.2545 - val_loss: 0.7868 - val_recall: 0.1660 - val_precision: 0.2219\n",
            "Epoch 892/1000\n",
            " - 2s - loss: 0.6426 - recall: 0.1965 - precision: 0.2625 - val_loss: 0.7924 - val_recall: 0.1639 - val_precision: 0.2145\n",
            "Epoch 893/1000\n",
            " - 2s - loss: 0.6435 - recall: 0.1938 - precision: 0.2631 - val_loss: 0.8057 - val_recall: 0.1658 - val_precision: 0.2113\n",
            "Epoch 894/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.2008 - precision: 0.2641 - val_loss: 0.7933 - val_recall: 0.1597 - val_precision: 0.2096\n",
            "Epoch 895/1000\n",
            " - 2s - loss: 0.6391 - recall: 0.2001 - precision: 0.2697 - val_loss: 0.7978 - val_recall: 0.1546 - val_precision: 0.2105\n",
            "Epoch 896/1000\n",
            " - 2s - loss: 0.6431 - recall: 0.1868 - precision: 0.2507 - val_loss: 0.7869 - val_recall: 0.1642 - val_precision: 0.2099\n",
            "Epoch 897/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1946 - precision: 0.2615 - val_loss: 0.8020 - val_recall: 0.1637 - val_precision: 0.2138\n",
            "Epoch 898/1000\n",
            " - 2s - loss: 0.6517 - recall: 0.1972 - precision: 0.2638 - val_loss: 0.7932 - val_recall: 0.1656 - val_precision: 0.2173\n",
            "Epoch 899/1000\n",
            " - 2s - loss: 0.6463 - recall: 0.1976 - precision: 0.2556 - val_loss: 0.7963 - val_recall: 0.1553 - val_precision: 0.2082\n",
            "Epoch 900/1000\n",
            " - 2s - loss: 0.6496 - recall: 0.1891 - precision: 0.2606 - val_loss: 0.8090 - val_recall: 0.1578 - val_precision: 0.2176\n",
            "Epoch 901/1000\n",
            " - 2s - loss: 0.6461 - recall: 0.1878 - precision: 0.2528 - val_loss: 0.8035 - val_recall: 0.1665 - val_precision: 0.2088\n",
            "Epoch 902/1000\n",
            " - 2s - loss: 0.6433 - recall: 0.1948 - precision: 0.2655 - val_loss: 0.7791 - val_recall: 0.1552 - val_precision: 0.2043\n",
            "Epoch 903/1000\n",
            " - 2s - loss: 0.6413 - recall: 0.1930 - precision: 0.2579 - val_loss: 0.7868 - val_recall: 0.1655 - val_precision: 0.2181\n",
            "Epoch 904/1000\n",
            " - 2s - loss: 0.6451 - recall: 0.1910 - precision: 0.2517 - val_loss: 0.8111 - val_recall: 0.1622 - val_precision: 0.2188\n",
            "Epoch 905/1000\n",
            " - 2s - loss: 0.6488 - recall: 0.1955 - precision: 0.2645 - val_loss: 0.7946 - val_recall: 0.1683 - val_precision: 0.2250\n",
            "Epoch 906/1000\n",
            " - 2s - loss: 0.6444 - recall: 0.1982 - precision: 0.2666 - val_loss: 0.7899 - val_recall: 0.1632 - val_precision: 0.2141\n",
            "Epoch 907/1000\n",
            " - 2s - loss: 0.6502 - recall: 0.1971 - precision: 0.2605 - val_loss: 0.7978 - val_recall: 0.1672 - val_precision: 0.2174\n",
            "Epoch 908/1000\n",
            " - 2s - loss: 0.6453 - recall: 0.1943 - precision: 0.2563 - val_loss: 0.7938 - val_recall: 0.1653 - val_precision: 0.2106\n",
            "Epoch 909/1000\n",
            " - 2s - loss: 0.6460 - recall: 0.1948 - precision: 0.2563 - val_loss: 0.8053 - val_recall: 0.1659 - val_precision: 0.2163\n",
            "Epoch 910/1000\n",
            " - 2s - loss: 0.6545 - recall: 0.1900 - precision: 0.2525 - val_loss: 0.8071 - val_recall: 0.1691 - val_precision: 0.2232\n",
            "Epoch 911/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1930 - precision: 0.2589 - val_loss: 0.7925 - val_recall: 0.1622 - val_precision: 0.2095\n",
            "Epoch 912/1000\n",
            " - 2s - loss: 0.6412 - recall: 0.1941 - precision: 0.2618 - val_loss: 0.7994 - val_recall: 0.1669 - val_precision: 0.2165\n",
            "Epoch 913/1000\n",
            " - 2s - loss: 0.6473 - recall: 0.1948 - precision: 0.2583 - val_loss: 0.8025 - val_recall: 0.1560 - val_precision: 0.2137\n",
            "Epoch 914/1000\n",
            " - 2s - loss: 0.6420 - recall: 0.1952 - precision: 0.2612 - val_loss: 0.8002 - val_recall: 0.1619 - val_precision: 0.2181\n",
            "Epoch 915/1000\n",
            " - 2s - loss: 0.6489 - recall: 0.1974 - precision: 0.2691 - val_loss: 0.7963 - val_recall: 0.1618 - val_precision: 0.2151\n",
            "Epoch 916/1000\n",
            " - 2s - loss: 0.6433 - recall: 0.1959 - precision: 0.2618 - val_loss: 0.8025 - val_recall: 0.1594 - val_precision: 0.2185\n",
            "Epoch 917/1000\n",
            " - 2s - loss: 0.6438 - recall: 0.1915 - precision: 0.2639 - val_loss: 0.8080 - val_recall: 0.1629 - val_precision: 0.2156\n",
            "Epoch 918/1000\n",
            " - 2s - loss: 0.6460 - recall: 0.1987 - precision: 0.2681 - val_loss: 0.8058 - val_recall: 0.1628 - val_precision: 0.2142\n",
            "Epoch 919/1000\n",
            " - 2s - loss: 0.6491 - recall: 0.1964 - precision: 0.2623 - val_loss: 0.7918 - val_recall: 0.1634 - val_precision: 0.2172\n",
            "Epoch 920/1000\n",
            " - 2s - loss: 0.6414 - recall: 0.2020 - precision: 0.2633 - val_loss: 0.7959 - val_recall: 0.1606 - val_precision: 0.2158\n",
            "Epoch 921/1000\n",
            " - 2s - loss: 0.6521 - recall: 0.1954 - precision: 0.2602 - val_loss: 0.7944 - val_recall: 0.1629 - val_precision: 0.2143\n",
            "Epoch 922/1000\n",
            " - 2s - loss: 0.6470 - recall: 0.1944 - precision: 0.2568 - val_loss: 0.8081 - val_recall: 0.1617 - val_precision: 0.2149\n",
            "Epoch 923/1000\n",
            " - 2s - loss: 0.6442 - recall: 0.1968 - precision: 0.2650 - val_loss: 0.8006 - val_recall: 0.1637 - val_precision: 0.2127\n",
            "Epoch 924/1000\n",
            " - 2s - loss: 0.6479 - recall: 0.1967 - precision: 0.2653 - val_loss: 0.8129 - val_recall: 0.1696 - val_precision: 0.2250\n",
            "Epoch 925/1000\n",
            " - 2s - loss: 0.6431 - recall: 0.1983 - precision: 0.2664 - val_loss: 0.8088 - val_recall: 0.1660 - val_precision: 0.2191\n",
            "Epoch 926/1000\n",
            " - 2s - loss: 0.6441 - recall: 0.1889 - precision: 0.2555 - val_loss: 0.8103 - val_recall: 0.1587 - val_precision: 0.2138\n",
            "Epoch 927/1000\n",
            " - 2s - loss: 0.6450 - recall: 0.1876 - precision: 0.2512 - val_loss: 0.8027 - val_recall: 0.1651 - val_precision: 0.2171\n",
            "Epoch 928/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1962 - precision: 0.2597 - val_loss: 0.8020 - val_recall: 0.1616 - val_precision: 0.2130\n",
            "Epoch 929/1000\n",
            " - 2s - loss: 0.6472 - recall: 0.1894 - precision: 0.2586 - val_loss: 0.7850 - val_recall: 0.1483 - val_precision: 0.2038\n",
            "Epoch 930/1000\n",
            " - 2s - loss: 0.6436 - recall: 0.1949 - precision: 0.2692 - val_loss: 0.8070 - val_recall: 0.1595 - val_precision: 0.2088\n",
            "Epoch 931/1000\n",
            " - 2s - loss: 0.6439 - recall: 0.1971 - precision: 0.2680 - val_loss: 0.7957 - val_recall: 0.1672 - val_precision: 0.2242\n",
            "Epoch 932/1000\n",
            " - 2s - loss: 0.6445 - recall: 0.1945 - precision: 0.2619 - val_loss: 0.7946 - val_recall: 0.1713 - val_precision: 0.2215\n",
            "Epoch 933/1000\n",
            " - 2s - loss: 0.6480 - recall: 0.1971 - precision: 0.2594 - val_loss: 0.8026 - val_recall: 0.1603 - val_precision: 0.2178\n",
            "Epoch 934/1000\n",
            " - 2s - loss: 0.6490 - recall: 0.1865 - precision: 0.2539 - val_loss: 0.7963 - val_recall: 0.1556 - val_precision: 0.2114\n",
            "Epoch 935/1000\n",
            " - 2s - loss: 0.6480 - recall: 0.1884 - precision: 0.2522 - val_loss: 0.7963 - val_recall: 0.1675 - val_precision: 0.2235\n",
            "Epoch 936/1000\n",
            " - 2s - loss: 0.6431 - recall: 0.1932 - precision: 0.2599 - val_loss: 0.8068 - val_recall: 0.1623 - val_precision: 0.2179\n",
            "Epoch 937/1000\n",
            " - 2s - loss: 0.6418 - recall: 0.1921 - precision: 0.2556 - val_loss: 0.8157 - val_recall: 0.1744 - val_precision: 0.2232\n",
            "Epoch 938/1000\n",
            " - 2s - loss: 0.6423 - recall: 0.1930 - precision: 0.2622 - val_loss: 0.8042 - val_recall: 0.1587 - val_precision: 0.2094\n",
            "Epoch 939/1000\n",
            " - 2s - loss: 0.6414 - recall: 0.1926 - precision: 0.2596 - val_loss: 0.8046 - val_recall: 0.1603 - val_precision: 0.2066\n",
            "Epoch 940/1000\n",
            " - 2s - loss: 0.6472 - recall: 0.1927 - precision: 0.2622 - val_loss: 0.7921 - val_recall: 0.1540 - val_precision: 0.2077\n",
            "Epoch 941/1000\n",
            " - 2s - loss: 0.6395 - recall: 0.1909 - precision: 0.2544 - val_loss: 0.8094 - val_recall: 0.1595 - val_precision: 0.2114\n",
            "Epoch 942/1000\n",
            " - 2s - loss: 0.6466 - recall: 0.1982 - precision: 0.2585 - val_loss: 0.7908 - val_recall: 0.1643 - val_precision: 0.2169\n",
            "Epoch 943/1000\n",
            " - 2s - loss: 0.6405 - recall: 0.1925 - precision: 0.2501 - val_loss: 0.7926 - val_recall: 0.1652 - val_precision: 0.2169\n",
            "Epoch 944/1000\n",
            " - 2s - loss: 0.6486 - recall: 0.1940 - precision: 0.2658 - val_loss: 0.7839 - val_recall: 0.1609 - val_precision: 0.2113\n",
            "Epoch 945/1000\n",
            " - 2s - loss: 0.6483 - recall: 0.1874 - precision: 0.2495 - val_loss: 0.8003 - val_recall: 0.1630 - val_precision: 0.2194\n",
            "Epoch 946/1000\n",
            " - 2s - loss: 0.6456 - recall: 0.1877 - precision: 0.2519 - val_loss: 0.7998 - val_recall: 0.1613 - val_precision: 0.2171\n",
            "Epoch 947/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.1954 - precision: 0.2600 - val_loss: 0.8274 - val_recall: 0.1671 - val_precision: 0.2251\n",
            "Epoch 948/1000\n",
            " - 2s - loss: 0.6580 - recall: 0.1837 - precision: 0.2453 - val_loss: 0.7877 - val_recall: 0.1577 - val_precision: 0.2075\n",
            "Epoch 949/1000\n",
            " - 2s - loss: 0.6500 - recall: 0.1908 - precision: 0.2544 - val_loss: 0.7949 - val_recall: 0.1672 - val_precision: 0.2177\n",
            "Epoch 950/1000\n",
            " - 2s - loss: 0.6485 - recall: 0.1918 - precision: 0.2491 - val_loss: 0.7809 - val_recall: 0.1632 - val_precision: 0.2204\n",
            "Epoch 951/1000\n",
            " - 2s - loss: 0.6461 - recall: 0.1909 - precision: 0.2557 - val_loss: 0.7864 - val_recall: 0.1659 - val_precision: 0.2200\n",
            "Epoch 952/1000\n",
            " - 2s - loss: 0.6433 - recall: 0.1965 - precision: 0.2648 - val_loss: 0.7967 - val_recall: 0.1640 - val_precision: 0.2130\n",
            "Epoch 953/1000\n",
            " - 2s - loss: 0.6510 - recall: 0.1950 - precision: 0.2565 - val_loss: 0.8079 - val_recall: 0.1650 - val_precision: 0.2064\n",
            "Epoch 954/1000\n",
            " - 2s - loss: 0.6456 - recall: 0.1948 - precision: 0.2623 - val_loss: 0.7969 - val_recall: 0.1555 - val_precision: 0.1982\n",
            "Epoch 955/1000\n",
            " - 2s - loss: 0.6436 - recall: 0.1962 - precision: 0.2676 - val_loss: 0.7915 - val_recall: 0.1578 - val_precision: 0.2098\n",
            "Epoch 956/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1876 - precision: 0.2471 - val_loss: 0.8187 - val_recall: 0.1713 - val_precision: 0.2227\n",
            "Epoch 957/1000\n",
            " - 2s - loss: 0.6491 - recall: 0.2000 - precision: 0.2664 - val_loss: 0.8010 - val_recall: 0.1603 - val_precision: 0.2131\n",
            "Epoch 958/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.1970 - precision: 0.2713 - val_loss: 0.8055 - val_recall: 0.1597 - val_precision: 0.2162\n",
            "Epoch 959/1000\n",
            " - 2s - loss: 0.6459 - recall: 0.1894 - precision: 0.2546 - val_loss: 0.7883 - val_recall: 0.1623 - val_precision: 0.2173\n",
            "Epoch 960/1000\n",
            " - 2s - loss: 0.6551 - recall: 0.1922 - precision: 0.2564 - val_loss: 0.8078 - val_recall: 0.1585 - val_precision: 0.2105\n",
            "Epoch 961/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.1970 - precision: 0.2632 - val_loss: 0.8032 - val_recall: 0.1601 - val_precision: 0.2133\n",
            "Epoch 962/1000\n",
            " - 2s - loss: 0.6484 - recall: 0.1867 - precision: 0.2485 - val_loss: 0.8075 - val_recall: 0.1646 - val_precision: 0.2179\n",
            "Epoch 963/1000\n",
            " - 2s - loss: 0.6475 - recall: 0.1922 - precision: 0.2619 - val_loss: 0.7965 - val_recall: 0.1564 - val_precision: 0.2085\n",
            "Epoch 964/1000\n",
            " - 2s - loss: 0.6503 - recall: 0.1969 - precision: 0.2620 - val_loss: 0.7869 - val_recall: 0.1665 - val_precision: 0.2174\n",
            "Epoch 965/1000\n",
            " - 2s - loss: 0.6457 - recall: 0.2018 - precision: 0.2640 - val_loss: 0.8090 - val_recall: 0.1549 - val_precision: 0.2095\n",
            "Epoch 966/1000\n",
            " - 2s - loss: 0.6495 - recall: 0.1962 - precision: 0.2621 - val_loss: 0.7932 - val_recall: 0.1698 - val_precision: 0.2192\n",
            "Epoch 967/1000\n",
            " - 2s - loss: 0.6501 - recall: 0.1961 - precision: 0.2619 - val_loss: 0.7909 - val_recall: 0.1633 - val_precision: 0.2189\n",
            "Epoch 968/1000\n",
            " - 2s - loss: 0.6439 - recall: 0.1961 - precision: 0.2634 - val_loss: 0.8295 - val_recall: 0.1642 - val_precision: 0.2130\n",
            "Epoch 969/1000\n",
            " - 2s - loss: 0.6471 - recall: 0.1979 - precision: 0.2643 - val_loss: 0.7980 - val_recall: 0.1736 - val_precision: 0.2270\n",
            "Epoch 970/1000\n",
            " - 2s - loss: 0.6439 - recall: 0.1943 - precision: 0.2577 - val_loss: 0.7999 - val_recall: 0.1674 - val_precision: 0.2185\n",
            "Epoch 971/1000\n",
            " - 2s - loss: 0.6518 - recall: 0.1924 - precision: 0.2514 - val_loss: 0.8035 - val_recall: 0.1732 - val_precision: 0.2222\n",
            "Epoch 972/1000\n",
            " - 2s - loss: 0.6482 - recall: 0.1953 - precision: 0.2570 - val_loss: 0.7927 - val_recall: 0.1607 - val_precision: 0.2054\n",
            "Epoch 973/1000\n",
            " - 2s - loss: 0.6433 - recall: 0.1963 - precision: 0.2631 - val_loss: 0.7946 - val_recall: 0.1680 - val_precision: 0.2236\n",
            "Epoch 974/1000\n",
            " - 2s - loss: 0.6404 - recall: 0.2056 - precision: 0.2716 - val_loss: 0.8103 - val_recall: 0.1612 - val_precision: 0.2142\n",
            "Epoch 975/1000\n",
            " - 2s - loss: 0.6458 - recall: 0.1991 - precision: 0.2650 - val_loss: 0.8147 - val_recall: 0.1727 - val_precision: 0.2241\n",
            "Epoch 976/1000\n",
            " - 2s - loss: 0.6464 - recall: 0.1875 - precision: 0.2473 - val_loss: 0.7990 - val_recall: 0.1705 - val_precision: 0.2204\n",
            "Epoch 977/1000\n",
            " - 2s - loss: 0.6485 - recall: 0.1911 - precision: 0.2529 - val_loss: 0.8182 - val_recall: 0.1576 - val_precision: 0.2099\n",
            "Epoch 978/1000\n",
            " - 2s - loss: 0.6463 - recall: 0.1982 - precision: 0.2622 - val_loss: 0.8048 - val_recall: 0.1712 - val_precision: 0.2286\n",
            "Epoch 979/1000\n",
            " - 2s - loss: 0.6453 - recall: 0.1998 - precision: 0.2618 - val_loss: 0.7990 - val_recall: 0.1547 - val_precision: 0.2091\n",
            "Epoch 980/1000\n",
            " - 2s - loss: 0.6443 - recall: 0.1965 - precision: 0.2676 - val_loss: 0.8085 - val_recall: 0.1610 - val_precision: 0.2160\n",
            "Epoch 981/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.1974 - precision: 0.2707 - val_loss: 0.7959 - val_recall: 0.1641 - val_precision: 0.2138\n",
            "Epoch 982/1000\n",
            " - 2s - loss: 0.6519 - recall: 0.1967 - precision: 0.2611 - val_loss: 0.8091 - val_recall: 0.1628 - val_precision: 0.2162\n",
            "Epoch 983/1000\n",
            " - 2s - loss: 0.6471 - recall: 0.1963 - precision: 0.2610 - val_loss: 0.7853 - val_recall: 0.1579 - val_precision: 0.2171\n",
            "Epoch 984/1000\n",
            " - 2s - loss: 0.6443 - recall: 0.1884 - precision: 0.2509 - val_loss: 0.7838 - val_recall: 0.1628 - val_precision: 0.2183\n",
            "Epoch 985/1000\n",
            " - 2s - loss: 0.6450 - recall: 0.1901 - precision: 0.2569 - val_loss: 0.7968 - val_recall: 0.1614 - val_precision: 0.2153\n",
            "Epoch 986/1000\n",
            " - 2s - loss: 0.6470 - recall: 0.1944 - precision: 0.2568 - val_loss: 0.8100 - val_recall: 0.1628 - val_precision: 0.2115\n",
            "Epoch 987/1000\n",
            " - 2s - loss: 0.6461 - recall: 0.1983 - precision: 0.2644 - val_loss: 0.8036 - val_recall: 0.1606 - val_precision: 0.2104\n",
            "Epoch 988/1000\n",
            " - 2s - loss: 0.6420 - recall: 0.1936 - precision: 0.2558 - val_loss: 0.8004 - val_recall: 0.1706 - val_precision: 0.2208\n",
            "Epoch 989/1000\n",
            " - 2s - loss: 0.6498 - recall: 0.1997 - precision: 0.2608 - val_loss: 0.8082 - val_recall: 0.1639 - val_precision: 0.2160\n",
            "Epoch 990/1000\n",
            " - 2s - loss: 0.6465 - recall: 0.1992 - precision: 0.2631 - val_loss: 0.8137 - val_recall: 0.1653 - val_precision: 0.2193\n",
            "Epoch 991/1000\n",
            " - 2s - loss: 0.6540 - recall: 0.1919 - precision: 0.2569 - val_loss: 0.8037 - val_recall: 0.1662 - val_precision: 0.2080\n",
            "Epoch 992/1000\n",
            " - 2s - loss: 0.6481 - recall: 0.1970 - precision: 0.2597 - val_loss: 0.7852 - val_recall: 0.1665 - val_precision: 0.2084\n",
            "Epoch 993/1000\n",
            " - 2s - loss: 0.6499 - recall: 0.1949 - precision: 0.2659 - val_loss: 0.7944 - val_recall: 0.1663 - val_precision: 0.2163\n",
            "Epoch 994/1000\n",
            " - 2s - loss: 0.6454 - recall: 0.1931 - precision: 0.2522 - val_loss: 0.8009 - val_recall: 0.1603 - val_precision: 0.2092\n",
            "Epoch 995/1000\n",
            " - 2s - loss: 0.6439 - recall: 0.1960 - precision: 0.2643 - val_loss: 0.8098 - val_recall: 0.1614 - val_precision: 0.2101\n",
            "Epoch 996/1000\n",
            " - 2s - loss: 0.6428 - recall: 0.1977 - precision: 0.2664 - val_loss: 0.8175 - val_recall: 0.1625 - val_precision: 0.2114\n",
            "Epoch 997/1000\n",
            " - 2s - loss: 0.6471 - recall: 0.1929 - precision: 0.2556 - val_loss: 0.8004 - val_recall: 0.1661 - val_precision: 0.2176\n",
            "Epoch 998/1000\n",
            " - 2s - loss: 0.6435 - recall: 0.1947 - precision: 0.2601 - val_loss: 0.7924 - val_recall: 0.1605 - val_precision: 0.2121\n",
            "Epoch 999/1000\n",
            " - 2s - loss: 0.6409 - recall: 0.2017 - precision: 0.2690 - val_loss: 0.8187 - val_recall: 0.1533 - val_precision: 0.2029\n",
            "Epoch 1000/1000\n",
            " - 2s - loss: 0.6373 - recall: 0.1951 - precision: 0.2653 - val_loss: 0.8225 - val_recall: 0.1552 - val_precision: 0.2030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiKtQoBvTwJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras\n",
        "from keras.layers import Dense, Conv2D, Flatten,Dropout,MaxPool2D, Input\n",
        "\n",
        "model =  Sequential()\n",
        "input_layer = Input()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}